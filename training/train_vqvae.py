#!/usr/bin/env python3
"""
VQ-VAEè®­ç»ƒè„šæœ¬
ç¬¬ä¸€é˜¶æ®µï¼šè®­ç»ƒVQ-VAEå­¦ä¹ å›¾åƒçš„ç¦»æ•£è¡¨ç¤º
"""

import os
import sys
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from pathlib import Path
from tqdm import tqdm
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from models.vqvae_model import MicroDopplerVQVAE
from utils.data_loader import MicroDopplerDataset
from utils.metrics import calculate_psnr, calculate_ssim

class VQVAETrainer:
    """VQ-VAEè®­ç»ƒå™¨"""
    
    def __init__(self, args):
        self.args = args
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(args.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®æ•°æ®å˜æ¢ (256x256 -> 128x128) - ä½¿ç”¨é«˜è´¨é‡ç¼©æ”¾
        interpolation_method = getattr(args, 'interpolation', 'lanczos')

        if interpolation_method == 'antialias':
            # æŠ—é”¯é½¿ç¼©æ”¾ (æ¨èç”¨äºæ·±åº¦å­¦ä¹ )
            resize_transform = transforms.Resize(
                (args.resolution, args.resolution),
                interpolation=transforms.InterpolationMode.BILINEAR,
                antialias=True
            )
        else:
            # ä¼ ç»Ÿæ’å€¼æ–¹æ³•
            interp_map = {
                'lanczos': transforms.InterpolationMode.LANCZOS,
                'bicubic': transforms.InterpolationMode.BICUBIC,
                'bilinear': transforms.InterpolationMode.BILINEAR,
            }
            interp_mode = interp_map.get(interpolation_method, transforms.InterpolationMode.LANCZOS)
            resize_transform = transforms.Resize((args.resolution, args.resolution), interpolation=interp_mode)

        self.transform = transforms.Compose([
            resize_transform,
            transforms.ToTensor(),  # [0, 1]
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # [-1, 1]
        ])

        print(f"ğŸ–¼ï¸ å›¾åƒç¼©æ”¾: 256x256 -> {args.resolution}x{args.resolution} ({interpolation_method})")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = self._create_model()
        self.model.to(self.device)
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=args.learning_rate,
            weight_decay=args.weight_decay,
            betas=(0.9, 0.999),
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=args.num_epochs,
            eta_min=args.learning_rate * 0.01,
        )
        
        # æŸå¤±å‡½æ•°
        self.recon_criterion = nn.MSELoss()
        
        print(f"ğŸš€ VQ-VAEè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"   åˆ†è¾¨ç‡: {args.resolution}x{args.resolution}")
    
    def _create_model(self):
        """åˆ›å»ºVQ-VAEæ¨¡å‹"""
        return MicroDopplerVQVAE(
            in_channels=3,
            out_channels=3,
            down_block_types=("DownEncoderBlock2D", "DownEncoderBlock2D", "DownEncoderBlock2D"),
            up_block_types=("UpDecoderBlock2D", "UpDecoderBlock2D", "UpDecoderBlock2D"),
            block_out_channels=(128, 256, 512),
            layers_per_block=2,
            act_fn="silu",
            latent_channels=256,
            sample_size=self.args.resolution // 8,  # 8å€ä¸‹é‡‡æ ·
            num_vq_embeddings=self.args.codebook_size,
            norm_num_groups=32,
            vq_embed_dim=256,
            commitment_cost=self.args.commitment_cost,
            ema_decay=self.args.ema_decay,
            restart_threshold=self.args.restart_threshold,
        )
    
    def _create_dataloader(self):
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        dataset = MicroDopplerDataset(
            data_dir=self.args.data_dir,
            transform=self.transform,
            return_user_id=True,  # è¿”å›ç”¨æˆ·IDç”¨äºåç»­Transformerè®­ç»ƒ
        )
        
        dataloader = DataLoader(
            dataset,
            batch_size=self.args.batch_size,
            shuffle=True,
            num_workers=self.args.num_workers,
            pin_memory=True,
            drop_last=True,
        )
        
        print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"   æ€»æ ·æœ¬æ•°: {len(dataset)}")
        print(f"   æ‰¹æ¬¡å¤§å°: {self.args.batch_size}")
        print(f"   æ‰¹æ¬¡æ•°é‡: {len(dataloader)}")
        
        return dataloader
    
    def train_epoch(self, dataloader, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        total_loss = 0
        total_recon_loss = 0
        total_vq_loss = 0
        
        pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{self.args.num_epochs}")
        
        for batch_idx, batch in enumerate(pbar):
            if isinstance(batch, (list, tuple)) and len(batch) == 2:
                images, user_ids = batch
            else:
                images = batch
                user_ids = None
            
            images = images.to(self.device)
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            
            outputs = self.model(images, return_dict=True)
            reconstructed = outputs.sample
            vq_loss = outputs.vq_loss
            
            # è®¡ç®—é‡å»ºæŸå¤±
            recon_loss = self.recon_criterion(reconstructed, images)
            
            # æ€»æŸå¤±
            total_loss_batch = recon_loss + vq_loss
            
            # åå‘ä¼ æ’­
            total_loss_batch.backward()
            
            # æ¢¯åº¦è£å‰ª
            if self.args.max_grad_norm > 0:
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.max_grad_norm)
            
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += total_loss_batch.item()
            total_recon_loss += recon_loss.item()
            total_vq_loss += vq_loss.item()
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'Loss': f'{total_loss_batch.item():.4f}',
                'Recon': f'{recon_loss.item():.4f}',
                'VQ': f'{vq_loss.item():.4f}',
                'LR': f'{self.optimizer.param_groups[0]["lr"]:.6f}',
            })
            
            # å®šæœŸä¿å­˜æ ·æœ¬
            if batch_idx % self.args.sample_interval == 0:
                self._save_samples(images, reconstructed, epoch, batch_idx)
        
        # æ›´æ–°å­¦ä¹ ç‡
        self.scheduler.step()
        
        # è¿”å›å¹³å‡æŸå¤±
        num_batches = len(dataloader)
        return {
            'total_loss': total_loss / num_batches,
            'recon_loss': total_recon_loss / num_batches,
            'vq_loss': total_vq_loss / num_batches,
        }
    
    def _save_samples(self, original, reconstructed, epoch, batch_idx):
        """ä¿å­˜é‡å»ºæ ·æœ¬"""
        sample_dir = self.output_dir / "samples"
        sample_dir.mkdir(exist_ok=True)
        
        # åå½’ä¸€åŒ–
        def denormalize(tensor):
            return (tensor * 0.5 + 0.5).clamp(0, 1)
        
        original = denormalize(original)
        reconstructed = denormalize(reconstructed)
        
        # ä¿å­˜å‰4ä¸ªæ ·æœ¬
        n_samples = min(4, original.size(0))
        
        fig, axes = plt.subplots(2, n_samples, figsize=(n_samples * 3, 6))
        if n_samples == 1:
            axes = axes.reshape(2, 1)
        
        for i in range(n_samples):
            # åŸå›¾
            axes[0, i].imshow(original[i].cpu().detach().permute(1, 2, 0).numpy())
            axes[0, i].set_title(f'Original {i+1}')
            axes[0, i].axis('off')

            # é‡å»ºå›¾
            axes[1, i].imshow(reconstructed[i].cpu().detach().permute(1, 2, 0).numpy())
            axes[1, i].set_title(f'Reconstructed {i+1}')
            axes[1, i].axis('off')
        
        plt.tight_layout()
        plt.savefig(sample_dir / f"epoch_{epoch:03d}_batch_{batch_idx:04d}.png", dpi=150, bbox_inches='tight')
        plt.close()
    
    def evaluate(self, dataloader):
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()
        
        total_psnr = 0
        total_ssim = 0
        num_samples = 0
        
        with torch.no_grad():
            for batch in tqdm(dataloader, desc="Evaluating"):
                if isinstance(batch, (list, tuple)) and len(batch) == 2:
                    images, _ = batch
                else:
                    images = batch
                
                images = images.to(self.device)
                
                outputs = self.model(images, return_dict=True)
                reconstructed = outputs.sample
                
                # åå½’ä¸€åŒ–åˆ°[0,1]
                images_eval = (images * 0.5 + 0.5).clamp(0, 1)
                reconstructed_eval = (reconstructed * 0.5 + 0.5).clamp(0, 1)
                
                # è®¡ç®—æŒ‡æ ‡
                for i in range(images.size(0)):
                    psnr = calculate_psnr(images_eval[i], reconstructed_eval[i])
                    ssim = calculate_ssim(images_eval[i], reconstructed_eval[i])
                    
                    total_psnr += psnr
                    total_ssim += ssim
                    num_samples += 1
        
        avg_psnr = total_psnr / num_samples
        avg_ssim = total_ssim / num_samples
        
        return {'psnr': avg_psnr, 'ssim': avg_ssim}
    
    def save_model(self, epoch, is_best=False):
        """ä¿å­˜æ¨¡å‹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'args': self.args,
        }
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        checkpoint_path = self.output_dir / f"checkpoint_epoch_{epoch:03d}.pth"
        torch.save(checkpoint, checkpoint_path)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = self.output_dir / "best_model.pth"
            torch.save(checkpoint, best_path)
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_path = self.output_dir / "final_model"
        final_path.mkdir(exist_ok=True)
        self.model.save_pretrained(final_path)
        print(f"ğŸ’¾ ä¿å­˜æ¨¡å‹: {final_path}")
    
    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        print(f"\nğŸ¯ å¼€å§‹VQ-VAEè®­ç»ƒ...")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        dataloader = self._create_dataloader()
        
        best_psnr = 0
        
        for epoch in range(self.args.num_epochs):
            # è®­ç»ƒ
            train_metrics = self.train_epoch(dataloader, epoch)
            
            print(f"\nEpoch {epoch+1}/{self.args.num_epochs}:")
            print(f"  è®­ç»ƒæŸå¤±: {train_metrics['total_loss']:.4f}")
            print(f"  é‡å»ºæŸå¤±: {train_metrics['recon_loss']:.4f}")
            print(f"  VQæŸå¤±: {train_metrics['vq_loss']:.4f}")
            
            # è¯„ä¼°
            if (epoch + 1) % self.args.eval_interval == 0:
                eval_metrics = self.evaluate(dataloader)
                print(f"  PSNR: {eval_metrics['psnr']:.2f} dB")
                print(f"  SSIM: {eval_metrics['ssim']:.4f}")
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                is_best = eval_metrics['psnr'] > best_psnr
                if is_best:
                    best_psnr = eval_metrics['psnr']
                
                self.save_model(epoch, is_best)
            
            # æ˜¾ç¤ºç æœ¬ä½¿ç”¨æƒ…å†µ
            if (epoch + 1) % self.args.codebook_monitor_interval == 0:
                stats = self.model.get_codebook_stats()
                print(f"  ğŸ“Š ç æœ¬ä½¿ç”¨ç‡: {stats['usage_rate']:.3f} ({stats['active_codes']}/{stats['total_codes']})")
                print(f"  ğŸ“ˆ ä½¿ç”¨ç†µ: {stats['usage_entropy']:.3f}")

                # åç¼©è­¦å‘Š
                if stats['usage_rate'] < 0.1:
                    print(f"  âš ï¸ è­¦å‘Š: ç æœ¬ä½¿ç”¨ç‡è¿‡ä½ï¼Œå¯èƒ½å‘ç”Ÿåç¼©!")
                elif stats['usage_rate'] < 0.3:
                    print(f"  âš ï¸ æ³¨æ„: ç æœ¬ä½¿ç”¨ç‡è¾ƒä½")
                else:
                    print(f"  âœ… ç æœ¬ä½¿ç”¨ç‡æ­£å¸¸")

                # ä¿å­˜ç æœ¬ä½¿ç”¨å›¾
                usage_plot_path = self.output_dir / f"codebook_usage_epoch_{epoch+1:03d}.png"
                self.model.plot_codebook_usage(str(usage_plot_path))

            # æŸå¤±è¶‹åŠ¿åˆ†æ
            if hasattr(self, 'loss_history'):
                self.loss_history.append(train_metrics['total_loss'])
                if len(self.loss_history) >= 3:
                    recent_trend = self.loss_history[-3:]
                    if all(recent_trend[i] < recent_trend[i+1] for i in range(len(recent_trend)-1)):
                        print(f"  âš ï¸ è­¦å‘Š: æŸå¤±è¿ç»­ä¸Šå‡ {recent_trend}")
            else:
                self.loss_history = [train_metrics['total_loss']]
        
        print(f"\nâœ… VQ-VAEè®­ç»ƒå®Œæˆ!")
        print(f"   æœ€ä½³PSNR: {best_psnr:.2f} dB")
        print(f"   æ¨¡å‹ä¿å­˜åœ¨: {self.output_dir}")

def main():
    parser = argparse.ArgumentParser(description="Train VQ-VAE for Micro-Doppler Images")
    
    # æ•°æ®å‚æ•°
    parser.add_argument("--data_dir", type=str, required=True, help="æ•°æ®é›†ç›®å½•")
    parser.add_argument("--output_dir", type=str, default="outputs/vqvae", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--resolution", type=int, default=128, help="å›¾åƒåˆ†è¾¨ç‡")
    parser.add_argument("--interpolation", type=str, default="lanczos",
                       choices=["lanczos", "bicubic", "bilinear", "antialias"],
                       help="å›¾åƒç¼©æ”¾æ’å€¼æ–¹æ³•")
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument("--codebook_size", type=int, default=1024, help="ç æœ¬å¤§å°")
    parser.add_argument("--commitment_cost", type=float, default=0.25, help="CommitmentæŸå¤±æƒé‡")
    parser.add_argument("--ema_decay", type=float, default=0.99, help="EMAè¡°å‡ç‡")
    parser.add_argument("--restart_threshold", type=float, default=1.0, help="ç æœ¬é‡ç½®é˜ˆå€¼")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--batch_size", type=int, default=16, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--num_epochs", type=int, default=100, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--learning_rate", type=float, default=1e-4, help="å­¦ä¹ ç‡")
    parser.add_argument("--weight_decay", type=float, default=1e-4, help="æƒé‡è¡°å‡")
    parser.add_argument("--max_grad_norm", type=float, default=1.0, help="æ¢¯åº¦è£å‰ª")
    
    # ç³»ç»Ÿå‚æ•°
    parser.add_argument("--num_workers", type=int, default=4, help="æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°")
    parser.add_argument("--sample_interval", type=int, default=500, help="æ ·æœ¬ä¿å­˜é—´éš”")
    parser.add_argument("--eval_interval", type=int, default=5, help="è¯„ä¼°é—´éš”")
    parser.add_argument("--codebook_monitor_interval", type=int, default=1, help="ç æœ¬ç›‘æ§é—´éš”")
    
    args = parser.parse_args()
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    trainer = VQVAETrainer(args)
    trainer.train()

if __name__ == "__main__":
    main()
