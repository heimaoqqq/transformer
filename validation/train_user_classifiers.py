#!/usr/bin/env python3
"""
è®­ç»ƒç”¨æˆ·éªŒè¯åˆ†ç±»å™¨
ä¸ºæ¯ä¸ªç”¨æˆ·è®­ç»ƒç‹¬ç«‹çš„ResNet-18äºŒåˆ†ç±»å™¨
"""

import os
import sys
import argparse
import json
from pathlib import Path
from typing import List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))

from validation.user_classifier import UserValidationSystem

def find_user_data_directories(data_root: str) -> dict:
    """
    æŸ¥æ‰¾ç”¨æˆ·æ•°æ®ç›®å½•
    
    Args:
        data_root: æ•°æ®æ ¹ç›®å½•
        
    Returns:
        ç”¨æˆ·IDåˆ°ç›®å½•è·¯å¾„çš„æ˜ å°„
    """
    data_root = Path(data_root)
    user_dirs = {}
    
    print(f"ğŸ” åœ¨ {data_root} ä¸­æŸ¥æ‰¾ç”¨æˆ·æ•°æ®...")

    # æŸ¥æ‰¾ç”¨æˆ·ç›®å½• (æ”¯æŒå¤šç§æ ¼å¼: user_01, user_1, ID_1, 1)
    for user_dir in data_root.iterdir():
        if user_dir.is_dir():
            dir_name = user_dir.name
            user_id = None

            try:
                if dir_name.startswith('user_'):
                    user_id = int(dir_name.split('_')[1])
                elif dir_name.startswith('ID_'):
                    user_id = int(dir_name.split('_')[1])
                elif dir_name.isdigit():
                    user_id = int(dir_name)

                if user_id is not None:
                    user_dirs[user_id] = str(user_dir)
                    print(f"  æ‰¾åˆ°ç”¨æˆ· {user_id}: {user_dir}")
                else:
                    print(f"  è·³è¿‡æ— æ•ˆç›®å½•: {user_dir}")

            except (IndexError, ValueError):
                print(f"  è·³è¿‡æ— æ•ˆç›®å½•: {user_dir}")
    
    print(f"âœ… æ‰¾åˆ° {len(user_dirs)} ä¸ªç”¨æˆ·ç›®å½•")
    return user_dirs

def train_classifiers_for_users(
    user_ids: List[int],
    real_data_root: str,
    output_dir: str,
    epochs: int = 20,
    batch_size: int = 32,
    learning_rate: float = 1e-3,
    max_samples_per_class: int = 500
):
    """
    ä¸ºæŒ‡å®šç”¨æˆ·è®­ç»ƒåˆ†ç±»å™¨
    
    Args:
        user_ids: è¦è®­ç»ƒçš„ç”¨æˆ·IDåˆ—è¡¨
        real_data_root: çœŸå®æ•°æ®æ ¹ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        epochs: è®­ç»ƒè½®æ•°
        batch_size: æ‰¹æ¬¡å¤§å°
        learning_rate: å­¦ä¹ ç‡
        max_samples_per_class: æ¯ç±»æœ€å¤§æ ·æœ¬æ•°
    """
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # æŸ¥æ‰¾ç”¨æˆ·æ•°æ®ç›®å½•
    user_dirs = find_user_data_directories(real_data_root)
    
    # æ£€æŸ¥æŒ‡å®šç”¨æˆ·æ˜¯å¦å­˜åœ¨
    missing_users = [uid for uid in user_ids if uid not in user_dirs]
    if missing_users:
        print(f"âŒ ä»¥ä¸‹ç”¨æˆ·æ•°æ®ä¸å­˜åœ¨: {missing_users}")
        return
    
    # åˆå§‹åŒ–éªŒè¯ç³»ç»Ÿ
    validation_system = UserValidationSystem()
    
    # ä¸ºæ¯ä¸ªç”¨æˆ·è®­ç»ƒåˆ†ç±»å™¨
    all_histories = {}
    
    for user_id in user_ids:
        print(f"\n{'='*50}")
        print(f"ğŸ¯ å¼€å§‹è®­ç»ƒç”¨æˆ· {user_id} çš„åˆ†ç±»å™¨")
        print(f"{'='*50}")
        
        # å‡†å¤‡è¯¥ç”¨æˆ·çš„æ•°æ®
        user_real_dir = user_dirs[user_id]
        other_user_dirs = [user_dirs[uid] for uid in user_dirs.keys() if uid != user_id]
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        image_paths, labels = validation_system.prepare_user_data(
            user_id=user_id,
            real_images_dir=user_real_dir,
            other_users_dirs=other_user_dirs,
            max_samples_per_class=max_samples_per_class
        )
        
        if len(image_paths) == 0:
            print(f"âŒ ç”¨æˆ· {user_id} æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒæ•°æ®ï¼Œè·³è¿‡")
            continue
        
        # æ£€æŸ¥æ•°æ®å¹³è¡¡æ€§
        positive_count = sum(labels)
        negative_count = len(labels) - positive_count
        print(f"  æ•°æ®åˆ†å¸ƒ: æ­£æ ·æœ¬ {positive_count}, è´Ÿæ ·æœ¬ {negative_count}")
        
        if positive_count < 10 or negative_count < 10:
            print(f"âš ï¸  ç”¨æˆ· {user_id} æ•°æ®é‡è¿‡å°‘ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ")
        
        # è®­ç»ƒåˆ†ç±»å™¨
        try:
            history = validation_system.train_user_classifier(
                user_id=user_id,
                image_paths=image_paths,
                labels=labels,
                epochs=epochs,
                batch_size=batch_size,
                learning_rate=learning_rate
            )
            
            all_histories[user_id] = history
            
            # ä¿å­˜åˆ†ç±»å™¨
            classifier_path = output_path / f"user_{user_id:02d}_classifier.pth"
            validation_system.save_classifier(user_id, str(classifier_path))
            
            # ä¿å­˜è®­ç»ƒå†å²
            history_path = output_path / f"user_{user_id:02d}_history.json"
            with open(history_path, 'w') as f:
                json.dump(history, f, indent=2)
            
            # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
            plot_path = output_path / f"user_{user_id:02d}_training.png"
            validation_system.plot_training_history(history, str(plot_path))
            
        except Exception as e:
            print(f"âŒ ç”¨æˆ· {user_id} è®­ç»ƒå¤±è´¥: {e}")
            continue
    
    # ä¿å­˜è®­ç»ƒé…ç½®
    config = {
        'user_ids': user_ids,
        'real_data_root': real_data_root,
        'epochs': epochs,
        'batch_size': batch_size,
        'learning_rate': learning_rate,
        'max_samples_per_class': max_samples_per_class,
        'trained_users': list(all_histories.keys())
    }
    
    config_path = output_path / "training_config.json"
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"âœ… æˆåŠŸè®­ç»ƒ {len(all_histories)} ä¸ªç”¨æˆ·åˆ†ç±»å™¨")

def main():
    parser = argparse.ArgumentParser(description="è®­ç»ƒç”¨æˆ·éªŒè¯åˆ†ç±»å™¨")
    
    # æ•°æ®å‚æ•°
    parser.add_argument("--real_data_root", type=str, required=True, 
                       help="çœŸå®æ•°æ®æ ¹ç›®å½• (åŒ…å«user_01, user_02ç­‰å­ç›®å½•)")
    parser.add_argument("--user_ids", type=int, nargs="+", required=True,
                       help="è¦è®­ç»ƒçš„ç”¨æˆ·IDåˆ—è¡¨")
    parser.add_argument("--output_dir", type=str, default="./user_classifiers",
                       help="è¾“å‡ºç›®å½•")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--epochs", type=int, default=20, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch_size", type=int, default=32, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--learning_rate", type=float, default=1e-3, help="å­¦ä¹ ç‡")
    parser.add_argument("--max_samples_per_class", type=int, default=500,
                       help="æ¯ç±»æœ€å¤§æ ·æœ¬æ•°")
    
    args = parser.parse_args()
    
    print("ğŸ¯ ç”¨æˆ·éªŒè¯åˆ†ç±»å™¨è®­ç»ƒ")
    print("=" * 50)
    print(f"çœŸå®æ•°æ®æ ¹ç›®å½•: {args.real_data_root}")
    print(f"ç”¨æˆ·IDåˆ—è¡¨: {args.user_ids}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"è®­ç»ƒå‚æ•°: epochs={args.epochs}, batch_size={args.batch_size}, lr={args.learning_rate}")
    print("=" * 50)
    
    train_classifiers_for_users(
        user_ids=args.user_ids,
        real_data_root=args.real_data_root,
        output_dir=args.output_dir,
        epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        max_samples_per_class=args.max_samples_per_class
    )

if __name__ == "__main__":
    main()
