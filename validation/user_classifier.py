#!/usr/bin/env python3
"""
ç”¨æˆ·éªŒè¯åˆ†ç±»å™¨
ä½¿ç”¨ResNet-18ä¸ºæ¯ä¸ªç”¨æˆ·è®­ç»ƒç‹¬ç«‹çš„äºŒåˆ†ç±»å™¨
éªŒè¯ç”Ÿæˆå›¾åƒæ˜¯å¦åŒ…å«å¯¹åº”ç”¨æˆ·çš„ç‰¹å¾ä¿¡æ¯
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision.models import resnet18
import numpy as np
from PIL import Image
from pathlib import Path
import json
from typing import List, Tuple, Dict
from tqdm import tqdm
import matplotlib.pyplot as plt
from datetime import datetime

class UserImageDataset(Dataset):
    """ç”¨æˆ·å›¾åƒæ•°æ®é›†"""
    
    def __init__(self, image_paths: List[str], labels: List[int], transform=None):
        """
        Args:
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            labels: æ ‡ç­¾åˆ—è¡¨ (0: è´Ÿæ ·æœ¬, 1: æ­£æ ·æœ¬)
            transform: å›¾åƒå˜æ¢
        """
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
        
        assert len(image_paths) == len(labels), "å›¾åƒæ•°é‡ä¸æ ‡ç­¾æ•°é‡ä¸åŒ¹é…"
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        # åŠ è½½å›¾åƒ
        image_path = self.image_paths[idx]
        try:
            image = Image.open(image_path).convert('RGB')
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½å›¾åƒ {image_path}: {e}")
            # åˆ›å»ºä¸€ä¸ªé»‘è‰²å›¾åƒä½œä¸ºå¤‡ç”¨
            image = Image.new('RGB', (64, 64), (0, 0, 0))
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            image = self.transform(image)
        
        label = self.labels[idx]
        return image, label

class UserClassifier(nn.Module):
    """æ”¹è¿›çš„ç”¨æˆ·åˆ†ç±»å™¨ - ä¸“é—¨é’ˆå¯¹å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾ä¼˜åŒ–"""

    def __init__(self, num_classes=2, pretrained=True, dropout_rate=0.5):
        """
        Args:
            num_classes: åˆ†ç±»æ•°é‡ (2: æ˜¯/ä¸æ˜¯è¯¥ç”¨æˆ·)
            pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
            dropout_rate: Dropoutæ¯”ç‡
        """
        super(UserClassifier, self).__init__()

        # ä½¿ç”¨ResNet-18ä½œä¸ºéª¨å¹²ç½‘ç»œ
        self.backbone = resnet18(pretrained=pretrained)

        # ç§»é™¤åŸå§‹çš„å…¨è¿æ¥å±‚
        in_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()  # ç§»é™¤æœ€åçš„fcå±‚

        # æ·»åŠ æ”¹è¿›çš„åˆ†ç±»å¤´ - æ›´é€‚åˆç»†å¾®ç‰¹å¾è¯†åˆ«
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(in_features, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.5),  # è¾ƒå°çš„dropout
            nn.Linear(256, 64),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.25),  # æ›´å°çš„dropout
            nn.Linear(64, num_classes)
        )

        # åˆå§‹åŒ–åˆ†ç±»å¤´æƒé‡
        self._init_classifier_weights()

    def _init_classifier_weights(self):
        """åˆå§‹åŒ–åˆ†ç±»å¤´æƒé‡"""
        for m in self.classifier.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, x):
        # ç‰¹å¾æå–
        features = self.backbone(x)  # [batch_size, 512]

        # åˆ†ç±»
        output = self.classifier(features)  # [batch_size, num_classes]

        return output

class MicroDopplerCNN(nn.Module):
    """ä¸“é—¨ä¸ºå¾®å¤šæ™®å‹’æ—¶é¢‘å›¾è®¾è®¡çš„è½»é‡çº§CNN"""

    def __init__(self, num_classes=2, dropout_rate=0.5):
        """
        ä¸“é—¨é’ˆå¯¹å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾çš„ç‰¹å¾è®¾è®¡
        å…³æ³¨æ—¶é—´-é¢‘ç‡åŸŸçš„å±€éƒ¨æ¨¡å¼
        """
        super(MicroDopplerCNN, self).__init__()

        # ç‰¹å¾æå–å±‚ - ä¸“é—¨æ•è·æ—¶é¢‘å›¾ç‰¹å¾
        self.features = nn.Sequential(
            # ç¬¬ä¸€ç»„ï¼šæ•è·ç²—ç²’åº¦æ—¶é¢‘ç‰¹å¾
            nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),

            # ç¬¬äºŒç»„ï¼šæ•è·ä¸­ç­‰ç²’åº¦ç‰¹å¾
            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            # ç¬¬ä¸‰ç»„ï¼šæ•è·ç»†ç²’åº¦ç‰¹å¾
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            # ç¬¬å››ç»„ï¼šé«˜çº§ç‰¹å¾
            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((4, 4))  # è‡ªé€‚åº”æ± åŒ–åˆ°å›ºå®šå°ºå¯¸
        )

        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(256 * 4 * 4, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.5),
            nn.Linear(512, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.25),
            nn.Linear(128, num_classes)
        )

        # åˆå§‹åŒ–æƒé‡
        self._init_weights()

    def _init_weights(self):
        """åˆå§‹åŒ–ç½‘ç»œæƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, x):
        # ç‰¹å¾æå–
        features = self.features(x)  # [batch_size, 256, 4, 4]

        # å±•å¹³
        features = features.view(features.size(0), -1)  # [batch_size, 256*4*4]

        # åˆ†ç±»
        output = self.classifier(features)

        return output

class UserValidationSystem:
    """ç”¨æˆ·éªŒè¯ç³»ç»Ÿ"""
    
    def __init__(self, device="auto"):
        """
        Args:
            device: è®¡ç®—è®¾å¤‡
        """
        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
        
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # æ”¹è¿›çš„å›¾åƒå˜æ¢ - é’ˆå¯¹å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾ä¼˜åŒ–
        self.transform = transforms.Compose([
            transforms.Resize((128, 128), interpolation=transforms.InterpolationMode.LANCZOS),
            transforms.ToTensor(),
            # ä½¿ç”¨ImageNetæ ‡å‡†åŒ– - å³ä½¿å¯¹äºå¾®å¤šæ™®å‹’æ•°æ®ä¹Ÿæœ‰åŠ©äºç‰¹å¾å­¦ä¹ 
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            # æ·»åŠ è½»å¾®çš„æ•°æ®å¢å¼ºä»¥æé«˜æ³›åŒ–èƒ½åŠ›
        ])

        # éªŒè¯æ—¶çš„å˜æ¢ (ä¸åŒ…å«æ•°æ®å¢å¼º)
        self.val_transform = transforms.Compose([
            transforms.Resize((128, 128), interpolation=transforms.InterpolationMode.LANCZOS),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])
        
        # å­˜å‚¨è®­ç»ƒå¥½çš„åˆ†ç±»å™¨
        self.classifiers = {}
    
    def prepare_user_data(self, user_id: int, real_images_dir: str, other_users_dirs: List[str], 
                         max_samples_per_class: int = 500) -> Tuple[List[str], List[int]]:
        """
        ä¸ºæŒ‡å®šç”¨æˆ·å‡†å¤‡è®­ç»ƒæ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
            real_images_dir: è¯¥ç”¨æˆ·çœŸå®å›¾åƒç›®å½•
            other_users_dirs: å…¶ä»–ç”¨æˆ·å›¾åƒç›®å½•åˆ—è¡¨
            max_samples_per_class: æ¯ç±»æœ€å¤§æ ·æœ¬æ•°
            
        Returns:
            (image_paths, labels): å›¾åƒè·¯å¾„åˆ—è¡¨å’Œæ ‡ç­¾åˆ—è¡¨
        """
        image_paths = []
        labels = []
        
        # æ­£æ ·æœ¬: è¯¥ç”¨æˆ·çš„çœŸå®å›¾åƒ
        real_dir = Path(real_images_dir)
        if real_dir.exists():
            real_images = list(real_dir.glob("*.png")) + list(real_dir.glob("*.jpg"))
            real_images = real_images[:max_samples_per_class]  # é™åˆ¶æ ·æœ¬æ•°é‡
            
            image_paths.extend([str(p) for p in real_images])
            labels.extend([1] * len(real_images))
            
            print(f"  ç”¨æˆ· {user_id} æ­£æ ·æœ¬: {len(real_images)} å¼ ")
        else:
            print(f"  è­¦å‘Š: ç”¨æˆ· {user_id} çœŸå®å›¾åƒç›®å½•ä¸å­˜åœ¨: {real_dir}")
        
        # è´Ÿæ ·æœ¬: å…¶ä»–ç”¨æˆ·çš„å›¾åƒ
        negative_count = 0
        for other_dir in other_users_dirs:
            if negative_count >= max_samples_per_class:
                break
                
            other_path = Path(other_dir)
            if other_path.exists():
                other_images = list(other_path.glob("*.png")) + list(other_path.glob("*.jpg"))
                
                # é™åˆ¶æ¯ä¸ªå…¶ä»–ç”¨æˆ·çš„æ ·æœ¬æ•°é‡ï¼Œç¡®ä¿è´Ÿæ ·æœ¬æ€»æ•°ä¸è¶…è¿‡é™åˆ¶
                remaining_slots = max_samples_per_class - negative_count
                other_images = other_images[:remaining_slots]
                
                image_paths.extend([str(p) for p in other_images])
                labels.extend([0] * len(other_images))
                
                negative_count += len(other_images)
        
        print(f"  ç”¨æˆ· {user_id} è´Ÿæ ·æœ¬: {negative_count} å¼ ")
        print(f"  ç”¨æˆ· {user_id} æ€»æ ·æœ¬: {len(image_paths)} å¼ ")
        
        return image_paths, labels
    
    def train_user_classifier(self, user_id: int, image_paths: List[str], labels: List[int],
                            epochs: int = 20, batch_size: int = 32, learning_rate: float = 1e-3,
                            validation_split: float = 0.2, model_type: str = "resnet") -> Dict:
        """
        è®­ç»ƒç”¨æˆ·åˆ†ç±»å™¨
        
        Args:
            user_id: ç”¨æˆ·ID
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            labels: æ ‡ç­¾åˆ—è¡¨
            epochs: è®­ç»ƒè½®æ•°
            batch_size: æ‰¹æ¬¡å¤§å°
            learning_rate: å­¦ä¹ ç‡
            validation_split: éªŒè¯é›†æ¯”ä¾‹
            
        Returns:
            è®­ç»ƒå†å²å­—å…¸
        """
        print(f"\nğŸ¯ è®­ç»ƒç”¨æˆ· {user_id} çš„åˆ†ç±»å™¨...")
        
        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        total_samples = len(image_paths)
        val_size = int(total_samples * validation_split)
        train_size = total_samples - val_size
        
        # éšæœºæ‰“ä¹±æ•°æ®
        indices = np.random.permutation(total_samples)
        train_indices = indices[:train_size]
        val_indices = indices[train_size:]
        
        train_paths = [image_paths[i] for i in train_indices]
        train_labels = [labels[i] for i in train_indices]
        val_paths = [image_paths[i] for i in val_indices]
        val_labels = [labels[i] for i in val_indices]
        
        # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
        train_dataset = UserImageDataset(train_paths, train_labels, self.transform)
        val_dataset = UserImageDataset(val_paths, val_labels, self.transform)
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
        
        # åˆ›å»ºæ¨¡å‹ - æ”¯æŒä¸åŒæ¶æ„é€‰æ‹©
        if model_type.lower() == "resnet":
            model = UserClassifier(num_classes=2, pretrained=True, dropout_rate=0.5)
            print(f"  ğŸ—ï¸  ä½¿ç”¨ResNet-18åˆ†ç±»å™¨ (é€‚åˆé€šç”¨å›¾åƒ)")
        elif model_type.lower() == "microdoppler":
            model = MicroDopplerCNN(num_classes=2, dropout_rate=0.5)
            print(f"  ğŸ—ï¸  ä½¿ç”¨å¾®å¤šæ™®å‹’ä¸“ç”¨CNN (ä¸“é—¨ä¼˜åŒ–)")
        else:
            print(f"  âš ï¸  æœªçŸ¥æ¨¡å‹ç±»å‹ {model_type}ï¼Œä½¿ç”¨é»˜è®¤ResNet-18")
            model = UserClassifier(num_classes=2, pretrained=True, dropout_rate=0.5)

        model.to(self.device)

        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"  ğŸ“Š æ¨¡å‹å‚æ•°: æ€»è®¡ {total_params:,}, å¯è®­ç»ƒ {trainable_params:,}")
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
        
        # è®­ç»ƒå†å²
        history = {
            'train_loss': [],
            'train_acc': [],
            'val_loss': [],
            'val_acc': []
        }
        
        best_val_acc = 0.0
        best_model_state = None
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            train_loss = 0.0
            train_correct = 0
            train_total = 0
            
            for images, labels_batch in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}"):
                images = images.to(self.device)
                labels_batch = labels_batch.to(self.device)
                
                optimizer.zero_grad()
                outputs = model(images)
                loss = criterion(outputs, labels_batch)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                train_total += labels_batch.size(0)
                train_correct += (predicted == labels_batch).sum().item()
            
            # éªŒè¯é˜¶æ®µ
            model.eval()
            val_loss = 0.0
            val_correct = 0
            val_total = 0
            
            with torch.no_grad():
                for images, labels_batch in val_loader:
                    images = images.to(self.device)
                    labels_batch = labels_batch.to(self.device)
                    
                    outputs = model(images)
                    loss = criterion(outputs, labels_batch)
                    
                    val_loss += loss.item()
                    _, predicted = torch.max(outputs.data, 1)
                    val_total += labels_batch.size(0)
                    val_correct += (predicted == labels_batch).sum().item()
            
            # è®¡ç®—å¹³å‡æŒ‡æ ‡
            train_loss_avg = train_loss / len(train_loader)
            train_acc = train_correct / train_total
            val_loss_avg = val_loss / len(val_loader)
            val_acc = val_correct / val_total
            
            # ä¿å­˜å†å²
            history['train_loss'].append(train_loss_avg)
            history['train_acc'].append(train_acc)
            history['val_loss'].append(val_loss_avg)
            history['val_acc'].append(val_acc)
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                best_model_state = model.state_dict().copy()
            
            # æ›´æ–°å­¦ä¹ ç‡
            scheduler.step()
            
            print(f"  Epoch {epoch+1}: Train Acc: {train_acc:.3f}, Val Acc: {val_acc:.3f}, Val Loss: {val_loss_avg:.4f}")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        if best_model_state is not None:
            model.load_state_dict(best_model_state)
        
        # ä¿å­˜åˆ†ç±»å™¨
        self.classifiers[user_id] = model
        
        print(f"âœ… ç”¨æˆ· {user_id} åˆ†ç±»å™¨è®­ç»ƒå®Œæˆï¼Œæœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.3f}")

        return history

    def validate_generated_images(self, user_id: int, generated_images_dir: str,
                                confidence_threshold: float = 0.8) -> Dict:
        """
        éªŒè¯ç”Ÿæˆå›¾åƒæ˜¯å¦åŒ…å«ç”¨æˆ·ç‰¹å¾

        Args:
            user_id: ç”¨æˆ·ID
            generated_images_dir: ç”Ÿæˆå›¾åƒç›®å½•
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼ (>0.8ç®—æˆåŠŸ)

        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        if user_id not in self.classifiers:
            raise ValueError(f"ç”¨æˆ· {user_id} çš„åˆ†ç±»å™¨å°šæœªè®­ç»ƒ")

        print(f"\nğŸ” éªŒè¯ç”¨æˆ· {user_id} çš„ç”Ÿæˆå›¾åƒ...")

        # åŠ è½½ç”Ÿæˆå›¾åƒ
        gen_dir = Path(generated_images_dir)
        if not gen_dir.exists():
            raise FileNotFoundError(f"ç”Ÿæˆå›¾åƒç›®å½•ä¸å­˜åœ¨: {gen_dir}")

        image_files = list(gen_dir.glob("*.png")) + list(gen_dir.glob("*.jpg"))
        if not image_files:
            print(f"  è­¦å‘Š: æœªæ‰¾åˆ°ç”Ÿæˆå›¾åƒ")
            return {}

        print(f"  æ‰¾åˆ° {len(image_files)} å¼ ç”Ÿæˆå›¾åƒ")

        # å‡†å¤‡æ•°æ®
        image_paths = [str(p) for p in image_files]
        dataset = UserImageDataset(image_paths, [0] * len(image_paths), self.transform)
        dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)

        # è·å–åˆ†ç±»å™¨
        model = self.classifiers[user_id]
        model.eval()

        # é¢„æµ‹
        all_predictions = []
        all_confidences = []

        with torch.no_grad():
            for images, _ in tqdm(dataloader, desc="éªŒè¯ç”Ÿæˆå›¾åƒ"):
                images = images.to(self.device)
                outputs = model(images)

                # è®¡ç®—æ¦‚ç‡å’Œé¢„æµ‹
                probabilities = torch.softmax(outputs, dim=1)
                confidences = probabilities[:, 1]  # æ­£ç±»(è¯¥ç”¨æˆ·)çš„ç½®ä¿¡åº¦
                predictions = (confidences > confidence_threshold).int()

                all_predictions.extend(predictions.cpu().numpy())
                all_confidences.extend(confidences.cpu().numpy())

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        all_predictions = np.array(all_predictions)
        all_confidences = np.array(all_confidences)

        success_count = np.sum(all_predictions)
        success_rate = success_count / len(all_predictions)
        avg_confidence = np.mean(all_confidences)
        max_confidence = np.max(all_confidences)
        min_confidence = np.min(all_confidences)

        results = {
            'user_id': user_id,
            'total_images': len(image_files),
            'success_count': int(success_count),
            'success_rate': float(success_rate),
            'avg_confidence': float(avg_confidence),
            'max_confidence': float(max_confidence),
            'min_confidence': float(min_confidence),
            'confidence_threshold': confidence_threshold,
            'individual_confidences': all_confidences.tolist(),
            'individual_predictions': all_predictions.tolist(),
            'image_files': [p.name for p in image_files]
        }

        print(f"  éªŒè¯ç»“æœ:")
        print(f"    æˆåŠŸå›¾åƒ: {success_count}/{len(image_files)} ({success_rate:.1%})")
        print(f"    å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        print(f"    ç½®ä¿¡åº¦èŒƒå›´: [{min_confidence:.3f}, {max_confidence:.3f}]")

        return results

    def save_classifier(self, user_id: int, save_path: str):
        """ä¿å­˜åˆ†ç±»å™¨"""
        if user_id not in self.classifiers:
            raise ValueError(f"ç”¨æˆ· {user_id} çš„åˆ†ç±»å™¨å°šæœªè®­ç»ƒ")

        save_path = Path(save_path)
        save_path.parent.mkdir(parents=True, exist_ok=True)

        torch.save({
            'model_state_dict': self.classifiers[user_id].state_dict(),
            'user_id': user_id,
            'model_class': 'UserClassifier'
        }, save_path)

        print(f"âœ… ç”¨æˆ· {user_id} åˆ†ç±»å™¨å·²ä¿å­˜åˆ°: {save_path}")

    def load_classifier(self, user_id: int, load_path: str):
        """åŠ è½½åˆ†ç±»å™¨"""
        checkpoint = torch.load(load_path, map_location=self.device)

        model = UserClassifier(num_classes=2, pretrained=False)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        model.eval()

        self.classifiers[user_id] = model

        print(f"âœ… ç”¨æˆ· {user_id} åˆ†ç±»å™¨å·²ä» {load_path} åŠ è½½")

    def plot_training_history(self, history: Dict, save_path: str = None):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

        # æŸå¤±æ›²çº¿
        ax1.plot(history['train_loss'], label='Train Loss')
        ax1.plot(history['val_loss'], label='Val Loss')
        ax1.set_title('Training and Validation Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)

        # å‡†ç¡®ç‡æ›²çº¿
        ax2.plot(history['train_acc'], label='Train Acc')
        ax2.plot(history['val_acc'], label='Val Acc')
        ax2.set_title('Training and Validation Accuracy')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.legend()
        ax2.grid(True)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"ğŸ“Š è®­ç»ƒå†å²å›¾å·²ä¿å­˜åˆ°: {save_path}")

        plt.show()

    def generate_validation_report(self, results_list: List[Dict], save_path: str = None) -> str:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        report = []
        report.append("# ç”¨æˆ·ç”Ÿæˆå›¾åƒéªŒè¯æŠ¥å‘Š\n")
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report.append(f"ç½®ä¿¡åº¦é˜ˆå€¼: {results_list[0]['confidence_threshold']}\n\n")

        # æ€»ä½“ç»Ÿè®¡
        total_images = sum(r['total_images'] for r in results_list)
        total_success = sum(r['success_count'] for r in results_list)
        overall_success_rate = total_success / total_images if total_images > 0 else 0

        report.append("## æ€»ä½“ç»Ÿè®¡\n")
        report.append(f"- æ€»å›¾åƒæ•°: {total_images}\n")
        report.append(f"- æˆåŠŸå›¾åƒæ•°: {total_success}\n")
        report.append(f"- æ€»ä½“æˆåŠŸç‡: {overall_success_rate:.1%}\n\n")

        # å„ç”¨æˆ·è¯¦ç»†ç»“æœ
        report.append("## å„ç”¨æˆ·è¯¦ç»†ç»“æœ\n")
        for result in results_list:
            user_id = result['user_id']
            report.append(f"### ç”¨æˆ· {user_id}\n")
            report.append(f"- å›¾åƒæ•°é‡: {result['total_images']}\n")
            report.append(f"- æˆåŠŸæ•°é‡: {result['success_count']}\n")
            report.append(f"- æˆåŠŸç‡: {result['success_rate']:.1%}\n")
            report.append(f"- å¹³å‡ç½®ä¿¡åº¦: {result['avg_confidence']:.3f}\n")
            report.append(f"- ç½®ä¿¡åº¦èŒƒå›´: [{result['min_confidence']:.3f}, {result['max_confidence']:.3f}]\n\n")

        report_text = "".join(report)

        if save_path:
            with open(save_path, 'w', encoding='utf-8') as f:
                f.write(report_text)
            print(f"ğŸ“„ éªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {save_path}")

        return report_text
