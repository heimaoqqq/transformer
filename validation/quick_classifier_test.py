#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•ä¿®å¤åçš„åˆ†ç±»å™¨
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
from PIL import Image

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))

from validation.user_classifier import UserValidationSystem

def quick_test_classifier():
    """å¿«é€Ÿæµ‹è¯•åˆ†ç±»å™¨çš„åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ”§ å¿«é€Ÿæµ‹è¯•ä¿®å¤åçš„åˆ†ç±»å™¨")
    
    # åˆ›å»ºéªŒè¯ç³»ç»Ÿ
    validation_system = UserValidationSystem()
    
    # æµ‹è¯•åˆ†ç±»å™¨åˆ›å»º
    print("\n1ï¸âƒ£ æµ‹è¯•åˆ†ç±»å™¨åˆ›å»º:")
    try:
        from validation.user_classifier import UserClassifier
        model = UserClassifier(num_classes=2, pretrained=True)
        print("âœ… åˆ†ç±»å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•forward
        test_input = torch.randn(1, 3, 128, 128)  # ä¿®å¤åçš„å°ºå¯¸
        with torch.no_grad():
            output = model(test_input)
            print(f"âœ… Forwardæµ‹è¯•æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
            
            # æµ‹è¯•softmax
            probabilities = torch.softmax(output, dim=1)
            print(f"âœ… Softmaxæµ‹è¯•æˆåŠŸï¼Œæ¦‚ç‡: {probabilities}")
            
    except Exception as e:
        print(f"âŒ åˆ†ç±»å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•å›¾åƒé¢„å¤„ç†
    print("\n2ï¸âƒ£ æµ‹è¯•å›¾åƒé¢„å¤„ç†:")
    try:
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = Image.new('RGB', (256, 256), (128, 128, 128))
        
        # åº”ç”¨å˜æ¢
        transformed = validation_system.transform(test_image)
        print(f"âœ… å›¾åƒå˜æ¢æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {transformed.shape}")
        print(f"âœ… åƒç´ å€¼èŒƒå›´: [{transformed.min():.3f}, {transformed.max():.3f}]")
        
        # æµ‹è¯•æ‰¹å¤„ç†
        batch = transformed.unsqueeze(0)
        with torch.no_grad():
            output = model(batch)
            probabilities = torch.softmax(output, dim=1)
            confidence = probabilities[0, 1].item()
            print(f"âœ… æ‰¹å¤„ç†æµ‹è¯•æˆåŠŸï¼Œç½®ä¿¡åº¦: {confidence:.3f}")
            
    except Exception as e:
        print(f"âŒ å›¾åƒé¢„å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    print("\nâœ… æ‰€æœ‰åŸºæœ¬æµ‹è¯•é€šè¿‡ï¼")
    return True

def test_on_real_data(data_dir: str, user_id: int = 1):
    """åœ¨çœŸå®æ•°æ®ä¸Šæµ‹è¯•"""
    print(f"\n3ï¸âƒ£ åœ¨çœŸå®æ•°æ®ä¸Šæµ‹è¯• (ç”¨æˆ· {user_id}):")
    
    data_path = Path(data_dir)
    user_dir = data_path / f"ID_{user_id}"
    
    if not user_dir.exists():
        print(f"âŒ ç”¨æˆ·ç›®å½•ä¸å­˜åœ¨: {user_dir}")
        return False
    
    # æ‰¾åˆ°ä¸€äº›å›¾åƒ
    image_files = list(user_dir.glob("*.png")) + list(user_dir.glob("*.jpg"))
    if not image_files:
        print(f"âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return False
    
    print(f"âœ… æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
    
    # åˆ›å»ºéªŒè¯ç³»ç»Ÿå’Œæ¨¡å‹
    validation_system = UserValidationSystem()
    from validation.user_classifier import UserClassifier
    model = UserClassifier(num_classes=2, pretrained=True)
    model.eval()
    
    # æµ‹è¯•å‰å‡ å¼ å›¾åƒ
    test_images = image_files[:5]
    confidences = []
    
    for img_path in test_images:
        try:
            # åŠ è½½å›¾åƒ
            image = Image.open(img_path).convert('RGB')
            print(f"  åŸå§‹å›¾åƒå°ºå¯¸: {image.size}")
            
            # é¢„å¤„ç†
            image_tensor = validation_system.transform(image).unsqueeze(0)
            print(f"  é¢„å¤„ç†åå½¢çŠ¶: {image_tensor.shape}")
            
            # é¢„æµ‹
            with torch.no_grad():
                output = model(image_tensor)
                probabilities = torch.softmax(output, dim=1)
                confidence = probabilities[0, 1].item()
                confidences.append(confidence)
                
                print(f"  {img_path.name}: ç½®ä¿¡åº¦ {confidence:.3f}")
                
        except Exception as e:
            print(f"  âŒ å¤„ç† {img_path.name} å¤±è´¥: {e}")
    
    if confidences:
        avg_conf = np.mean(confidences)
        print(f"\nğŸ“Š çœŸå®æ•°æ®æµ‹è¯•ç»“æœ:")
        print(f"  æµ‹è¯•å›¾åƒæ•°: {len(confidences)}")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {avg_conf:.3f}")
        print(f"  ç½®ä¿¡åº¦èŒƒå›´: [{min(confidences):.3f}, {max(confidences):.3f}]")
        
        # æ³¨æ„ï¼šè¿™æ˜¯æœªè®­ç»ƒçš„æ¨¡å‹ï¼Œæ‰€ä»¥ç½®ä¿¡åº¦åº”è¯¥æ¥è¿‘éšæœº(0.5)
        if 0.3 < avg_conf < 0.7:
            print(f"  âœ… æœªè®­ç»ƒæ¨¡å‹çš„éšæœºè¾“å‡ºæ­£å¸¸")
        else:
            print(f"  âš ï¸  æœªè®­ç»ƒæ¨¡å‹çš„è¾“å‡ºå¼‚å¸¸")
    
    return True

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="å¿«é€Ÿæµ‹è¯•åˆ†ç±»å™¨ä¿®å¤")
    parser.add_argument("--data_dir", type=str, help="æ•°æ®ç›®å½• (å¯é€‰)")
    parser.add_argument("--user_id", type=int, default=1, help="æµ‹è¯•ç”¨æˆ·ID")
    
    args = parser.parse_args()
    
    print("ğŸ”§ åˆ†ç±»å™¨ä¿®å¤éªŒè¯")
    print("=" * 40)
    
    # åŸºæœ¬åŠŸèƒ½æµ‹è¯•
    basic_ok = quick_test_classifier()
    
    # çœŸå®æ•°æ®æµ‹è¯• (å¦‚æœæä¾›)
    if args.data_dir and basic_ok:
        real_data_ok = test_on_real_data(args.data_dir, args.user_id)
    
    print("\n" + "=" * 40)
    if basic_ok:
        print("âœ… åˆ†ç±»å™¨ä¿®å¤éªŒè¯é€šè¿‡")
        print("ğŸ’¡ ä¸»è¦ä¿®å¤:")
        print("   1. ç®€åŒ–äº†forwardå‡½æ•°")
        print("   2. ä¿®å¤äº†å›¾åƒå°ºå¯¸ (64â†’128)")
        print("   3. ç§»é™¤äº†ä¸ä¸€è‡´çš„å½’ä¸€åŒ–")
        print("\nğŸš€ ç°åœ¨å¯ä»¥é‡æ–°è®­ç»ƒåˆ†ç±»å™¨äº†")
    else:
        print("âŒ åˆ†ç±»å™¨ä¿®å¤éªŒè¯å¤±è´¥")

if __name__ == "__main__":
    main()
