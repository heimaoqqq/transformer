#!/usr/bin/env python3
"""
ç”¨æˆ·IDæ˜ å°„ä¸€è‡´æ€§æ£€æŸ¥å·¥å…·
ç¡®ä¿è®­ç»ƒã€æ¨ç†ã€éªŒè¯æ—¶ä½¿ç”¨ç›¸åŒçš„ç”¨æˆ·IDæ˜ å°„
"""

import os
import sys
from pathlib import Path
from typing import Dict, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))

def get_training_mapping(data_dir: str) -> Dict[int, int]:
    """è·å–è®­ç»ƒæ—¶çš„ç”¨æˆ·IDæ˜ å°„ï¼ˆæ¨¡æ‹Ÿdata_loader.pyçš„é€»è¾‘ï¼‰"""
    print("ğŸ‹ï¸  è·å–è®­ç»ƒæ—¶çš„ç”¨æˆ·IDæ˜ å°„...")
    
    data_path = Path(data_dir)
    users = []
    
    for user_dir in data_path.iterdir():
        if user_dir.is_dir() and user_dir.name.startswith('ID_'):
            try:
                user_id = int(user_dir.name.split('_')[1])
                users.append(user_id)
            except ValueError:
                continue
    
    users = sorted(users)  # è®­ç»ƒæ—¶çš„æ’åºé€»è¾‘
    user_to_idx = {user_id: idx for idx, user_id in enumerate(users)}
    
    print(f"  æ‰¾åˆ°ç”¨æˆ·: {users}")
    print(f"  æ˜ å°„: {user_to_idx}")
    
    return user_to_idx

def get_inference_mapping(data_dir: str) -> Dict[int, int]:
    """è·å–æ¨ç†æ—¶çš„ç”¨æˆ·IDæ˜ å°„ï¼ˆæ¨¡æ‹Ÿgenerate_training_style.pyçš„é€»è¾‘ï¼‰"""
    print("\nğŸ¨ è·å–æ¨ç†æ—¶çš„ç”¨æˆ·IDæ˜ å°„...")
    
    data_path = Path(data_dir)
    all_users = []
    
    for user_dir in data_path.iterdir():
        if user_dir.is_dir() and user_dir.name.startswith('ID_'):
            try:
                user_id = int(user_dir.name.split('_')[1])
                all_users.append(user_id)
            except ValueError:
                continue
    
    all_users = sorted(all_users)  # æ¨ç†æ—¶çš„æ’åºé€»è¾‘
    user_id_to_idx = {user_id: idx for idx, user_id in enumerate(all_users)}
    
    print(f"  æ‰¾åˆ°ç”¨æˆ·: {all_users}")
    print(f"  æ˜ å°„: {user_id_to_idx}")
    
    return user_id_to_idx

def get_validation_mapping(data_dir: str) -> Dict[int, int]:
    """è·å–éªŒè¯æ—¶çš„ç”¨æˆ·IDæ˜ å°„ï¼ˆæ¨¡æ‹Ÿvalidation_pipeline.pyçš„é€»è¾‘ï¼‰"""
    print("\nğŸ” è·å–éªŒè¯æ—¶çš„ç”¨æˆ·IDæ˜ å°„...")
    
    data_path = Path(data_dir)
    all_users = []
    
    for user_dir in data_path.iterdir():
        if user_dir.is_dir() and user_dir.name.startswith('ID_'):
            try:
                user_id = int(user_dir.name.split('_')[1])
                all_users.append(user_id)
            except ValueError:
                continue
    
    all_users = sorted(all_users)  # éªŒè¯æ—¶çš„æ’åºé€»è¾‘
    user_id_mapping = {user_id: idx for idx, user_id in enumerate(all_users)}
    
    print(f"  æ‰¾åˆ°ç”¨æˆ·: {all_users}")
    print(f"  æ˜ å°„: {user_id_mapping}")
    
    return user_id_mapping

def check_mapping_consistency(data_dir: str) -> bool:
    """æ£€æŸ¥æ‰€æœ‰æ˜ å°„æ˜¯å¦ä¸€è‡´"""
    print("ğŸ” æ£€æŸ¥ç”¨æˆ·IDæ˜ å°„ä¸€è‡´æ€§")
    print("=" * 60)
    
    # è·å–å„ä¸ªé˜¶æ®µçš„æ˜ å°„
    training_mapping = get_training_mapping(data_dir)
    inference_mapping = get_inference_mapping(data_dir)
    validation_mapping = get_validation_mapping(data_dir)
    
    # æ£€æŸ¥ä¸€è‡´æ€§
    print(f"\nğŸ“Š ä¸€è‡´æ€§æ£€æŸ¥:")
    
    # æ£€æŸ¥ç”¨æˆ·åˆ—è¡¨æ˜¯å¦ç›¸åŒ
    training_users = set(training_mapping.keys())
    inference_users = set(inference_mapping.keys())
    validation_users = set(validation_mapping.keys())
    
    if training_users == inference_users == validation_users:
        print(f"  âœ… ç”¨æˆ·åˆ—è¡¨ä¸€è‡´: {sorted(training_users)}")
    else:
        print(f"  âŒ ç”¨æˆ·åˆ—è¡¨ä¸ä¸€è‡´!")
        print(f"    è®­ç»ƒ: {sorted(training_users)}")
        print(f"    æ¨ç†: {sorted(inference_users)}")
        print(f"    éªŒè¯: {sorted(validation_users)}")
        return False
    
    # æ£€æŸ¥æ˜ å°„æ˜¯å¦ç›¸åŒ
    if training_mapping == inference_mapping == validation_mapping:
        print(f"  âœ… ç”¨æˆ·IDæ˜ å°„å®Œå…¨ä¸€è‡´")
        
        # æ˜¾ç¤ºæ˜ å°„è¯¦æƒ…
        print(f"\nğŸ“‹ ç»Ÿä¸€çš„ç”¨æˆ·IDæ˜ å°„:")
        for user_id in sorted(training_mapping.keys()):
            idx = training_mapping[user_id]
            print(f"    ç”¨æˆ· {user_id:2d} â†’ ç´¢å¼• {idx:2d}")
        
        return True
    else:
        print(f"  âŒ ç”¨æˆ·IDæ˜ å°„ä¸ä¸€è‡´!")
        
        # æ‰¾å‡ºä¸ä¸€è‡´çš„åœ°æ–¹
        all_users = sorted(training_users)
        print(f"\nğŸ” è¯¦ç»†å¯¹æ¯”:")
        print(f"{'ç”¨æˆ·ID':<8} {'è®­ç»ƒ':<8} {'æ¨ç†':<8} {'éªŒè¯':<8} {'çŠ¶æ€'}")
        print("-" * 50)
        
        for user_id in all_users:
            train_idx = training_mapping.get(user_id, "N/A")
            infer_idx = inference_mapping.get(user_id, "N/A")
            valid_idx = validation_mapping.get(user_id, "N/A")
            
            if train_idx == infer_idx == valid_idx:
                status = "âœ…"
            else:
                status = "âŒ"
            
            print(f"{user_id:<8} {train_idx:<8} {infer_idx:<8} {valid_idx:<8} {status}")
        
        return False

def check_data_directory_structure(data_dir: str):
    """æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„"""
    print(f"\nğŸ“ æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„: {data_dir}")
    
    data_path = Path(data_dir)
    if not data_path.exists():
        print(f"  âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_path}")
        return
    
    # åˆ—å‡ºæ‰€æœ‰å­ç›®å½•
    subdirs = [d for d in data_path.iterdir() if d.is_dir()]
    print(f"  ğŸ“‚ æ‰¾åˆ° {len(subdirs)} ä¸ªå­ç›®å½•:")
    
    user_dirs = []
    other_dirs = []
    
    for subdir in subdirs:
        if subdir.name.startswith('ID_'):
            try:
                user_id = int(subdir.name.split('_')[1])
                user_dirs.append((user_id, subdir))
            except ValueError:
                other_dirs.append(subdir)
        else:
            other_dirs.append(subdir)
    
    # æ˜¾ç¤ºç”¨æˆ·ç›®å½•
    user_dirs.sort(key=lambda x: x[0])
    print(f"  ğŸ‘¥ ç”¨æˆ·ç›®å½• ({len(user_dirs)} ä¸ª):")
    for user_id, user_dir in user_dirs:
        # ç»Ÿè®¡å›¾åƒæ•°é‡
        image_files = list(user_dir.glob("*.png")) + list(user_dir.glob("*.jpg"))
        print(f"    ID_{user_id:2d} â†’ {len(image_files):3d} å¼ å›¾åƒ")
    
    # æ˜¾ç¤ºå…¶ä»–ç›®å½•
    if other_dirs:
        print(f"  ğŸ“ å…¶ä»–ç›®å½• ({len(other_dirs)} ä¸ª):")
        for other_dir in other_dirs[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"    {other_dir.name}")
        if len(other_dirs) > 5:
            print(f"    ... è¿˜æœ‰ {len(other_dirs) - 5} ä¸ª")

def test_specific_user_mapping(data_dir: str, test_user_ids: List[int]):
    """æµ‹è¯•ç‰¹å®šç”¨æˆ·çš„æ˜ å°„"""
    print(f"\nğŸ¯ æµ‹è¯•ç‰¹å®šç”¨æˆ·æ˜ å°„: {test_user_ids}")
    
    # è·å–æ˜ å°„
    mapping = get_training_mapping(data_dir)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    for user_id in test_user_ids:
        if user_id in mapping:
            idx = mapping[user_id]
            print(f"  ç”¨æˆ· {user_id:2d} â†’ ç´¢å¼• {idx:2d} âœ…")
        else:
            print(f"  ç”¨æˆ· {user_id:2d} â†’ æœªæ‰¾åˆ° âŒ")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="æ£€æŸ¥ç”¨æˆ·IDæ˜ å°„ä¸€è‡´æ€§")
    parser.add_argument("--data_dir", type=str, required=True, help="æ•°æ®æ ¹ç›®å½•")
    parser.add_argument("--test_users", type=int, nargs='+', default=[1, 2, 3],
                       help="æµ‹è¯•ç‰¹å®šç”¨æˆ·ID")
    
    args = parser.parse_args()
    
    print("ğŸ” ç”¨æˆ·IDæ˜ å°„ä¸€è‡´æ€§æ£€æŸ¥å·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„
    check_data_directory_structure(args.data_dir)
    
    # æ£€æŸ¥æ˜ å°„ä¸€è‡´æ€§
    is_consistent = check_mapping_consistency(args.data_dir)
    
    # æµ‹è¯•ç‰¹å®šç”¨æˆ·
    test_specific_user_mapping(args.data_dir, args.test_users)
    
    # æ€»ç»“
    print(f"\n" + "=" * 60)
    if is_consistent:
        print("ğŸ‰ ç”¨æˆ·IDæ˜ å°„å®Œå…¨ä¸€è‡´ï¼Œæ²¡æœ‰é—®é¢˜ï¼")
        print("ğŸ’¡ å¦‚æœéªŒè¯ä»ç„¶å¤±è´¥ï¼Œé—®é¢˜å¯èƒ½åœ¨å…¶ä»–åœ°æ–¹")
    else:
        print("ğŸš¨ å‘ç°ç”¨æˆ·IDæ˜ å°„ä¸ä¸€è‡´ï¼")
        print("ğŸ’¡ è¿™å¾ˆå¯èƒ½æ˜¯éªŒè¯å¤±è´¥çš„æ ¹æœ¬åŸå› ")
        print("ğŸ”§ å»ºè®®æ£€æŸ¥å¹¶ç»Ÿä¸€æ‰€æœ‰ç»„ä»¶çš„æ˜ å°„é€»è¾‘")

if __name__ == "__main__":
    main()
