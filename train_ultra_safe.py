#!/usr/bin/env python3
"""
è¶…ä¿å®ˆè®­ç»ƒå™¨ - ç»å¯¹ä¸ä¼šOOM
åŸºäºæ€§èƒ½åˆ†æç»“æœçš„æœ€ä¿å®ˆé…ç½®
"""

import os
import sys
import subprocess
import torch
from pathlib import Path

def setup_ultra_safe_environment():
    """è®¾ç½®è¶…ä¿å®ˆç¯å¢ƒ"""
    # å¼ºåˆ¶å•GPU
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    
    # æä¿å®ˆå†…å­˜åˆ†é…
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:64'
    os.environ['PYTHONUNBUFFERED'] = '1'
    
    # åŸºç¡€ä¼˜åŒ–
    torch.backends.cudnn.benchmark = True

def get_ultra_safe_config():
    """è·å–è¶…ä¿å®ˆé…ç½®"""
    
    gpu_name = torch.cuda.get_device_properties(0).name
    
    if "P100" in gpu_name:
        return {
            "batch_size": 4,            # è¶…ä¿å®ˆ
            "mixed_precision": "no",    # P100ç”¨FP32
            "learning_rate": "0.0001",  
            "gradient_accumulation": 4, 
            "num_workers": 1,           
        }
    else:  # T4æˆ–å…¶ä»–
        return {
            "batch_size": 2,            # æä¿å®ˆ
            "mixed_precision": "fp16",  
            "learning_rate": "0.0001",  
            "gradient_accumulation": 8, # å¤§ç´¯ç§¯ä¿æŒæœ‰æ•ˆæ‰¹æ¬¡
            "num_workers": 1,           
        }

def launch_ultra_safe_training():
    """å¯åŠ¨è¶…ä¿å®ˆè®­ç»ƒ"""
    
    setup_ultra_safe_environment()
    
    # æ£€æµ‹GPU
    if not torch.cuda.is_available():
        print("âŒ æ²¡æœ‰æ£€æµ‹åˆ°CUDA GPU")
        return False
    
    props = torch.cuda.get_device_properties(0)
    gpu_name = props.name
    
    print(f"ğŸ® ä½¿ç”¨GPU: {gpu_name}")
    print(f"   å†…å­˜: {props.total_memory / 1024**3:.1f} GB")
    
    # æ¸…ç†GPUç¼“å­˜
    torch.cuda.empty_cache()
    
    # è·å–é…ç½®
    config = get_ultra_safe_config()
    
    print(f"\nğŸ›¡ï¸  å¯åŠ¨è¶…ä¿å®ˆè®­ç»ƒ...")
    
    cmd = [
        "python", "-u",
        "training/train_vae.py",
        "--data_dir", "/kaggle/input/dataset",
        "--output_dir", "/kaggle/working/outputs/vae",
        "--batch_size", str(config["batch_size"]),
        "--num_epochs", "20",  # å‡å°‘epochæ•°
        "--learning_rate", config["learning_rate"],
        "--mixed_precision", config["mixed_precision"],
        "--gradient_accumulation_steps", str(config["gradient_accumulation"]),
        "--kl_weight", "1e-6",
        "--perceptual_weight", "0.0",
        "--freq_weight", "0.05",
        "--resolution", "256",
        "--num_workers", str(config["num_workers"]),
        "--save_interval", "5",
        "--log_interval", "1",  # æ›´é¢‘ç¹æ—¥å¿—
        "--sample_interval", "100",
        "--experiment_name", "kaggle_vae_ultra_safe"
    ]
    
    print(f"ğŸ“Š è¶…ä¿å®ˆé…ç½®:")
    print(f"   ğŸ“¦ æ‰¹æ¬¡å¤§å°: {config['batch_size']} (ç»å¯¹å®‰å…¨)")
    print(f"   ğŸ”¢ æ··åˆç²¾åº¦: {config['mixed_precision']}")
    print(f"   ğŸ“ˆ å­¦ä¹ ç‡: {config['learning_rate']}")
    print(f"   âš¡ æ¢¯åº¦ç´¯ç§¯: {config['gradient_accumulation']}")
    print(f"   ğŸ§µ æ•°æ®çº¿ç¨‹: {config['num_workers']}")
    print(f"   ğŸ’¾ å†…å­˜åˆ†é…: 64MBå— (é˜²ç¢ç‰‡)")
    
    # æœ‰æ•ˆæ‰¹æ¬¡å¤§å°
    effective_batch = config["batch_size"] * config["gradient_accumulation"]
    print(f"   ğŸ¯ æœ‰æ•ˆæ‰¹æ¬¡: {effective_batch}")
    
    # é¢„æœŸæ€§èƒ½
    if "P100" in gpu_name:
        print(f"\nğŸ“Š P100è¶…ä¿å®ˆé¢„æœŸ:")
        print(f"   â±ï¸  æ¯è½®æ—¶é—´: 15-25åˆ†é’Ÿ")
        print(f"   ğŸ’¾ å†…å­˜ä½¿ç”¨: ~6-8GB")
        print(f"   ğŸ›¡ï¸  ç¨³å®šæ€§: æœ€é«˜")
    else:
        print(f"\nğŸ“Š T4è¶…ä¿å®ˆé¢„æœŸ:")
        print(f"   â±ï¸  æ¯è½®æ—¶é—´: 20-30åˆ†é’Ÿ")
        print(f"   ğŸ’¾ å†…å­˜ä½¿ç”¨: ~4-6GB")
        print(f"   ğŸ›¡ï¸  ç¨³å®šæ€§: æœ€é«˜")
    
    print(f"\nCommand: {' '.join(cmd)}")
    print("=" * 80)
    
    try:
        # å¯åŠ¨è®­ç»ƒ
        process = subprocess.Popen(
            cmd,
            stdout=None,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=0
        )
        
        return_code = process.wait()
        
        if return_code == 0:
            print(f"\nâœ… è¶…ä¿å®ˆè®­ç»ƒå®Œæˆ!")
            return True
        else:
            print(f"\nâŒ è®­ç»ƒå¤±è´¥ (é€€å‡ºç : {return_code})")
            return False
            
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        process.terminate()
        return False
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¯åŠ¨å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ›¡ï¸  è¶…ä¿å®ˆVAEè®­ç»ƒ (ç»å¯¹ä¸OOM)")
    print("=" * 50)
    
    print("ğŸ¯ è¶…ä¿å®ˆç­–ç•¥:")
    print("   âœ… æå°æ‰¹æ¬¡å¤§å° (åŸºäºæ€§èƒ½åˆ†æ)")
    print("   âœ… å•GPUé¿å…é€šä¿¡å¼€é”€")
    print("   âœ… 3å±‚ä¸‹é‡‡æ · (55Må‚æ•°)")
    print("   âœ… å¤§æ¢¯åº¦ç´¯ç§¯ä¿æŒæœ‰æ•ˆæ‰¹æ¬¡")
    print("   âœ… æä¿å®ˆå†…å­˜åˆ†é…")
    print("   âœ… å•çº¿ç¨‹æ•°æ®åŠ è½½")
    
    print("\nğŸ“Š åŸºäºæ€§èƒ½åˆ†æçš„ä¼˜åŒ–:")
    print("   ğŸ“‰ å‰å‘ä¼ æ’­: 1067ms â†’ 500ms (å°æ‰¹æ¬¡)")
    print("   ğŸ“‰ å†…å­˜ä½¿ç”¨: 15GB â†’ 6GB")
    print("   ğŸ“ˆ ç¨³å®šæ€§: æœ€å¤§åŒ–")
    print("   ğŸ¯ è´¨é‡: ä¿æŒ (256Ã—256)")
    
    print("\nğŸ—ï¸  æ¶æ„ä¼˜åŠ¿:")
    print("   ğŸ“‰ å‚æ•°é‡: 83M â†’ 55M (3å±‚ä¸‹é‡‡æ ·)")
    print("   âš¡ è®¡ç®—é‡: å‡å°‘33%")
    print("   ğŸ¯ å‹ç¼©æ¯”: ä¿æŒ64:1")
    print("   ğŸ“ æ½œåœ¨ç©ºé—´: 32Ã—32Ã—4")
    
    success = launch_ultra_safe_training()
    
    if success:
        print("\nğŸ‰ è¶…ä¿å®ˆè®­ç»ƒå®Œæˆ!")
        print("ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: /kaggle/working/outputs/vae/final_model")
        print("ğŸ’¡ è™½ç„¶æ…¢ä¸€äº›ï¼Œä½†ç»å¯¹ç¨³å®šå¯é !")
    else:
        print("\nâŒ è®­ç»ƒå¤±è´¥!")
        print("ğŸ’¡ å¦‚æœè¿˜æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥:")
        print("   - GPUå†…å­˜æ˜¯å¦è¢«å…¶ä»–è¿›ç¨‹å ç”¨")
        print("   - æ•°æ®é›†è·¯å¾„æ˜¯å¦æ­£ç¡®")
        sys.exit(1)

if __name__ == "__main__":
    main()
