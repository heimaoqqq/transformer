#!/usr/bin/env python3
"""
å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æ•°æ®å¢å¹¿é¡¹ç›® - æµç¨‹æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯æ•´ä¸ªè®­ç»ƒå’Œç”Ÿæˆæµç¨‹
"""

import os
import torch
import numpy as np
from PIL import Image
from pathlib import Path
import argparse
import shutil

def create_test_data(output_dir: str, num_users: int = 5, images_per_user: int = 10):
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    print(f"Creating test data in {output_dir}...")
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # ä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»ºç›®å½•å’Œå›¾åƒ (ä½¿ç”¨ID_æ ¼å¼)
    for user_id in range(1, num_users + 1):
        user_dir = output_path / f"ID_{user_id}"
        user_dir.mkdir(exist_ok=True)
        
        for img_id in range(images_per_user):
            # åˆ›å»ºæ¨¡æ‹Ÿçš„å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾
            # ä½¿ç”¨ä¸åŒçš„é¢œè‰²æ¨¡å¼æ¥æ¨¡æ‹Ÿä¸åŒç”¨æˆ·çš„ç‰¹å¾
            img = create_mock_micro_doppler(user_id, img_id)
            img.save(user_dir / f"image_{img_id:03d}.png")
    
    print(f"Created test data for {num_users} users, {images_per_user} images each")

def create_mock_micro_doppler(user_id: int, img_id: int, size: int = 256):
    """åˆ›å»ºæ¨¡æ‹Ÿçš„å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾"""
    # åˆ›å»ºåŸºç¡€å™ªå£°
    np.random.seed(user_id * 1000 + img_id)
    
    # æ—¶é—´è½´å’Œé¢‘ç‡è½´
    t = np.linspace(0, 2*np.pi, size)
    f = np.linspace(0, 2*np.pi, size)
    T, F = np.meshgrid(t, f)
    
    # ä¸ºä¸åŒç”¨æˆ·åˆ›å»ºä¸åŒçš„é¢‘ç‡æ¨¡å¼
    # æ¨¡æ‹Ÿæ­¥æ€çš„å‘¨æœŸæ€§ç‰¹å¾
    base_freq = 0.5 + user_id * 0.1  # ä¸åŒç”¨æˆ·çš„åŸºç¡€é¢‘ç‡
    
    # ä¸»è¦ä¿¡å·ï¼šæ­¥æ€åŸºé¢‘
    signal1 = np.sin(base_freq * T) * np.exp(-0.1 * F)
    
    # è°æ³¢ï¼šæ­¥æ€çš„å€é¢‘æˆåˆ†
    signal2 = 0.5 * np.sin(2 * base_freq * T) * np.exp(-0.2 * F)
    signal3 = 0.3 * np.sin(3 * base_freq * T) * np.exp(-0.3 * F)
    
    # å¾®å¤šæ™®å‹’è°ƒåˆ¶ï¼šè‚¢ä½“æ‘†åŠ¨
    modulation = 0.2 * np.sin(4 * base_freq * T + user_id) * np.cos(0.5 * F)
    
    # ç»„åˆä¿¡å·
    combined = signal1 + signal2 + signal3 + modulation
    
    # æ·»åŠ å™ªå£°
    noise = 0.1 * np.random.randn(size, size)
    combined += noise
    
    # å½’ä¸€åŒ–åˆ°[0, 1]
    combined = (combined - combined.min()) / (combined.max() - combined.min())
    
    # è½¬æ¢ä¸ºRGBå›¾åƒ (æ¨¡æ‹Ÿæ—¶é¢‘å›¾çš„ä¼ªå½©è‰²)
    # ä½¿ç”¨jet colormapçš„ç®€åŒ–ç‰ˆæœ¬
    rgb_image = np.zeros((size, size, 3))
    
    # çº¢è‰²é€šé“ï¼šé«˜é¢‘æˆåˆ†
    rgb_image[:, :, 0] = combined
    
    # ç»¿è‰²é€šé“ï¼šä¸­é¢‘æˆåˆ†
    rgb_image[:, :, 1] = np.roll(combined, size//4, axis=1)
    
    # è“è‰²é€šé“ï¼šä½é¢‘æˆåˆ†
    rgb_image[:, :, 2] = np.roll(combined, size//2, axis=1)
    
    # è½¬æ¢ä¸ºPILå›¾åƒ
    rgb_image = (rgb_image * 255).astype(np.uint8)
    return Image.fromarray(rgb_image)

def test_data_loader():
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
    print("\n=== Testing Data Loader ===")
    
    try:
        from utils.data_loader import MicroDopplerDataset, MicroDopplerDataModule
        from torch.utils.data import DataLoader
        
        # æµ‹è¯•æ•°æ®é›†
        dataset = MicroDopplerDataset(
            data_dir="./test_data",
            resolution=256,
            augment=True
        )
        
        print(f"Dataset size: {len(dataset)}")
        print(f"Number of users: {dataset.num_users}")
        print(f"User mapping: {dataset.user_to_idx}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½å™¨
        dataloader = DataLoader(dataset, batch_size=2, shuffle=True)
        
        for batch in dataloader:
            print(f"Batch image shape: {batch['image'].shape}")
            print(f"Batch user IDs: {batch['user_id']}")
            print(f"Batch user indices: {batch['user_idx']}")
            break
        
        print("âœ… Data loader test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Data loader test failed: {e}")
        return False

def test_vae_model():
    """æµ‹è¯•VAEæ¨¡å‹"""
    print("\n=== Testing VAE Model ===")
    
    try:
        from diffusers import AutoencoderKL
        
        # åˆ›å»ºVAEæ¨¡å‹
        vae = AutoencoderKL(
            in_channels=3,
            out_channels=3,
            latent_channels=4,
            sample_size=256,
        )
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_input = torch.randn(1, 3, 256, 256)
        
        with torch.no_grad():
            # ç¼–ç 
            posterior = vae.encode(test_input).latent_dist
            latents = posterior.sample()
            
            # è§£ç 
            reconstruction = vae.decode(latents).sample
        
        print(f"Input shape: {test_input.shape}")
        print(f"Latent shape: {latents.shape}")
        print(f"Reconstruction shape: {reconstruction.shape}")
        
        print("âœ… VAE model test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ VAE model test failed: {e}")
        return False

def test_unet_model():
    """æµ‹è¯•UNetæ¨¡å‹"""
    print("\n=== Testing UNet Model ===")
    
    try:
        from diffusers import UNet2DConditionModel
        
        # åˆ›å»ºUNetæ¨¡å‹
        unet = UNet2DConditionModel(
            sample_size=32,  # 256/8 = 32
            in_channels=4,
            out_channels=4,
            cross_attention_dim=768,
        )
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_latents = torch.randn(1, 4, 32, 32)
        test_timesteps = torch.randint(0, 1000, (1,))
        test_conditions = torch.randn(1, 1, 768)
        
        with torch.no_grad():
            noise_pred = unet(
                test_latents,
                test_timesteps,
                encoder_hidden_states=test_conditions
            ).sample
        
        print(f"Input latents shape: {test_latents.shape}")
        print(f"Timesteps shape: {test_timesteps.shape}")
        print(f"Conditions shape: {test_conditions.shape}")
        print(f"Noise prediction shape: {noise_pred.shape}")
        
        print("âœ… UNet model test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ UNet model test failed: {e}")
        return False

def test_condition_encoder():
    """æµ‹è¯•æ¡ä»¶ç¼–ç å™¨"""
    print("\n=== Testing Condition Encoder ===")
    
    try:
        import sys
        sys.path.append('./training')
        from train_diffusion import UserConditionEncoder
        
        # åˆ›å»ºæ¡ä»¶ç¼–ç å™¨
        encoder = UserConditionEncoder(num_users=5, embed_dim=768)
        
        # æµ‹è¯•ç¼–ç 
        user_indices = torch.tensor([0, 1, 2, 3, 4])
        
        with torch.no_grad():
            embeddings = encoder(user_indices)
        
        print(f"User indices: {user_indices}")
        print(f"Embeddings shape: {embeddings.shape}")
        
        print("âœ… Condition encoder test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Condition encoder test failed: {e}")
        return False

def test_metrics():
    """æµ‹è¯•è¯„ä¼°æŒ‡æ ‡"""
    print("\n=== Testing Metrics ===")
    
    try:
        from utils.metrics import MetricsCalculator
        
        # åˆ›å»ºè®¡ç®—å™¨
        calculator = MetricsCalculator(device="cpu")
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        img1 = np.random.randint(0, 256, (256, 256, 3), dtype=np.uint8)
        img2 = np.random.randint(0, 256, (256, 256, 3), dtype=np.uint8)
        
        # æµ‹è¯•PSNRå’ŒSSIM
        psnr_value = calculator.calculate_psnr(img1, img2)
        ssim_value = calculator.calculate_ssim(img1, img2)
        
        print(f"PSNR: {psnr_value:.2f}")
        print(f"SSIM: {ssim_value:.4f}")
        
        # æµ‹è¯•é¢‘åŸŸç›¸ä¼¼æ€§
        freq_sim = calculator.calculate_frequency_similarity(img1, img2)
        print(f"Frequency similarity: {freq_sim:.4f}")
        
        print("âœ… Metrics test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Metrics test failed: {e}")
        return False

def run_full_test():
    """è¿è¡Œå®Œæ•´æµ‹è¯•"""
    print("ğŸš€ Starting Full Pipeline Test")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    create_test_data("./test_data", num_users=5, images_per_user=5)
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("Data Loader", test_data_loader),
        ("VAE Model", test_vae_model),
        ("UNet Model", test_unet_model),
        ("Condition Encoder", test_condition_encoder),
        ("Metrics", test_metrics),
    ]
    
    results = []
    for test_name, test_func in tests:
        success = test_func()
        results.append((test_name, success))
    
    # æ€»ç»“ç»“æœ
    print("\n" + "=" * 50)
    print("ğŸ“Š Test Results Summary")
    print("=" * 50)
    
    passed = 0
    for test_name, success in results:
        status = "âœ… PASSED" if success else "âŒ FAILED"
        print(f"{test_name:20} {status}")
        if success:
            passed += 1
    
    print(f"\nOverall: {passed}/{len(tests)} tests passed")
    
    if passed == len(tests):
        print("ğŸ‰ All tests passed! Your environment is ready for training.")
    else:
        print("âš ï¸  Some tests failed. Please check the error messages above.")
    
    # æ¸…ç†æµ‹è¯•æ•°æ®
    if Path("./test_data").exists():
        shutil.rmtree("./test_data")
        print("\nğŸ§¹ Cleaned up test data")

def main():
    parser = argparse.ArgumentParser(description="Test Micro-Doppler Pipeline")
    parser.add_argument("--test", type=str, choices=[
        "all", "data", "vae", "unet", "encoder", "metrics"
    ], default="all", help="Which test to run")
    
    args = parser.parse_args()
    
    if args.test == "all":
        run_full_test()
    elif args.test == "data":
        create_test_data("./test_data")
        test_data_loader()
    elif args.test == "vae":
        test_vae_model()
    elif args.test == "unet":
        test_unet_model()
    elif args.test == "encoder":
        test_condition_encoder()
    elif args.test == "metrics":
        test_metrics()

if __name__ == "__main__":
    main()
