#!/usr/bin/env python3
"""
VQ-VAE + Transformer ç»Ÿä¸€ç¯å¢ƒé…ç½®è„šæœ¬
åŸºäºdiffuserså®˜æ–¹é…ç½®ï¼Œæ”¯æŒVQ-VAEå’ŒTransformerè®­ç»ƒ

åŠŸèƒ½ï¼š
- å®‰è£…PyTorch GPUç‰ˆæœ¬
- ä½¿ç”¨diffuserså®˜æ–¹é…ç½®: diffusers[torch] + transformers
- æ™ºèƒ½é€‰æ‹©diffusersç‰ˆæœ¬ï¼Œç¡®ä¿VQModelå¯ç”¨
- å®‰è£…å®Œæ•´çš„å›¾åƒå¤„ç†å’Œåºåˆ—ç”Ÿæˆä¾èµ–
- æµ‹è¯•VQ-VAEå’ŒTransformerç¯å¢ƒå®Œæ•´æ€§

ç‰ˆæœ¬ç­–ç•¥ï¼š
- éµå¾ªdiffuserså®˜æ–¹é…ç½®: pip install diffusers[torch] transformers
- æ™ºèƒ½é™çº§: å¦‚æœVQModelä¸å¯ç”¨ï¼Œè‡ªåŠ¨é™çº§åˆ°ç¨³å®šç‰ˆæœ¬
- ç»Ÿä¸€ç®¡ç†: ä¸€ä¸ªç¯å¢ƒæ”¯æŒä¸¤ä¸ªè®­ç»ƒé˜¶æ®µ
"""

import os
import sys
import subprocess
import importlib
from pathlib import Path

def run_command(cmd, description="", timeout=600):
    """è¿è¡Œå‘½ä»¤å¹¶è¿”å›æ˜¯å¦æˆåŠŸ"""
    print(f"ğŸ”„ {description}")
    print(f"   å‘½ä»¤: {cmd}")
    
    try:
        result = subprocess.run(
            cmd, 
            shell=True, 
            capture_output=True, 
            text=True, 
            timeout=timeout
        )
        
        if result.returncode == 0:
            print(f"âœ… {description} æˆåŠŸ")
            return True
        else:
            print(f"âŒ {description} å¤±è´¥")
            if result.stderr:
                print(f"   é”™è¯¯: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        print(f"â° {description} è¶…æ—¶ (>{timeout}ç§’)")
        return False
    except Exception as e:
        print(f"âŒ {description} å¼‚å¸¸: {e}")
        return False

def install_pytorch():
    """å®‰è£…PyTorch GPUç‰ˆæœ¬"""
    print("ğŸ”¥ å®‰è£…GPUç‰ˆæœ¬PyTorch...")
    
    pytorch_options = [
        ("pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121", "PyTorchæ–¹æ¡ˆ 1"),
        ("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121", "PyTorchæ–¹æ¡ˆ 2"),
        ("pip install torch torchvision torchaudio", "PyTorchæ–¹æ¡ˆ 3 (CPUå¤‡ç”¨)"),
    ]
    
    for cmd, description in pytorch_options:
        print(f"\nå°è¯•{description}...")
        if run_command(cmd, f"ğŸ”„ {description}"):
            print(f"âœ… å®‰è£…PyTorch GPUç‰ˆæœ¬ æˆåŠŸ")
            return True
    
    print("âŒ æ‰€æœ‰PyTorchå®‰è£…æ–¹æ¡ˆéƒ½å¤±è´¥")
    return False

def test_vqmodel_import():
    """æµ‹è¯•VQModelå¯¼å…¥æ˜¯å¦æˆåŠŸ"""
    try:
        import subprocess
        import sys
        
        # åœ¨å­è¿›ç¨‹ä¸­æµ‹è¯•å¯¼å…¥ï¼Œé¿å…å½±å“å½“å‰è¿›ç¨‹
        result = subprocess.run([
            sys.executable, "-c", 
            "from diffusers.models.autoencoders.vq_model import VQModel; print('SUCCESS')"
        ], capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0 and "SUCCESS" in result.stdout:
            return True
        else:
            print(f"VQModelå¯¼å…¥å¤±è´¥: {result.stderr}")
            return False
    except Exception as e:
        print(f"VQModelæµ‹è¯•å¼‚å¸¸: {e}")
        return False

def install_core_dependencies():
    """å®‰è£…æ ¸å¿ƒä¾èµ– - ä¿®å¤huggingface_hubç‰ˆæœ¬å†²çª"""
    print("ğŸ¨ å®‰è£…æ ¸å¿ƒä¾èµ–...")
    print("ğŸ’¡ ä¿®å¤huggingface_hubç‰ˆæœ¬å†²çªå’ŒOfflineModeIsEnabledé”™è¯¯")

    # å…ˆå¸è½½å¯èƒ½å†²çªçš„åŒ…
    run_command("pip uninstall -y huggingface_hub diffusers transformers accelerate torchao", "æ¸…ç†å¯èƒ½å†²çªçš„åŒ…")
    run_command("pip cache purge", "æ¸…ç†pipç¼“å­˜")

    # ç¬¬ä¸€æ­¥ï¼šä¿®å¤NumPyç‰ˆæœ¬å†²çª
    print("\nğŸ”§ ä¿®å¤NumPyç‰ˆæœ¬å†²çª...")
    if not run_command("pip install 'numpy<2.0' --force-reinstall", "é™çº§NumPyåˆ°1.xç‰ˆæœ¬"):
        return False

    # ç¬¬äºŒæ­¥ï¼šå®‰è£…å…¼å®¹çš„huggingface_hubç‰ˆæœ¬ï¼ˆå…³é”®ä¿®å¤ï¼‰
    print("\nğŸ”§ å®‰è£…å…¼å®¹çš„huggingface_hubç‰ˆæœ¬...")
    if not run_command("pip install 'huggingface_hub==0.20.3'", "å®‰è£… huggingface_hub 0.20.3 (ä¿®å¤OfflineModeIsEnabled)"):
        return False

    # ç¬¬ä¸‰æ­¥ï¼šå®‰è£…å…¼å®¹çš„transformersç‰ˆæœ¬
    print("\nğŸ”§ å®‰è£…å…¼å®¹çš„transformersç‰ˆæœ¬...")
    if not run_command("pip install 'transformers==4.36.2'", "å®‰è£… transformers 4.36.2 (å…¼å®¹ç‰ˆæœ¬)"):
        return False

    # ç¬¬å››æ­¥ï¼šå®‰è£…å…¼å®¹çš„diffusersç‰ˆæœ¬
    print("\nğŸ”§ å®‰è£…å…¼å®¹çš„diffusersç‰ˆæœ¬...")
    if not run_command("pip install 'diffusers==0.25.1'", "å®‰è£… diffusers 0.25.1 (ç¨³å®šç‰ˆæœ¬)"):
        return False

    # ç¬¬äº”æ­¥ï¼šå®‰è£…accelerate
    print("\nğŸ”§ å®‰è£…accelerate...")
    if not run_command("pip install 'accelerate==0.25.0'", "å®‰è£… accelerate 0.25.0"):
        return False

    # ç¬¬å…­æ­¥ï¼šæµ‹è¯•VQModelæ˜¯å¦å¯ç”¨
    print("\nğŸ§ª æµ‹è¯•VQModelå¯ç”¨æ€§...")
    vqmodel_available = test_vqmodel_import()

    if not vqmodel_available:
        print("\nâš ï¸ å°è¯•æ›´æ—©çš„ç¨³å®šç‰ˆæœ¬...")
        # å°è¯•æ›´æ—©çš„ç‰ˆæœ¬ç»„åˆ
        stable_versions = [
            ("diffusers==0.24.0", "transformers==4.35.2", "huggingface_hub==0.19.4"),
            ("diffusers==0.23.1", "transformers==4.34.1", "huggingface_hub==0.18.0"),
        ]

        for diffusers_ver, transformers_ver, hub_ver in stable_versions:
            print(f"\nå°è¯•ç‰ˆæœ¬ç»„åˆ: {diffusers_ver}, {transformers_ver}, {hub_ver}")
            if (run_command(f"pip install {hub_ver} --force-reinstall", f"å®‰è£… {hub_ver}") and
                run_command(f"pip install {transformers_ver} --force-reinstall", f"å®‰è£… {transformers_ver}") and
                run_command(f"pip install {diffusers_ver} --force-reinstall", f"å®‰è£… {diffusers_ver}")):

                if test_vqmodel_import():
                    print("âœ… ç¨³å®šç‰ˆæœ¬ç»„åˆVQModelå¯ç”¨")
                    vqmodel_available = True
                    break

        if not vqmodel_available:
            print("âŒ æ‰€æœ‰ç‰ˆæœ¬ç»„åˆéƒ½å¤±è´¥")
            return False
    else:
        print("âœ… VQModelå¯ç”¨")

    # ç¬¬ä¸ƒæ­¥ï¼šå®‰è£…å…¶ä»–æ ¸å¿ƒä¾èµ–
    core_packages = [
        ("safetensors==0.4.1", "SafeTensors"),
        ("tokenizers==0.15.0", "Tokenizers"),
    ]

    success_count = 4  # huggingface_hub, transformers, diffusers, accelerateå·²æˆåŠŸ
    for package, description in core_packages:
        if run_command(f"pip install {package}", f"å®‰è£… {description}"):
            success_count += 1

    # éªŒè¯ç‰ˆæœ¬å…¼å®¹æ€§
    print("\nğŸ”§ éªŒè¯ç‰ˆæœ¬å…¼å®¹æ€§...")
    run_command("pip check", "æ£€æŸ¥ä¾èµ–å†²çª")

    total_packages = 4 + len(core_packages)
    print(f"\nğŸ“Š æ ¸å¿ƒä¾èµ–å®‰è£…ç»“æœ: {success_count}/{total_packages} æˆåŠŸ")
    return success_count >= total_packages - 1 and vqmodel_available



def install_additional_dependencies():
    """å®‰è£…é¢å¤–ä¾èµ– - å…¼å®¹ç‰ˆæœ¬"""
    print("ğŸ“š å®‰è£…é¢å¤–ä¾èµ–...")

    # ç¡®ä¿NumPyç‰ˆæœ¬æ­£ç¡®
    run_command("pip install 'numpy<2.0' --force-reinstall", "ç¡®ä¿NumPy 1.xç‰ˆæœ¬")

    additional_packages = [
        # æ•°æ®å¤„ç† (å…¼å®¹NumPy 1.xçš„ç‰ˆæœ¬)
        "pillow>=9.0.0",
        "opencv-python>=4.8.0",
        "matplotlib>=3.7.0",
        "scikit-image>=0.20.0",

        # æœºå™¨å­¦ä¹ å·¥å…·
        "scikit-learn>=1.3.0",
        "einops>=0.6.0",
        "tqdm>=4.65.0",

        # å…¶ä»–å·¥å…·
        "scipy>=1.10.0",
    ]

    success_count = 0
    for package in additional_packages:
        if run_command(f"pip install '{package}'", f"å®‰è£… {package}"):
            success_count += 1

    # ç‰¹æ®Šå¤„ç†lpips (å¯é€‰ä¾èµ–)
    print("\nğŸ¨ å®‰è£…æ„ŸçŸ¥æŸå¤±åº“...")
    if run_command("pip install lpips", "å®‰è£… lpips (å¯é€‰)"):
        success_count += 1
    else:
        print("âš ï¸ lpipså®‰è£…å¤±è´¥ï¼Œè·³è¿‡ (å¯é€‰ä¾èµ–)")

    print(f"\nğŸ“Š é¢å¤–ä¾èµ–å®‰è£…ç»“æœ: {success_count}/{len(additional_packages)+1} æˆåŠŸ")
    return success_count >= len(additional_packages) - 2  # å…è®¸2ä¸ªå¤±è´¥

def test_unified_environment():
    """æµ‹è¯•ç»Ÿä¸€ç¯å¢ƒ"""
    print("ğŸ§ª æµ‹è¯•ç»Ÿä¸€ç¯å¢ƒ...")
    
    # æ¸…ç†æ¨¡å—ç¼“å­˜
    modules_to_clear = ['torch', 'diffusers', 'transformers', 'huggingface_hub', 'accelerate']
    for module_name in modules_to_clear:
        if module_name in sys.modules:
            del sys.modules[module_name]
    
    # åŸºç¡€æµ‹è¯•
    tests = [
        ("PyTorch", "torch"),
        ("Diffusers", "diffusers"),
        ("Transformers", "transformers"),
        ("HuggingFace Hub", "huggingface_hub"),
        ("Accelerate", "accelerate"),
    ]
    
    success_count = 0
    for name, module in tests:
        try:
            imported_module = importlib.import_module(module)
            version = getattr(imported_module, '__version__', 'unknown')
            print(f"âœ… {name}: {version}")
            success_count += 1
        except ImportError:
            print(f"âŒ {name}: å¯¼å…¥å¤±è´¥")
    
    # æµ‹è¯•PyTorch CUDA
    try:
        import torch
        if torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨: {torch.version.cuda}")
            print(f"âœ… GPUæ•°é‡: {torch.cuda.device_count()}")
        else:
            print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
    except Exception as e:
        print(f"âŒ PyTorchæµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•VQModel
    try:
        from diffusers.models.autoencoders.vq_model import VQModel
        print("âœ… VQModel: å¯ç”¨ (VQ-VAEæ”¯æŒ)")
    except ImportError as e:
        print(f"âŒ VQModel: å¯¼å…¥å¤±è´¥ - {e}")
    
    # æµ‹è¯•GPT2
    try:
        from transformers import GPT2Config, GPT2LMHeadModel
        print("âœ… GPT2: å¯ç”¨ (Transformeræ”¯æŒ)")
    except ImportError as e:
        print(f"âŒ GPT2: å¯¼å…¥å¤±è´¥ - {e}")
    
    print(f"\nğŸ“Š ç»Ÿä¸€ç¯å¢ƒæµ‹è¯•ç»“æœ: {success_count}/{len(tests)} æˆåŠŸ")
    return success_count >= len(tests) - 1

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ VQ-VAE + Transformer ç»Ÿä¸€ç¯å¢ƒé…ç½®è„šæœ¬")
    print("=" * 60)
    print("ğŸ¯ ä¸€ä¸ªç¯å¢ƒæ”¯æŒVQ-VAEå’ŒTransformerè®­ç»ƒ")
    print("ğŸ’¡ ä¿®å¤huggingface_hubç‰ˆæœ¬å†²çªå’ŒOfflineModeIsEnabledé”™è¯¯")
    print("ğŸ”§ ä½¿ç”¨å…¼å®¹çš„ç‰ˆæœ¬ç»„åˆç¡®ä¿ç¨³å®šè¿è¡Œ")
    print()

    steps = [
        ("å®‰è£…PyTorch", install_pytorch),
        ("å®‰è£…æ ¸å¿ƒä¾èµ–", install_core_dependencies),
        ("å®‰è£…é¢å¤–ä¾èµ–", install_additional_dependencies),
        ("æµ‹è¯•ç¯å¢ƒ", test_unified_environment),
    ]
    
    for step_name, step_func in steps:
        print(f"\n{'='*20} {step_name} {'='*20}")
        if not step_func():
            print(f"\nâŒ {step_name}å¤±è´¥ï¼Œåœæ­¢å®‰è£…")
            return False
    
    print("\nğŸ‰ ç»Ÿä¸€ç¯å¢ƒé…ç½®å®Œæˆ!")
    print("âœ… æ”¯æŒVQ-VAEå’ŒTransformerè®­ç»ƒ")
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
    print("   1. VQ-VAEè®­ç»ƒ: python training/train_vqvae.py --help")
    print("   2. Transformerè®­ç»ƒ: python training/train_transformer.py --help")
    print("   3. å®Œæ•´è®­ç»ƒ: python train_main.py --help")
    print("\nğŸš€ è®­ç»ƒå‘½ä»¤ç¤ºä¾‹:")
    print("   python train_main.py --data_dir /kaggle/input/dataset")
    print("\nğŸ’¡ ç¯å¢ƒè¯´æ˜:")
    print("   - diffusers: æ™ºèƒ½ç‰ˆæœ¬é€‰æ‹©ï¼Œç¡®ä¿VQModelå¯ç”¨")
    print("   - transformers: æœ€æ–°ç‰ˆæœ¬ï¼Œæ”¯æŒåºåˆ—ç”Ÿæˆ")
    print("   - ç»Ÿä¸€ç¯å¢ƒ: ç®€åŒ–éƒ¨ç½²å’Œç»´æŠ¤")

if __name__ == "__main__":
    main()
