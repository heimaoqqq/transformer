#!/usr/bin/env python3
"""
ç®€åŒ–çš„æ¡ä»¶æ‰©æ•£éªŒè¯è„šæœ¬
ä¸“é—¨éªŒè¯31ä½ç”¨æˆ·çš„æ­¥æ€å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾åƒæ¡ä»¶æ‰©æ•£æ•ˆæœ

ä½¿ç”¨æ–¹æ³•:
1. è®­ç»ƒ31ä¸ªç”¨æˆ·åˆ†ç±»å™¨ (æ¯ä¸ªç”¨æˆ·ä¸€ä¸ªäºŒåˆ†ç±»å™¨: æ˜¯/ä¸æ˜¯è¯¥ç”¨æˆ·)
2. ç”ŸæˆæŒ‡å®šç”¨æˆ·çš„å›¾åƒ
3. ç”¨å¯¹åº”çš„åˆ†ç±»å™¨éªŒè¯ç”Ÿæˆå›¾åƒæ˜¯å¦åŒ…å«è¯¥ç”¨æˆ·ç‰¹å¾

æ ¸å¿ƒæ€è·¯:
- å¦‚æœæ¡ä»¶æ‰©æ•£çœŸçš„æœ‰æ•ˆï¼Œç”Ÿæˆçš„ç”¨æˆ·Aå›¾åƒåº”è¯¥è¢«ç”¨æˆ·Açš„åˆ†ç±»å™¨è¯†åˆ«ä¸º"æ˜¯ç”¨æˆ·A"
- åŒæ—¶è¢«å…¶ä»–ç”¨æˆ·çš„åˆ†ç±»å™¨è¯†åˆ«ä¸º"ä¸æ˜¯è¯¥ç”¨æˆ·"
"""

import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision.models import resnet18
import numpy as np
from PIL import Image
from pathlib import Path
import json
from typing import List, Tuple, Dict, Optional
from tqdm import tqdm
import matplotlib.pyplot as plt
from datetime import datetime
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from validation.user_classifier import UserValidationSystem
import random

class SimpleConditionValidator:
    """ç®€åŒ–çš„æ¡ä»¶æ‰©æ•£éªŒè¯å™¨"""
    
    def __init__(self, data_dir: str, output_dir: str = "./validation_results", device: str = "auto"):
        """
        Args:
            data_dir: æ•°æ®ç›®å½•ï¼ŒåŒ…å«ID_1, ID_2, ..., ID_31ç­‰å­ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            device: è®¡ç®—è®¾å¤‡
        """
        self.data_dir = Path(data_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)

        print(f"ğŸš€ è®¾å¤‡: {self.device}")
        print(f"ğŸ“Š æ•°æ®é›†æ ¼å¼: 256Ã—256å½©è‰²å›¾åƒ")
        print(f"ğŸ“ æ•°æ®ç›®å½•: {self.data_dir}")

        # åˆå§‹åŒ–éªŒè¯ç³»ç»Ÿ (é’ˆå¯¹256Ã—256å›¾åƒä¼˜åŒ–)
        self.validation_system = UserValidationSystem(device=str(self.device))

        # æ‰«æç”¨æˆ·æ•°æ®
        self.user_mapping = self._scan_users()
        self.num_users = len(self.user_mapping)

        print(f"ğŸ“Š å‘ç° {self.num_users} ä¸ªç”¨æˆ·: {sorted(self.user_mapping.keys())}")

        # éªŒè¯æ•°æ®é›†æ ¼å¼
        self._validate_dataset_format()
    
    def _scan_users(self) -> Dict[int, str]:
        """æ‰«æç”¨æˆ·ç›®å½•"""
        user_mapping = {}
        
        for user_dir in self.data_dir.iterdir():
            if user_dir.is_dir() and user_dir.name.startswith('ID_'):
                try:
                    user_id = int(user_dir.name.split('_')[1])
                    image_files = list(user_dir.glob("*.png")) + list(user_dir.glob("*.jpg"))
                    
                    if len(image_files) > 0:
                        user_mapping[user_id] = str(user_dir)
                        print(f"  ç”¨æˆ· {user_id:2d}: {len(image_files):3d} å¼ å›¾åƒ")
                    else:
                        print(f"  âš ï¸  ç”¨æˆ· {user_id:2d}: æ— å›¾åƒæ–‡ä»¶")
                        
                except ValueError:
                    print(f"  âŒ æ— æ•ˆç›®å½•å: {user_dir.name}")
                    continue
        
        return user_mapping

    def _validate_dataset_format(self):
        """éªŒè¯æ•°æ®é›†æ ¼å¼"""
        print(f"\nğŸ” éªŒè¯æ•°æ®é›†æ ¼å¼...")

        total_images = 0
        format_issues = []

        for user_id, user_dir in self.user_mapping.items():
            user_path = Path(user_dir)
            image_files = list(user_path.glob("*.png")) + list(user_path.glob("*.jpg"))

            if len(image_files) > 0:
                # æ£€æŸ¥ç¬¬ä¸€å¼ å›¾åƒçš„æ ¼å¼
                try:
                    sample_image = Image.open(image_files[0])
                    width, height = sample_image.size
                    mode = sample_image.mode

                    if width != 256 or height != 256:
                        format_issues.append(f"ç”¨æˆ· {user_id}: å°ºå¯¸ {width}Ã—{height} (æœŸæœ› 256Ã—256)")

                    if mode != 'RGB':
                        format_issues.append(f"ç”¨æˆ· {user_id}: æ¨¡å¼ {mode} (æœŸæœ› RGB)")

                    total_images += len(image_files)

                except Exception as e:
                    format_issues.append(f"ç”¨æˆ· {user_id}: å›¾åƒè¯»å–å¤±è´¥ - {e}")

        print(f"  æ€»å›¾åƒæ•°: {total_images}")

        if format_issues:
            print(f"  âš ï¸  æ ¼å¼é—®é¢˜:")
            for issue in format_issues[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
                print(f"    {issue}")
            if len(format_issues) > 5:
                print(f"    ... è¿˜æœ‰ {len(format_issues) - 5} ä¸ªé—®é¢˜")
        else:
            print(f"  âœ… æ•°æ®é›†æ ¼å¼éªŒè¯é€šè¿‡")

    def generate_test_images(self, model_dir: str, user_id: int, num_images: int = 50,
                           num_inference_steps: int = 50, guidance_scale: float = 1.0) -> str:
        """
        ç”Ÿæˆæµ‹è¯•å›¾åƒ (æ”¯æŒæŒ‡å¯¼å¼ºåº¦)

        Args:
            model_dir: æ¨¡å‹ç›®å½•
            user_id: ç”¨æˆ·ID
            num_images: ç”Ÿæˆå›¾åƒæ•°é‡
            num_inference_steps: æ¨ç†æ­¥æ•°
            guidance_scale: æŒ‡å¯¼å¼ºåº¦ (1.0=çº¯æ¡ä»¶, >1.0=CFGå¢å¼º)

        Returns:
            ç”Ÿæˆå›¾åƒç›®å½•è·¯å¾„
        """
        print(f"\nğŸ¨ ä¸ºç”¨æˆ· {user_id} ç”Ÿæˆæµ‹è¯•å›¾åƒ")
        print(f"  å‚æ•°: {num_images}å¼ , {num_inference_steps}æ­¥, æŒ‡å¯¼å¼ºåº¦={guidance_scale}")

        generated_dir = self.output_dir / f"generated_user_{user_id:02d}"
        generated_dir.mkdir(exist_ok=True)

        # æ„å»ºç”Ÿæˆå‘½ä»¤
        cmd = [
            "python", "inference/generate.py",
            "--vae_path", f"{model_dir}/vae/final_model",
            "--unet_path", f"{model_dir}/unet/final_model",
            "--condition_encoder_path", f"{model_dir}/condition_encoder/final_model.pth",
            "--user_ids", str(user_id),
            "--num_images_per_user", str(num_images),
            "--num_inference_steps", str(num_inference_steps),
            "--output_dir", str(generated_dir),
            "--data_dir", str(self.data_dir),
            "--num_users", str(self.num_users)
        ]

        # å¦‚æœæ”¯æŒæŒ‡å¯¼å¼ºåº¦ï¼Œæ·»åŠ å‚æ•°
        if guidance_scale > 1.0:
            cmd.extend(["--guidance_scale", str(guidance_scale)])

        print(f"  å‘½ä»¤: {' '.join(cmd)}")

        try:
            import subprocess
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=Path(__file__).parent)

            if result.returncode == 0:
                print(f"  âœ… ç”Ÿæˆå®Œæˆ: {generated_dir}")
                return str(generated_dir)
            else:
                print(f"  âŒ ç”Ÿæˆå¤±è´¥: {result.stderr}")
                return ""

        except Exception as e:
            print(f"  âŒ ç”Ÿæˆå¼‚å¸¸: {e}")
            return ""

    def prepare_user_data_with_split(self, user_id: int, user_dir: str, other_dirs: list,
                                   max_samples_per_class: int = 500, negative_ratio: float = 2.0,
                                   train_ratio: float = 0.8) -> tuple:
        """
        ä¸ºæŒ‡å®šç”¨æˆ·å‡†å¤‡è®­ç»ƒæ•°æ®ï¼Œæ”¯æŒè®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†

        Args:
            user_id: ç”¨æˆ·ID
            user_dir: è¯¥ç”¨æˆ·å›¾åƒç›®å½•
            other_dirs: å…¶ä»–ç”¨æˆ·ç›®å½•åˆ—è¡¨
            max_samples_per_class: æ­£æ ·æœ¬æœ€å¤§æ•°é‡
            negative_ratio: è´Ÿæ ·æœ¬ä¸æ­£æ ·æœ¬çš„æ¯”ä¾‹
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹ (0.8 = 80%è®­ç»ƒï¼Œ20%éªŒè¯)

        Returns:
            (train_paths, train_labels, val_paths, val_labels)
        """
        print(f"\nğŸ‘¤ å‡†å¤‡ç”¨æˆ· {user_id} çš„æ•°æ® (è®­ç»ƒ/éªŒè¯åˆ’åˆ†)")

        # 1. æ”¶é›†æ­£æ ·æœ¬ (è¯¥ç”¨æˆ·çš„å›¾åƒ)
        user_path = Path(user_dir)
        positive_images = list(user_path.glob("*.png")) + list(user_path.glob("*.jpg"))
        positive_images = positive_images[:max_samples_per_class]

        print(f"  ç”¨æˆ· {user_id} æ€»æ­£æ ·æœ¬: {len(positive_images)} å¼ ")

        # 2. åˆ’åˆ†æ­£æ ·æœ¬ä¸ºè®­ç»ƒ/éªŒè¯é›†
        random.shuffle(positive_images)
        train_split = int(len(positive_images) * train_ratio)

        train_positive = positive_images[:train_split]
        val_positive = positive_images[train_split:]

        print(f"  æ­£æ ·æœ¬åˆ’åˆ†: è®­ç»ƒ {len(train_positive)} å¼ , éªŒè¯ {len(val_positive)} å¼ ")

        # 3. æ”¶é›†è´Ÿæ ·æœ¬ (å…¶ä»–ç”¨æˆ·çš„å›¾åƒ)
        all_negative_images = []

        for other_dir in other_dirs:
            other_path = Path(other_dir)
            if other_path.exists():
                other_images = list(other_path.glob("*.png")) + list(other_path.glob("*.jpg"))
                all_negative_images.extend(other_images)

        # 4. è®¡ç®—éœ€è¦çš„è´Ÿæ ·æœ¬æ•°é‡
        train_negative_needed = int(len(train_positive) * negative_ratio)
        val_negative_needed = int(len(val_positive) * negative_ratio)
        total_negative_needed = train_negative_needed + val_negative_needed

        print(f"  ç›®æ ‡è´Ÿæ ·æœ¬: è®­ç»ƒ {train_negative_needed} å¼ , éªŒè¯ {val_negative_needed} å¼ ")
        print(f"  å¯ç”¨è´Ÿæ ·æœ¬æ± : {len(all_negative_images)} å¼ ")

        # 5. éšæœºé€‰æ‹©è´Ÿæ ·æœ¬å¹¶åˆ’åˆ†
        if len(all_negative_images) >= total_negative_needed:
            selected_negative = random.sample(all_negative_images, total_negative_needed)
        else:
            selected_negative = all_negative_images
            print(f"  âš ï¸  è´Ÿæ ·æœ¬ä¸è¶³ï¼Œä½¿ç”¨å…¨éƒ¨ {len(selected_negative)} å¼ ")

        # 6. åˆ’åˆ†è´Ÿæ ·æœ¬ä¸ºè®­ç»ƒ/éªŒè¯é›†
        random.shuffle(selected_negative)
        train_negative = selected_negative[:train_negative_needed]
        val_negative = selected_negative[train_negative_needed:train_negative_needed + val_negative_needed]

        print(f"  è´Ÿæ ·æœ¬åˆ’åˆ†: è®­ç»ƒ {len(train_negative)} å¼ , éªŒè¯ {len(val_negative)} å¼ ")

        # 7. ç»„åˆè®­ç»ƒé›†
        train_paths = [str(p) for p in train_positive] + [str(p) for p in train_negative]
        train_labels = [1] * len(train_positive) + [0] * len(train_negative)

        # 8. ç»„åˆéªŒè¯é›†
        val_paths = [str(p) for p in val_positive] + [str(p) for p in val_negative]
        val_labels = [1] * len(val_positive) + [0] * len(val_negative)

        # 9. æ‰“ä¹±æ•°æ®
        train_data = list(zip(train_paths, train_labels))
        val_data = list(zip(val_paths, val_labels))
        random.shuffle(train_data)
        random.shuffle(val_data)

        train_paths, train_labels = zip(*train_data) if train_data else ([], [])
        val_paths, val_labels = zip(*val_data) if val_data else ([], [])

        print(f"  âœ… æ•°æ®å‡†å¤‡å®Œæˆ:")
        print(f"    è®­ç»ƒé›†: {len(train_paths)} å¼  (æ­£æ ·æœ¬ {len(train_positive)}, è´Ÿæ ·æœ¬ {len(train_negative)})")
        print(f"    éªŒè¯é›†: {len(val_paths)} å¼  (æ­£æ ·æœ¬ {len(val_positive)}, è´Ÿæ ·æœ¬ {len(val_negative)})")

        return list(train_paths), list(train_labels), list(val_paths), list(val_labels)
    
    def train_all_classifiers(self, epochs: int = 30, batch_size: int = 32, 
                            max_samples_per_class: int = 500) -> Dict[int, float]:
        """
        è®­ç»ƒæ‰€æœ‰ç”¨æˆ·çš„åˆ†ç±»å™¨
        
        Args:
            epochs: è®­ç»ƒè½®æ•°
            batch_size: æ‰¹æ¬¡å¤§å°
            max_samples_per_class: æ¯ç±»æœ€å¤§æ ·æœ¬æ•°
            
        Returns:
            å„ç”¨æˆ·åˆ†ç±»å™¨çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡
        """
        print(f"\nğŸ¤– å¼€å§‹è®­ç»ƒ {self.num_users} ä¸ªç”¨æˆ·åˆ†ç±»å™¨")
        print(f"  å‚æ•°: epochs={epochs}, batch_size={batch_size}, max_samples={max_samples_per_class}")
        print("=" * 60)
        
        classifier_accuracies = {}
        
        for user_id in sorted(self.user_mapping.keys()):
            print(f"\nğŸ‘¤ è®­ç»ƒç”¨æˆ· {user_id} çš„åˆ†ç±»å™¨...")
            
            # å‡†å¤‡è¯¥ç”¨æˆ·çš„è®­ç»ƒæ•°æ® (æ”¯æŒè®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†)
            user_dir = self.user_mapping[user_id]
            other_dirs = [self.user_mapping[uid] for uid in self.user_mapping.keys() if uid != user_id]

            # å‡†å¤‡æ•°æ® (80%è®­ç»ƒï¼Œ20%éªŒè¯)
            train_paths, train_labels, val_paths, val_labels = self.prepare_user_data_with_split(
                user_id=user_id,
                user_dir=user_dir,
                other_dirs=other_dirs,
                max_samples_per_class=max_samples_per_class,
                negative_ratio=2.0,  # 2:1çš„è´Ÿæ­£æ ·æœ¬æ¯”ä¾‹
                train_ratio=0.8      # 80%è®­ç»ƒï¼Œ20%éªŒè¯
            )
            
            if len(train_paths) == 0:
                print(f"  âŒ ç”¨æˆ· {user_id} æ— å¯ç”¨è®­ç»ƒæ•°æ®ï¼Œè·³è¿‡")
                continue

            # è®­ç»ƒåˆ†ç±»å™¨ (åˆå¹¶è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œè®©åŸæœ‰æ–¹æ³•å†…éƒ¨åˆ’åˆ†)
            all_paths = train_paths + val_paths
            all_labels = train_labels + val_labels

            try:
                history = self.validation_system.train_user_classifier(
                    user_id=user_id,
                    image_paths=all_paths,
                    labels=all_labels,
                    epochs=epochs,
                    batch_size=batch_size,
                    learning_rate=5e-4,
                    validation_split=0.2  # å†…éƒ¨å†æ¬¡åˆ’åˆ†20%ä½œä¸ºéªŒè¯é›†
                )
                
                # è®°å½•æœ€ä½³å‡†ç¡®ç‡
                best_acc = max(history['val_acc'])
                classifier_accuracies[user_id] = best_acc
                
                # ä¿å­˜åˆ†ç±»å™¨
                classifier_path = self.output_dir / f"classifier_user_{user_id:02d}.pth"
                self.validation_system.save_classifier(user_id, str(classifier_path))
                
                # ä¿å­˜è®­ç»ƒæ›²çº¿
                plot_path = self.output_dir / f"training_user_{user_id:02d}.png"
                self.validation_system.plot_training_history(history, str(plot_path))
                
                print(f"  âœ… ç”¨æˆ· {user_id} åˆ†ç±»å™¨è®­ç»ƒå®Œæˆï¼Œæœ€ä½³å‡†ç¡®ç‡: {best_acc:.3f}")
                
            except Exception as e:
                print(f"  âŒ ç”¨æˆ· {user_id} åˆ†ç±»å™¨è®­ç»ƒå¤±è´¥: {e}")
                continue
        
        # æ€»ç»“è®­ç»ƒç»“æœ
        print(f"\nğŸ“Š åˆ†ç±»å™¨è®­ç»ƒæ€»ç»“:")
        print(f"  æˆåŠŸè®­ç»ƒ: {len(classifier_accuracies)}/{self.num_users} ä¸ªåˆ†ç±»å™¨")
        
        if classifier_accuracies:
            avg_acc = np.mean(list(classifier_accuracies.values()))
            min_acc = min(classifier_accuracies.values())
            max_acc = max(classifier_accuracies.values())
            
            print(f"  å¹³å‡å‡†ç¡®ç‡: {avg_acc:.3f}")
            print(f"  å‡†ç¡®ç‡èŒƒå›´: [{min_acc:.3f}, {max_acc:.3f}]")
            
            # æ˜¾ç¤ºå„ç”¨æˆ·å‡†ç¡®ç‡
            print(f"  è¯¦ç»†ç»“æœ:")
            for user_id in sorted(classifier_accuracies.keys()):
                acc = classifier_accuracies[user_id]
                status = "ğŸŒŸ" if acc >= 0.85 else "âœ…" if acc >= 0.75 else "âš ï¸" if acc >= 0.65 else "âŒ"
                print(f"    ç”¨æˆ· {user_id:2d}: {acc:.3f} {status}")
        
        # ä¿å­˜ç»“æœ
        results_file = self.output_dir / "classifier_training_results.json"
        with open(results_file, 'w') as f:
            json.dump({
                'training_time': datetime.now().isoformat(),
                'num_users': self.num_users,
                'training_params': {
                    'epochs': epochs,
                    'batch_size': batch_size,
                    'max_samples_per_class': max_samples_per_class
                },
                'classifier_accuracies': classifier_accuracies,
                'summary': {
                    'successful_classifiers': len(classifier_accuracies),
                    'average_accuracy': float(np.mean(list(classifier_accuracies.values()))) if classifier_accuracies else 0,
                    'min_accuracy': float(min(classifier_accuracies.values())) if classifier_accuracies else 0,
                    'max_accuracy': float(max(classifier_accuracies.values())) if classifier_accuracies else 0
                }
            }, f, indent=2)
        
        print(f"\nğŸ“„ è®­ç»ƒç»“æœä¿å­˜åœ¨: {results_file}")
        
        return classifier_accuracies

    def load_classifiers(self, user_ids: Optional[List[int]] = None) -> bool:
        """
        åŠ è½½å·²è®­ç»ƒçš„åˆ†ç±»å™¨

        Args:
            user_ids: è¦åŠ è½½çš„ç”¨æˆ·IDåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºåŠ è½½æ‰€æœ‰å¯ç”¨çš„

        Returns:
            æ˜¯å¦æˆåŠŸåŠ è½½
        """
        if user_ids is None:
            user_ids = list(self.user_mapping.keys())

        loaded_count = 0

        for user_id in user_ids:
            classifier_path = self.output_dir / f"classifier_user_{user_id:02d}.pth"

            if classifier_path.exists():
                try:
                    self.validation_system.load_classifier(user_id, str(classifier_path))
                    loaded_count += 1
                    print(f"  âœ… ç”¨æˆ· {user_id} åˆ†ç±»å™¨åŠ è½½æˆåŠŸ")
                except Exception as e:
                    print(f"  âŒ ç”¨æˆ· {user_id} åˆ†ç±»å™¨åŠ è½½å¤±è´¥: {e}")
            else:
                print(f"  âš ï¸  ç”¨æˆ· {user_id} åˆ†ç±»å™¨æ–‡ä»¶ä¸å­˜åœ¨: {classifier_path}")

        print(f"ğŸ“Š æˆåŠŸåŠ è½½ {loaded_count}/{len(user_ids)} ä¸ªåˆ†ç±»å™¨")
        return loaded_count > 0

    def validate_generated_images(self, generated_images_dir: str, target_user_id: int,
                                confidence_threshold: float = 0.8) -> Dict:
        """
        éªŒè¯ç”Ÿæˆå›¾åƒæ˜¯å¦åŒ…å«æŒ‡å®šç”¨æˆ·ç‰¹å¾

        Args:
            generated_images_dir: ç”Ÿæˆå›¾åƒç›®å½•
            target_user_id: ç›®æ ‡ç”¨æˆ·ID
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼

        Returns:
            éªŒè¯ç»“æœ
        """
        print(f"\nğŸ” éªŒè¯ç”¨æˆ· {target_user_id} çš„ç”Ÿæˆå›¾åƒ")
        print(f"  å›¾åƒç›®å½•: {generated_images_dir}")
        print(f"  ç½®ä¿¡åº¦é˜ˆå€¼: {confidence_threshold}")

        # æ£€æŸ¥ç›®æ ‡ç”¨æˆ·åˆ†ç±»å™¨æ˜¯å¦å·²åŠ è½½
        if target_user_id not in self.validation_system.classifiers:
            print(f"âŒ ç”¨æˆ· {target_user_id} çš„åˆ†ç±»å™¨æœªåŠ è½½")
            return {}

        # éªŒè¯ç”Ÿæˆå›¾åƒ
        try:
            result = self.validation_system.validate_generated_images(
                user_id=target_user_id,
                generated_images_dir=generated_images_dir,
                confidence_threshold=confidence_threshold
            )

            # ä¿å­˜éªŒè¯ç»“æœ
            result_file = self.output_dir / f"validation_user_{target_user_id:02d}.json"
            with open(result_file, 'w') as f:
                json.dump(result, f, indent=2)

            print(f"ğŸ“„ éªŒè¯ç»“æœä¿å­˜åœ¨: {result_file}")

            return result

        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
            return {}

    def cross_validate_all_users(self, generated_images_dir: str, target_user_id: int,
                               confidence_threshold: float = 0.8) -> Dict:
        """
        äº¤å‰éªŒè¯ï¼šç”¨æ‰€æœ‰ç”¨æˆ·çš„åˆ†ç±»å™¨éªŒè¯ç”Ÿæˆå›¾åƒ
        è¿™æ˜¯éªŒè¯æ¡ä»¶æ‰©æ•£æ•ˆæœçš„å…³é”®æµ‹è¯•

        Args:
            generated_images_dir: ç”Ÿæˆå›¾åƒç›®å½•
            target_user_id: ç›®æ ‡ç”¨æˆ·ID (ç”Ÿæˆå›¾åƒå£°ç§°çš„ç”¨æˆ·)
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼

        Returns:
            äº¤å‰éªŒè¯ç»“æœ
        """
        print(f"\nğŸ¯ äº¤å‰éªŒè¯ï¼šç”¨æ‰€æœ‰åˆ†ç±»å™¨éªŒè¯ç”¨æˆ· {target_user_id} çš„ç”Ÿæˆå›¾åƒ")
        print(f"  æ ¸å¿ƒé—®é¢˜ï¼šç”Ÿæˆçš„å›¾åƒæ˜¯å¦çœŸçš„åŒ…å«ç”¨æˆ· {target_user_id} çš„ç‰¹å¾ï¼Ÿ")
        print("=" * 60)

        gen_dir = Path(generated_images_dir)
        if not gen_dir.exists():
            print(f"âŒ ç”Ÿæˆå›¾åƒç›®å½•ä¸å­˜åœ¨: {gen_dir}")
            return {}

        image_files = list(gen_dir.glob("*.png")) + list(gen_dir.glob("*.jpg"))
        if not image_files:
            print(f"âŒ æœªæ‰¾åˆ°ç”Ÿæˆå›¾åƒ")
            return {}

        print(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} å¼ ç”Ÿæˆå›¾åƒ")

        # ç”¨æ¯ä¸ªç”¨æˆ·çš„åˆ†ç±»å™¨éªŒè¯è¿™äº›å›¾åƒ
        cross_validation_results = {}

        for user_id in sorted(self.validation_system.classifiers.keys()):
            print(f"\nğŸ” ç”¨æˆ· {user_id} çš„åˆ†ç±»å™¨éªŒè¯...")

            try:
                result = self.validation_system.validate_generated_images(
                    user_id=user_id,
                    generated_images_dir=generated_images_dir,
                    confidence_threshold=confidence_threshold
                )

                cross_validation_results[user_id] = result

                success_rate = result['success_rate']
                avg_confidence = result['avg_confidence']

                if user_id == target_user_id:
                    # ç›®æ ‡ç”¨æˆ·çš„åˆ†ç±»å™¨åº”è¯¥è¯†åˆ«å‡ºè¿™äº›æ˜¯è¯¥ç”¨æˆ·çš„å›¾åƒ
                    status = "ğŸ¯" if success_rate >= 0.7 else "âš ï¸" if success_rate >= 0.5 else "âŒ"
                    print(f"  {status} ç›®æ ‡ç”¨æˆ· {user_id}: æˆåŠŸç‡ {success_rate:.2f}, ç½®ä¿¡åº¦ {avg_confidence:.3f}")
                else:
                    # å…¶ä»–ç”¨æˆ·çš„åˆ†ç±»å™¨åº”è¯¥è¯†åˆ«å‡ºè¿™äº›ä¸æ˜¯è¯¥ç”¨æˆ·çš„å›¾åƒ
                    status = "âœ…" if success_rate <= 0.3 else "âš ï¸" if success_rate <= 0.5 else "âŒ"
                    print(f"  {status} å…¶ä»–ç”¨æˆ· {user_id}: æˆåŠŸç‡ {success_rate:.2f}, ç½®ä¿¡åº¦ {avg_confidence:.3f}")

            except Exception as e:
                print(f"  âŒ ç”¨æˆ· {user_id} éªŒè¯å¤±è´¥: {e}")
                continue

        # åˆ†æäº¤å‰éªŒè¯ç»“æœ
        analysis = self._analyze_cross_validation(cross_validation_results, target_user_id, confidence_threshold)

        # ä¿å­˜å®Œæ•´ç»“æœ
        complete_result = {
            'target_user_id': target_user_id,
            'generated_images_dir': str(generated_images_dir),
            'confidence_threshold': confidence_threshold,
            'total_images': len(image_files),
            'cross_validation_results': cross_validation_results,
            'analysis': analysis,
            'timestamp': datetime.now().isoformat()
        }

        result_file = self.output_dir / f"cross_validation_user_{target_user_id:02d}.json"
        with open(result_file, 'w') as f:
            json.dump(complete_result, f, indent=2)

        print(f"\nğŸ“„ äº¤å‰éªŒè¯ç»“æœä¿å­˜åœ¨: {result_file}")

        return complete_result

    def _analyze_cross_validation(self, cross_results: Dict, target_user_id: int,
                                confidence_threshold: float) -> Dict:
        """åˆ†æäº¤å‰éªŒè¯ç»“æœ"""

        if not cross_results:
            return {'error': 'No cross validation results'}

        # ç›®æ ‡ç”¨æˆ·ç»“æœ
        target_result = cross_results.get(target_user_id, {})
        target_success_rate = target_result.get('success_rate', 0)
        target_confidence = target_result.get('avg_confidence', 0)

        # å…¶ä»–ç”¨æˆ·ç»“æœ
        other_results = {uid: result for uid, result in cross_results.items() if uid != target_user_id}
        other_success_rates = [result.get('success_rate', 0) for result in other_results.values()]
        other_confidences = [result.get('avg_confidence', 0) for result in other_results.values()]

        avg_other_success = np.mean(other_success_rates) if other_success_rates else 0
        avg_other_confidence = np.mean(other_confidences) if other_confidences else 0

        # æ¡ä»¶æ‰©æ•£æ•ˆæœè¯„ä¼°
        condition_effective = (
            target_success_rate >= 0.7 and  # ç›®æ ‡ç”¨æˆ·åˆ†ç±»å™¨è¯†åˆ«ç‡é«˜
            avg_other_success <= 0.3        # å…¶ä»–ç”¨æˆ·åˆ†ç±»å™¨è¯†åˆ«ç‡ä½
        )

        # è®¡ç®—åŒºåˆ†åº¦
        discrimination_score = target_success_rate - avg_other_success

        analysis = {
            'condition_effective': condition_effective,
            'target_user_performance': {
                'user_id': target_user_id,
                'success_rate': target_success_rate,
                'avg_confidence': target_confidence,
                'status': 'good' if target_success_rate >= 0.7 else 'poor'
            },
            'other_users_performance': {
                'avg_success_rate': avg_other_success,
                'avg_confidence': avg_other_confidence,
                'status': 'good' if avg_other_success <= 0.3 else 'poor'
            },
            'discrimination_score': discrimination_score,
            'overall_assessment': {
                'condition_control': 'effective' if condition_effective else 'ineffective',
                'discrimination_quality': (
                    'excellent' if discrimination_score >= 0.5 else
                    'good' if discrimination_score >= 0.3 else
                    'poor' if discrimination_score >= 0.1 else
                    'very_poor'
                )
            }
        }

        # æ‰“å°åˆ†æç»“æœ
        print(f"\nğŸ“Š äº¤å‰éªŒè¯åˆ†æç»“æœ:")
        print(f"  ç›®æ ‡ç”¨æˆ· {target_user_id} è¯†åˆ«ç‡: {target_success_rate:.2f}")
        print(f"  å…¶ä»–ç”¨æˆ·å¹³å‡è¯†åˆ«ç‡: {avg_other_success:.2f}")
        print(f"  åŒºåˆ†åº¦å¾—åˆ†: {discrimination_score:.2f}")
        print(f"  æ¡ä»¶æ§åˆ¶æ•ˆæœ: {'âœ… æœ‰æ•ˆ' if condition_effective else 'âŒ æ— æ•ˆ'}")

        return analysis

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ç®€åŒ–çš„æ¡ä»¶æ‰©æ•£éªŒè¯ç³»ç»Ÿ - ä¸“é—¨éªŒè¯31ä½ç”¨æˆ·æ­¥æ€å¾®å¤šæ™®å‹’å›¾åƒ",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    # å¿…éœ€å‚æ•°
    parser.add_argument("--data_dir", type=str, required=True,
                       help="æ•°æ®ç›®å½• (åŒ…å«ID_1, ID_2, ..., ID_31å­ç›®å½•)")
    parser.add_argument("--action", type=str, required=True,
                       choices=['train', 'validate', 'cross_validate'],
                       help="æ‰§è¡ŒåŠ¨ä½œ: train=è®­ç»ƒåˆ†ç±»å™¨, validate=éªŒè¯å•ä¸ªç”¨æˆ·, cross_validate=äº¤å‰éªŒè¯")

    # å¯é€‰å‚æ•°
    parser.add_argument("--output_dir", type=str, default="./validation_results",
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--device", type=str, default="auto",
                       help="è®¡ç®—è®¾å¤‡ (auto/cuda/cpu)")

    # è®­ç»ƒå‚æ•°
    parser.add_argument("--epochs", type=int, default=30,
                       help="åˆ†ç±»å™¨è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch_size", type=int, default=32,
                       help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--max_samples", type=int, default=500,
                       help="æ¯ç±»æœ€å¤§æ ·æœ¬æ•°")

    # éªŒè¯å‚æ•°
    parser.add_argument("--generated_images_dir", type=str,
                       help="ç”Ÿæˆå›¾åƒç›®å½• (éªŒè¯æ—¶å¿…éœ€)")
    parser.add_argument("--target_user_id", type=int,
                       help="ç›®æ ‡ç”¨æˆ·ID (éªŒè¯æ—¶å¿…éœ€)")
    parser.add_argument("--confidence_threshold", type=float, default=0.8,
                       help="ç½®ä¿¡åº¦é˜ˆå€¼")

    args = parser.parse_args()

    print("ğŸ¯ ç®€åŒ–çš„æ¡ä»¶æ‰©æ•£éªŒè¯ç³»ç»Ÿ")
    print("=" * 60)
    print(f"ğŸ“Š æ•°æ®ç›®å½•: {args.data_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ¬ æ‰§è¡ŒåŠ¨ä½œ: {args.action}")

    # åˆ›å»ºéªŒè¯å™¨
    validator = SimpleConditionValidator(
        data_dir=args.data_dir,
        output_dir=args.output_dir,
        device=args.device
    )

    if args.action == 'train':
        # è®­ç»ƒæ‰€æœ‰ç”¨æˆ·çš„åˆ†ç±»å™¨
        print(f"\nğŸ¤– å¼€å§‹è®­ç»ƒåˆ†ç±»å™¨...")
        accuracies = validator.train_all_classifiers(
            epochs=args.epochs,
            batch_size=args.batch_size,
            max_samples_per_class=args.max_samples
        )

        if accuracies:
            print(f"\nğŸ‰ åˆ†ç±»å™¨è®­ç»ƒå®Œæˆ!")
            print(f"ğŸ’¡ ä¸‹ä¸€æ­¥: ä½¿ç”¨ --action validate æˆ– --action cross_validate éªŒè¯ç”Ÿæˆå›¾åƒ")
        else:
            print(f"\nâŒ åˆ†ç±»å™¨è®­ç»ƒå¤±è´¥!")
            return 1

    elif args.action == 'validate':
        # éªŒè¯å•ä¸ªç”¨æˆ·çš„ç”Ÿæˆå›¾åƒ
        if not args.generated_images_dir or args.target_user_id is None:
            print(f"âŒ éªŒè¯æ¨¡å¼éœ€è¦ --generated_images_dir å’Œ --target_user_id å‚æ•°")
            return 1

        # åŠ è½½åˆ†ç±»å™¨
        if not validator.load_classifiers([args.target_user_id]):
            print(f"âŒ æ— æ³•åŠ è½½ç”¨æˆ· {args.target_user_id} çš„åˆ†ç±»å™¨")
            return 1

        # éªŒè¯
        result = validator.validate_generated_images(
            generated_images_dir=args.generated_images_dir,
            target_user_id=args.target_user_id,
            confidence_threshold=args.confidence_threshold
        )

        if result:
            success_rate = result['success_rate']
            avg_confidence = result['avg_confidence']
            print(f"\nğŸ“Š éªŒè¯ç»“æœ: æˆåŠŸç‡ {success_rate:.2f}, å¹³å‡ç½®ä¿¡åº¦ {avg_confidence:.3f}")

            if success_rate >= 0.7:
                print(f"ğŸ‰ éªŒè¯æˆåŠŸ! ç”Ÿæˆå›¾åƒåŒ…å«ç”¨æˆ· {args.target_user_id} çš„ç‰¹å¾")
            else:
                print(f"âš ï¸  éªŒè¯ç»“æœä¸ç†æƒ³ï¼Œå¯èƒ½éœ€è¦æ”¹è¿›æ¡ä»¶æ‰©æ•£æ¨¡å‹")
        else:
            print(f"âŒ éªŒè¯å¤±è´¥!")
            return 1

    elif args.action == 'cross_validate':
        # äº¤å‰éªŒè¯
        if not args.generated_images_dir or args.target_user_id is None:
            print(f"âŒ äº¤å‰éªŒè¯æ¨¡å¼éœ€è¦ --generated_images_dir å’Œ --target_user_id å‚æ•°")
            return 1

        # åŠ è½½æ‰€æœ‰åˆ†ç±»å™¨
        if not validator.load_classifiers():
            print(f"âŒ æ— æ³•åŠ è½½åˆ†ç±»å™¨")
            return 1

        # äº¤å‰éªŒè¯
        result = validator.cross_validate_all_users(
            generated_images_dir=args.generated_images_dir,
            target_user_id=args.target_user_id,
            confidence_threshold=args.confidence_threshold
        )

        if result and 'analysis' in result:
            analysis = result['analysis']
            condition_effective = analysis['condition_effective']
            discrimination_score = analysis['discrimination_score']

            if condition_effective:
                print(f"\nğŸ‰ äº¤å‰éªŒè¯æˆåŠŸ! æ¡ä»¶æ‰©æ•£æ¨¡å‹æœ‰æ•ˆæ§åˆ¶ç”¨æˆ·ç‰¹å¾")
                print(f"  åŒºåˆ†åº¦å¾—åˆ†: {discrimination_score:.2f}")
            else:
                print(f"\nâš ï¸  äº¤å‰éªŒè¯æ˜¾ç¤ºæ¡ä»¶æ§åˆ¶æ•ˆæœä¸ä½³")
                print(f"  åŒºåˆ†åº¦å¾—åˆ†: {discrimination_score:.2f}")
                print(f"ğŸ’¡ å»ºè®®: æ£€æŸ¥è®­ç»ƒæ•°æ®ã€å¢åŠ è®­ç»ƒè½®æ•°æˆ–è°ƒæ•´æ¨¡å‹æ¶æ„")
        else:
            print(f"âŒ äº¤å‰éªŒè¯å¤±è´¥!")
            return 1

    return 0

if __name__ == "__main__":
    exit(main())
