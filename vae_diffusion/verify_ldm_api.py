#!/usr/bin/env python3
"""
LDM APIç¡®è®¤è„šæœ¬
éªŒè¯æ‰©æ•£æ¨¡å‹ç›¸å…³APIçš„å…¼å®¹æ€§å’Œå¯ç”¨æ€§
"""

import torch
import warnings
warnings.filterwarnings("ignore")

def check_versions():
    """æ£€æŸ¥å…³é”®åŒ…ç‰ˆæœ¬"""
    print("ğŸ“¦ æ£€æŸ¥å…³é”®åŒ…ç‰ˆæœ¬:")
    
    packages = [
        ('torch', 'PyTorch'),
        ('diffusers', 'Diffusers'),
        ('transformers', 'Transformers'),
        ('accelerate', 'Accelerate'),
    ]
    
    versions = {}
    for package, name in packages:
        try:
            module = __import__(package)
            version = getattr(module, '__version__', 'unknown')
            print(f"   âœ… {name}: {version}")
            versions[package] = version
        except ImportError:
            print(f"   âŒ {name}: æœªå®‰è£…")
            versions[package] = None
    
    return versions

def test_unet_api():
    """æµ‹è¯•UNet2DConditionModel API"""
    print("\nğŸ¯ æµ‹è¯•UNet2DConditionModel API:")
    
    try:
        from diffusers import UNet2DConditionModel
        
        # 1. æµ‹è¯•æ„é€ å‡½æ•°
        print("   1ï¸âƒ£ æµ‹è¯•æ„é€ å‡½æ•°...")
        unet = UNet2DConditionModel(
            sample_size=32,
            in_channels=4,
            out_channels=4,
            cross_attention_dim=512,  # ä¸­å‹é…ç½®
            layers_per_block=2,
            block_out_channels=(128, 256, 512, 512),  # ä¸­å‹é…ç½®
            down_block_types=(
                "CrossAttnDownBlock2D",
                "CrossAttnDownBlock2D",
                "CrossAttnDownBlock2D",
                "DownBlock2D",
            ),
            up_block_types=(
                "UpBlock2D",
                "CrossAttnUpBlock2D",
                "CrossAttnUpBlock2D",
                "CrossAttnUpBlock2D",
            ),
            attention_head_dim=8,
            use_linear_projection=True,
        )
        print("   âœ… UNetæ„é€ å‡½æ•°å…¼å®¹")
        
        # 2. æµ‹è¯•å‰å‘ä¼ æ’­
        print("   2ï¸âƒ£ æµ‹è¯•å‰å‘ä¼ æ’­...")
        with torch.no_grad():
            sample = torch.randn(1, 4, 32, 32)
            timestep = torch.randint(0, 1000, (1,))
            encoder_hidden_states = torch.randn(1, 1, 512)  # åŒ¹é…æ–°çš„cross_attention_dim
            
            # æµ‹è¯•return_dict=Falseæ¨¡å¼
            result = unet(
                sample,
                timestep,
                encoder_hidden_states=encoder_hidden_states,
                return_dict=False
            )
            
            if isinstance(result, tuple) and len(result) > 0:
                noise_pred = result[0]
                print("   âœ… return_dict=False æ¨¡å¼å…¼å®¹")
            else:
                print("   âŒ return_dict=False æ¨¡å¼ä¸å…¼å®¹")
                return False
            
            # æµ‹è¯•.sampleå±æ€§æ¨¡å¼
            result2 = unet(
                sample,
                timestep,
                encoder_hidden_states=encoder_hidden_states
            )
            
            if hasattr(result2, 'sample'):
                noise_pred2 = result2.sample
                print("   âœ… .sample å±æ€§å…¼å®¹")
            else:
                print("   âŒ .sample å±æ€§ä¸å…¼å®¹")
                return False
        
        # 3. æµ‹è¯•é…ç½®å±æ€§
        print("   3ï¸âƒ£ æµ‹è¯•é…ç½®å±æ€§...")
        config_attrs = [
            'sample_size', 'in_channels', 'out_channels', 
            'cross_attention_dim', 'layers_per_block'
        ]
        
        for attr in config_attrs:
            if hasattr(unet.config, attr):
                value = getattr(unet.config, attr)
                print(f"      âœ… config.{attr}: {value}")
            else:
                print(f"      âŒ config.{attr}: ä¸å¯ç”¨")
                return False
        
        print("   âœ… UNet APIå®Œå…¨å…¼å®¹")
        return True
        
    except Exception as e:
        print(f"   âŒ UNet APIæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_scheduler_api():
    """æµ‹è¯•è°ƒåº¦å™¨API"""
    print("\nâ° æµ‹è¯•è°ƒåº¦å™¨API:")
    
    try:
        from diffusers import DDPMScheduler, DDIMScheduler
        
        # 1. æµ‹è¯•DDPMè°ƒåº¦å™¨
        print("   1ï¸âƒ£ æµ‹è¯•DDPMè°ƒåº¦å™¨...")
        ddpm_scheduler = DDPMScheduler(
            num_train_timesteps=1000,
            beta_start=0.00085,
            beta_end=0.012,
            beta_schedule="scaled_linear",
            variance_type="fixed_small",
            clip_sample=False,
            prediction_type="epsilon",
        )
        
        # æµ‹è¯•å…³é”®æ–¹æ³•
        test_latents = torch.randn(1, 4, 32, 32)
        test_noise = torch.randn_like(test_latents)
        test_timesteps = torch.randint(0, 1000, (1,))
        
        with torch.no_grad():
            # add_noiseæ–¹æ³•
            noisy_latents = ddpm_scheduler.add_noise(test_latents, test_noise, test_timesteps)
            print("      âœ… add_noise() æ–¹æ³•å¯ç”¨")
            
            # scale_model_inputæ–¹æ³•
            scaled_input = ddpm_scheduler.scale_model_input(test_latents, test_timesteps[0])
            print("      âœ… scale_model_input() æ–¹æ³•å¯ç”¨")
            
            # stepæ–¹æ³•
            step_result = ddpm_scheduler.step(test_noise, test_timesteps[0], test_latents)
            if hasattr(step_result, 'prev_sample'):
                print("      âœ… step().prev_sample å¯ç”¨")
            else:
                print("      âŒ step().prev_sample ä¸å¯ç”¨")
                return False
            
            # é…ç½®å±æ€§
            config_attrs = ['num_train_timesteps', 'beta_start', 'beta_end', 'prediction_type']
            for attr in config_attrs:
                if hasattr(ddpm_scheduler.config, attr):
                    value = getattr(ddpm_scheduler.config, attr)
                    print(f"      âœ… config.{attr}: {value}")
                else:
                    print(f"      âŒ config.{attr}: ä¸å¯ç”¨")
        
        # 2. æµ‹è¯•DDIMè°ƒåº¦å™¨
        print("   2ï¸âƒ£ æµ‹è¯•DDIMè°ƒåº¦å™¨...")
        ddim_scheduler = DDIMScheduler.from_config(ddpm_scheduler.config)
        ddim_scheduler.set_timesteps(50)
        
        with torch.no_grad():
            step_result = ddim_scheduler.step(test_noise, test_timesteps[0], test_latents)
            if hasattr(step_result, 'prev_sample'):
                print("      âœ… DDIM step().prev_sample å¯ç”¨")
            else:
                print("      âŒ DDIM step().prev_sample ä¸å¯ç”¨")
                return False
        
        print("   âœ… è°ƒåº¦å™¨APIå®Œå…¨å…¼å®¹")
        return True
        
    except Exception as e:
        print(f"   âŒ è°ƒåº¦å™¨APIæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_accelerate_api():
    """æµ‹è¯•Accelerate API"""
    print("\nğŸš€ æµ‹è¯•Accelerate API:")
    
    try:
        from accelerate import Accelerator
        
        # åˆ›å»ºåŠ é€Ÿå™¨
        accelerator = Accelerator(
            gradient_accumulation_steps=1,
            mixed_precision="fp16",
        )
        
        print("   âœ… Acceleratoråˆ›å»ºæˆåŠŸ")
        print(f"      è®¾å¤‡: {accelerator.device}")
        print(f"      æ··åˆç²¾åº¦: {accelerator.mixed_precision}")
        print(f"      æ˜¯å¦ä¸»è¿›ç¨‹: {accelerator.is_main_process}")
        
        # æµ‹è¯•prepareæ–¹æ³•
        dummy_model = torch.nn.Linear(10, 1)
        dummy_optimizer = torch.optim.Adam(dummy_model.parameters())
        
        model, optimizer = accelerator.prepare(dummy_model, dummy_optimizer)
        print("   âœ… prepare() æ–¹æ³•å¯ç”¨")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Accelerate APIæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_training_workflow():
    """æµ‹è¯•å®Œæ•´è®­ç»ƒå·¥ä½œæµç¨‹API"""
    print("\nğŸ”„ æµ‹è¯•å®Œæ•´è®­ç»ƒå·¥ä½œæµç¨‹API:")
    
    try:
        from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler
        from accelerate import Accelerator
        
        # åˆ›å»ºæ¨¡å‹
        vae = AutoencoderKL(
            in_channels=3,
            out_channels=3,
            latent_channels=4,
            sample_size=128,
        )
        
        unet = UNet2DConditionModel(
            sample_size=32,
            in_channels=4,
            out_channels=4,
            cross_attention_dim=512,  # ä¸­å‹é…ç½®
        )
        
        scheduler = DDPMScheduler(num_train_timesteps=1000)
        accelerator = Accelerator()
        
        print("   1ï¸âƒ£ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
        with torch.no_grad():
            # è¾“å…¥æ•°æ®
            images = torch.randn(2, 3, 128, 128)
            user_conditions = torch.randn(2, 1, 512)  # åŒ¹é…æ–°çš„cross_attention_dim
            
            # VAEç¼–ç 
            posterior = vae.encode(images).latent_dist
            latents = posterior.sample()
            latents = latents * vae.config.scaling_factor
            print("   2ï¸âƒ£ VAEç¼–ç æˆåŠŸ")
            
            # æ·»åŠ å™ªå£°
            noise = torch.randn_like(latents)
            timesteps = torch.randint(0, scheduler.config.num_train_timesteps, (latents.shape[0],))
            noisy_latents = scheduler.add_noise(latents, noise, timesteps)
            print("   3ï¸âƒ£ å™ªå£°æ·»åŠ æˆåŠŸ")
            
            # UNeté¢„æµ‹
            model_pred = unet(
                noisy_latents,
                timesteps,
                encoder_hidden_states=user_conditions,
                return_dict=False
            )[0]
            print("   4ï¸âƒ£ UNeté¢„æµ‹æˆåŠŸ")
            
            # æŸå¤±è®¡ç®—
            loss = torch.nn.functional.mse_loss(model_pred, noise)
            print(f"   5ï¸âƒ£ æŸå¤±è®¡ç®—æˆåŠŸ: {loss.item():.6f}")
            
            # VAEè§£ç 
            latents_decoded = latents / vae.config.scaling_factor
            reconstruction = vae.decode(latents_decoded).sample
            print("   6ï¸âƒ£ VAEè§£ç æˆåŠŸ")
        
        print("   âœ… å®Œæ•´è®­ç»ƒå·¥ä½œæµç¨‹APIå…¼å®¹")
        return True
        
    except Exception as e:
        print(f"   âŒ è®­ç»ƒå·¥ä½œæµç¨‹APIæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” LDM APIå…¼å®¹æ€§éªŒè¯")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ç‰ˆæœ¬
    versions = check_versions()
    
    # 2. APIå…¼å®¹æ€§æµ‹è¯•
    tests = [
        ("UNet2DConditionModel API", test_unet_api),
        ("è°ƒåº¦å™¨ API", test_scheduler_api),
        ("Accelerate API", test_accelerate_api),
        ("å®Œæ•´è®­ç»ƒå·¥ä½œæµç¨‹ API", test_training_workflow)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # 3. æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š LDM APIå…¼å®¹æ€§éªŒè¯æ€»ç»“:")
    
    passed = 0
    for test_name, result in results:
        status = "âœ…" if result else "âŒ"
        print(f"   {status} {test_name}")
        if result:
            passed += 1
    
    total = len(results)
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰LDM APIå®Œå…¨å…¼å®¹ï¼")
        print("âœ… å½“å‰ç‰ˆæœ¬å¯ä»¥å®‰å…¨ç”¨äºLDMè®­ç»ƒ")
        return True
    else:
        print("\nâš ï¸  å­˜åœ¨LDM APIå…¼å®¹æ€§é—®é¢˜")
        print("âŒ å»ºè®®æ£€æŸ¥ç‰ˆæœ¬æˆ–ä½¿ç”¨æ¨èç‰ˆæœ¬ç»„åˆ")
        return False

if __name__ == "__main__":
    main()
