#!/usr/bin/env python3
"""
éªŒè¯æ¨¡å‹é…ç½®ä¸€è‡´æ€§
æ£€æŸ¥UNetå’Œæ¡ä»¶ç¼–ç å™¨çš„ç»´åº¦æ˜¯å¦åŒ¹é…
"""

import torch
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

def check_model_consistency():
    """æ£€æŸ¥æ¨¡å‹é…ç½®ä¸€è‡´æ€§"""
    print("ğŸ” æ£€æŸ¥æ¨¡å‹é…ç½®ä¸€è‡´æ€§...")
    
    # æ¨¡å‹è·¯å¾„ - è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
    unet_path = "/kaggle/input/diffusion-final-model"
    condition_encoder_path = "/kaggle/input/diffusion-final-model/condition_encoder.pt"
    
    try:
        # 1. æ£€æŸ¥UNeté…ç½®
        print("\n1ï¸âƒ£ æ£€æŸ¥UNeté…ç½®:")
        from diffusers import UNet2DConditionModel
        unet = UNet2DConditionModel.from_pretrained(unet_path)
        
        print(f"   UNet cross_attention_dim: {unet.config.cross_attention_dim}")
        print(f"   UNet in_channels: {unet.config.in_channels}")
        print(f"   UNet sample_size: {unet.config.sample_size}")
        
        # 2. æ£€æŸ¥æ¡ä»¶ç¼–ç å™¨é…ç½®
        print("\n2ï¸âƒ£ æ£€æŸ¥æ¡ä»¶ç¼–ç å™¨é…ç½®:")
        condition_encoder_state = torch.load(condition_encoder_path, map_location='cpu')
        
        if 'user_embedding.weight' in condition_encoder_state:
            num_users, embed_dim = condition_encoder_state['user_embedding.weight'].shape
            print(f"   æ¡ä»¶ç¼–ç å™¨ num_users: {num_users}")
            print(f"   æ¡ä»¶ç¼–ç å™¨ embed_dim: {embed_dim}")
        else:
            print("   âŒ æ— æ³•ä»æƒé‡æ–‡ä»¶æ¨æ–­æ¡ä»¶ç¼–ç å™¨é…ç½®")
            return False
        
        # 3. æ£€æŸ¥ç»´åº¦åŒ¹é…
        print("\n3ï¸âƒ£ æ£€æŸ¥ç»´åº¦åŒ¹é…:")
        if embed_dim == unet.config.cross_attention_dim:
            print(f"   âœ… ç»´åº¦åŒ¹é…! ({embed_dim})")
            return True
        else:
            print(f"   âŒ ç»´åº¦ä¸åŒ¹é…!")
            print(f"      æ¡ä»¶ç¼–ç å™¨: {embed_dim}")
            print(f"      UNetæœŸæœ›: {unet.config.cross_attention_dim}")
            
            # 4. åˆ†æå¯èƒ½çš„åŸå› 
            print("\n4ï¸âƒ£ å¯èƒ½çš„åŸå› åˆ†æ:")
            if unet.config.cross_attention_dim == 1024 and embed_dim == 512:
                print("   ğŸ¤” å¯èƒ½åŸå› :")
                print("      - UNetä½¿ç”¨äº†æ›´å¤§çš„é…ç½® (1024ç»´)")
                print("      - æ¡ä»¶ç¼–ç å™¨ä½¿ç”¨äº†ä¸­å‹é…ç½® (512ç»´)")
                print("      - è¿™å¯èƒ½æ˜¯å› ä¸ºUNetå’Œæ¡ä»¶ç¼–ç å™¨æ¥è‡ªä¸åŒçš„è®­ç»ƒé…ç½®")
            
            print("\n   ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
            print("      1. ä½¿ç”¨æŠ•å½±å±‚ (å½“å‰ä¿®å¤æ–¹æ¡ˆ)")
            print("      2. é‡æ–°è®­ç»ƒæ¡ä»¶ç¼–ç å™¨ä½¿ç”¨1024ç»´")
            print("      3. é‡æ–°è®­ç»ƒUNetä½¿ç”¨512ç»´")
            
            return False
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        return False

def simulate_training_scenario():
    """æ¨¡æ‹Ÿè®­ç»ƒæ—¶çš„åœºæ™¯"""
    print("\nğŸ¯ æ¨¡æ‹Ÿè®­ç»ƒæ—¶çš„åœºæ™¯:")
    
    try:
        from ..training.train_diffusion import UserConditionEncoder
        from diffusers import UNet2DConditionModel
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ—¶çš„é…ç½®
        cross_attention_dim = 512  # å‡è®¾è¿™æ˜¯è®­ç»ƒæ—¶ä½¿ç”¨çš„é…ç½®
        num_users = 31
        
        print(f"   è®­ç»ƒé…ç½®: cross_attention_dim = {cross_attention_dim}")
        
        # åˆ›å»ºæ¡ä»¶ç¼–ç å™¨ (è®­ç»ƒæ—¶çš„æ–¹å¼)
        condition_encoder = UserConditionEncoder(
            num_users=num_users,
            embed_dim=cross_attention_dim
        )
        
        # åˆ›å»ºUNet (è®­ç»ƒæ—¶çš„æ–¹å¼)
        unet = UNet2DConditionModel(
            sample_size=32,
            in_channels=4,
            out_channels=4,
            layers_per_block=2,
            block_out_channels=(128, 256, 512, 512),
            down_block_types=(
                "CrossAttnDownBlock2D",
                "CrossAttnDownBlock2D", 
                "CrossAttnDownBlock2D",
                "DownBlock2D",
            ),
            up_block_types=(
                "UpBlock2D",
                "CrossAttnUpBlock2D",
                "CrossAttnUpBlock2D",
                "CrossAttnUpBlock2D",
            ),
            cross_attention_dim=cross_attention_dim,  # å…³é”®ï¼šä½¿ç”¨ç›¸åŒçš„ç»´åº¦
            attention_head_dim=8,
            use_linear_projection=True,
        )
        
        print(f"   âœ… è®­ç»ƒæ—¶é…ç½®ä¸€è‡´:")
        print(f"      æ¡ä»¶ç¼–ç å™¨ embed_dim: {condition_encoder.embed_dim}")
        print(f"      UNet cross_attention_dim: {unet.config.cross_attention_dim}")
        
        # æµ‹è¯•å…¼å®¹æ€§
        with torch.no_grad():
            user_tensor = torch.tensor([0])
            encoder_hidden_states = condition_encoder(user_tensor)
            encoder_hidden_states = encoder_hidden_states.unsqueeze(1)
            
            latents = torch.randn(1, 4, 32, 32)
            timesteps = torch.tensor([100])
            
            # è¿™åº”è¯¥ä¸ä¼šå‡ºé”™
            noise_pred = unet(
                latents,
                timesteps,
                encoder_hidden_states=encoder_hidden_states,
                return_dict=False
            )[0]
            
            print(f"   âœ… è®­ç»ƒæ—¶å…¼å®¹æ€§æµ‹è¯•é€šè¿‡!")
            print(f"      è¾“å…¥å½¢çŠ¶: {encoder_hidden_states.shape}")
            print(f"      è¾“å‡ºå½¢çŠ¶: {noise_pred.shape}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ è®­ç»ƒæ—¶åœºæ™¯æ¨¡æ‹Ÿå¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æ¨¡å‹é…ç½®ä¸€è‡´æ€§éªŒè¯å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥å®é™…æ¨¡å‹é…ç½®
    consistency_ok = check_model_consistency()
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ—¶åœºæ™¯
    training_ok = simulate_training_scenario()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š æ€»ç»“:")
    
    if consistency_ok:
        print("âœ… ä½ çš„æ¨¡å‹é…ç½®æ˜¯ä¸€è‡´çš„ï¼Œä¸åº”è¯¥å‡ºç°ç»´åº¦ä¸åŒ¹é…é—®é¢˜")
        print("   å¦‚æœä»ç„¶å‡ºé”™ï¼Œå¯èƒ½æ˜¯å…¶ä»–åŸå› ")
    else:
        print("âŒ ä½ çš„æ¨¡å‹é…ç½®ä¸ä¸€è‡´ï¼Œè¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆä¼šå‡ºç°ç»´åº¦ä¸åŒ¹é…")
        print("   è®­ç»ƒæ—¶æ²¡é—®é¢˜æ˜¯å› ä¸ºUNetå’Œæ¡ä»¶ç¼–ç å™¨æ˜¯åŒæ—¶åˆ›å»ºçš„ï¼Œé…ç½®ä¸€è‡´")
        print("   æ¨ç†æ—¶æœ‰é—®é¢˜æ˜¯å› ä¸ºåŠ è½½çš„æ¨¡å‹æ¥è‡ªä¸åŒçš„è®­ç»ƒé…ç½®")
    
    if training_ok:
        print("âœ… è®­ç»ƒæ—¶åœºæ™¯æ¨¡æ‹ŸæˆåŠŸï¼Œè¯æ˜åŒæ—¶åˆ›å»ºæ—¶ä¸ä¼šæœ‰é—®é¢˜")
    
    print("\nğŸ’¡ å»ºè®®:")
    print("1. ä½¿ç”¨å½“å‰çš„æŠ•å½±å±‚ä¿®å¤æ–¹æ¡ˆ (å·²å®ç°)")
    print("2. æˆ–è€…ç¡®ä¿UNetå’Œæ¡ä»¶ç¼–ç å™¨æ¥è‡ªåŒä¸€æ¬¡è®­ç»ƒ")
    print("3. æ£€æŸ¥ä½ çš„è®­ç»ƒé…ç½®ï¼Œç¡®è®¤cross_attention_dimè®¾ç½®")

if __name__ == "__main__":
    main()
