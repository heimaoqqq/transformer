#!/usr/bin/env python3
"""
微多普勒时频图数据加载器
支持用户ID标签和数据增广
"""

import os
import torch
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import numpy as np
from pathlib import Path
import torchvision.transforms as transforms
import json
from typing import Dict, List, Optional, Tuple

class MicroDopplerDataset(Dataset):
    """微多普勒时频图数据集"""
    
    def __init__(
        self,
        data_dir: str,
        resolution: int = 256,
        augment: bool = True,
        split: str = "train",
        user_ids: Optional[List[int]] = None
    ):
        """
        初始化数据集
        
        Args:
            data_dir: 数据目录路径
            resolution: 图像分辨率
            augment: 是否使用数据增广
            split: 数据集分割 ("train", "val", "test")
            user_ids: 指定用户ID列表，None表示使用所有用户
        """
        self.data_dir = Path(data_dir)
        self.resolution = resolution
        self.augment = augment
        self.split = split
        
        # 扫描数据文件
        self.image_paths, self.user_labels = self._scan_data(user_ids)
        
        # 创建用户ID到索引的映射
        unique_users = sorted(list(set(self.user_labels)))
        self.user_to_idx = {user: idx for idx, user in enumerate(unique_users)}
        self.idx_to_user = {idx: user for user, idx in self.user_to_idx.items()}
        self.num_users = len(unique_users)
        
        print(f"Loaded {len(self.image_paths)} images from {self.num_users} users")
        print(f"Users: {unique_users}")
        
        # 定义图像变换
        self.transform = self._create_transforms()
    
    def _scan_data(self, user_ids: Optional[List[int]]) -> Tuple[List[Path], List[int]]:
        """
        扫描数据目录，获取图像路径和用户标签

        预期目录结构:
        data_dir/
        ├── ID_1/
        │   ├── image_001.png
        │   ├── image_002.png
        │   └── ...
        ├── ID_2/
        │   └── ...
        └── ID_31/
        """
        image_paths = []
        user_labels = []

        # 获取所有用户目录并按数字顺序排序
        user_dirs = []
        for user_dir in self.data_dir.iterdir():
            if not user_dir.is_dir():
                continue

            # 提取用户ID
            user_name = user_dir.name
            if user_name.startswith('ID_'):
                try:
                    user_id = int(user_name.split('_')[1])
                    user_dirs.append((user_id, user_dir))
                except ValueError:
                    print(f"Warning: Invalid user directory name: {user_name}")
                    continue
            else:
                print(f"Warning: Unexpected directory name: {user_name}")
                continue

        # 按用户ID数字顺序排序 (1, 2, 3, ..., 31)
        user_dirs.sort(key=lambda x: x[0])

        # 处理每个用户目录
        for user_id, user_dir in user_dirs:
            # 如果指定了用户ID列表，检查是否包含当前用户
            if user_ids is not None and user_id not in user_ids:
                continue

            # 扫描用户目录下的图像文件
            user_images = []
            for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp']:
                user_images.extend(user_dir.glob(ext))

            if len(user_images) == 0:
                print(f"Warning: No images found for user {user_id}")
                continue

            # 按文件名排序确保一致性
            user_images = sorted(user_images, key=lambda x: x.name)

            # 添加到列表
            for img_path in user_images:
                image_paths.append(img_path)
                user_labels.append(user_id)

        if len(image_paths) == 0:
            raise ValueError(f"No valid images found in {self.data_dir}")

        return image_paths, user_labels
    
    def _create_transforms(self):
        """
        创建图像变换 - 针对微多普勒时频图优化

        注意：微多普勒时频图对传统数据增强很敏感，因为：
        1. 时间轴和频率轴有物理意义，不能随意变换
        2. 颜色代表多普勒频移，不能随意调整
        3. 几何变换会破坏时频关系
        """
        transform_list = []

        # 现代化变换 - 采用128×128高质量方案
        # 现代标准: 128×128输入，VAE下采样到32×32
        # 使用Lanczos插值获得最佳质量
        modern_resolution = 128
        print(f"🎨 采用现代化标准: 缩放到 {modern_resolution}×{modern_resolution} (原始: {self.resolution}×{self.resolution})")
        print(f"   🖼️  缩放方法: Lanczos (现代高质量插值)")
        print(f"   📊 优势: 4倍信息容量, 更好细节保留, 现代VAE标准")

        transform_list.extend([
            transforms.Resize((modern_resolution, modern_resolution),
                            interpolation=transforms.InterpolationMode.LANCZOS),  # 现代高质量缩放
            transforms.ToTensor(),
        ])

        # 微多普勒专用的轻微增广 (仅训练时，非常保守)
        if self.augment and self.split == "train":
            print("Warning: Using minimal augmentation for micro-Doppler spectrograms")

            # 只使用对时频图安全的增广
            safe_augment_transforms = [
                # 极小的随机噪声 (模拟测量噪声)
                transforms.Lambda(lambda x: self._add_measurement_noise(x, noise_factor=0.005)),

                # 极小的亮度调整 (模拟信号强度变化)
                transforms.Lambda(lambda x: self._adjust_signal_strength(x, factor_range=0.05)),
            ]

            # 在ToTensor之后应用
            for aug_transform in safe_augment_transforms:
                transform_list.append(aug_transform)

        # 归一化到[0, 1]范围
        # 注意：不使用ImageNet的归一化，因为微多普勒图像的分布不同

        return transforms.Compose(transform_list)
    
    def _add_measurement_noise(self, tensor: torch.Tensor, noise_factor: float = 0.005) -> torch.Tensor:
        """
        添加测量噪声 - 模拟雷达系统的测量不确定性
        使用很小的噪声因子，不破坏时频结构
        """
        noise = torch.randn_like(tensor) * noise_factor
        return torch.clamp(tensor + noise, 0, 1)

    def _adjust_signal_strength(self, tensor: torch.Tensor, factor_range: float = 0.05) -> torch.Tensor:
        """
        调整信号强度 - 模拟不同距离或RCS的影响
        只进行很小的亮度调整，保持相对强度关系
        """
        # 随机调整因子 [-factor_range, +factor_range]
        adjustment = (torch.rand(1).item() - 0.5) * 2 * factor_range
        adjusted = tensor * (1 + adjustment)
        return torch.clamp(adjusted, 0, 1)
    
    def __len__(self) -> int:
        return len(self.image_paths)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """获取单个样本"""
        # 加载图像
        img_path = self.image_paths[idx]
        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"Error loading image {img_path}: {e}")
            # 返回黑色图像作为fallback
            image = Image.new('RGB', (self.resolution, self.resolution), (0, 0, 0))
        
        # 应用变换
        image = self.transform(image)
        
        # 获取用户标签
        user_id = self.user_labels[idx]
        user_idx = self.user_to_idx[user_id]
        
        return {
            'image': image,
            'user_id': user_id,
            'user_idx': user_idx,
            'path': str(img_path)
        }
    
    def get_user_samples(self, user_id: int, num_samples: int = 5) -> List[torch.Tensor]:
        """获取指定用户的样本图像"""
        user_indices = [i for i, uid in enumerate(self.user_labels) if uid == user_id]
        
        if len(user_indices) == 0:
            raise ValueError(f"User {user_id} not found in dataset")
        
        # 随机选择样本
        selected_indices = np.random.choice(
            user_indices, 
            size=min(num_samples, len(user_indices)), 
            replace=False
        )
        
        samples = []
        for idx in selected_indices:
            sample = self[idx]
            samples.append(sample['image'])
        
        return samples

class MicroDopplerDataModule:
    """数据模块，管理训练/验证/测试数据集"""
    
    def __init__(
        self,
        data_dir: str,
        batch_size: int = 16,
        num_workers: int = 4,
        resolution: int = 256,
        val_split: float = 0.2,
        test_split: float = 0.1,
        seed: int = 42
    ):
        self.data_dir = data_dir
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.resolution = resolution
        self.val_split = val_split
        self.test_split = test_split
        self.seed = seed
        
        # 设置随机种子
        np.random.seed(seed)
        
        # 扫描所有用户
        self.all_users = self._get_all_users()
        
        # 分割用户
        self.train_users, self.val_users, self.test_users = self._split_users()
        
        print(f"Data split:")
        print(f"  Train users: {len(self.train_users)} - {self.train_users}")
        print(f"  Val users: {len(self.val_users)} - {self.val_users}")
        print(f"  Test users: {len(self.test_users)} - {self.test_users}")
    
    def _get_all_users(self) -> List[int]:
        """获取所有用户ID"""
        data_path = Path(self.data_dir)
        users = []

        for user_dir in data_path.iterdir():
            if user_dir.is_dir() and user_dir.name.startswith('ID_'):
                try:
                    user_id = int(user_dir.name.split('_')[1])
                    users.append(user_id)
                except ValueError:
                    continue

        return sorted(users)
    
    def _split_users(self) -> Tuple[List[int], List[int], List[int]]:
        """按用户分割数据集"""
        users = self.all_users.copy()
        np.random.shuffle(users)
        
        n_users = len(users)
        n_test = max(1, int(n_users * self.test_split))
        n_val = max(1, int(n_users * self.val_split))
        n_train = n_users - n_test - n_val
        
        train_users = users[:n_train]
        val_users = users[n_train:n_train + n_val]
        test_users = users[n_train + n_val:]
        
        return sorted(train_users), sorted(val_users), sorted(test_users)
    
    def get_dataloader(self, split: str = "train") -> DataLoader:
        """获取数据加载器"""
        if split == "train":
            user_ids = self.train_users
            shuffle = True
            augment = True
        elif split == "val":
            user_ids = self.val_users
            shuffle = False
            augment = False
        elif split == "test":
            user_ids = self.test_users
            shuffle = False
            augment = False
        else:
            raise ValueError(f"Invalid split: {split}")
        
        dataset = MicroDopplerDataset(
            data_dir=self.data_dir,
            resolution=self.resolution,
            augment=augment,
            split=split,
            user_ids=user_ids
        )
        
        return DataLoader(
            dataset,
            batch_size=self.batch_size,
            shuffle=shuffle,
            num_workers=self.num_workers,
            pin_memory=True,
            drop_last=(split == "train")
        )
    
    def get_all_dataloader(self) -> DataLoader:
        """获取包含所有用户的数据加载器"""
        dataset = MicroDopplerDataset(
            data_dir=self.data_dir,
            resolution=self.resolution,
            augment=False,
            split="all",
            user_ids=None
        )
        
        return DataLoader(
            dataset,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=self.num_workers,
            pin_memory=True
        )

def test_dataloader():
    """测试数据加载器"""
    # 创建测试数据
    test_dir = Path("./test_data")
    test_dir.mkdir(exist_ok=True)

    # 创建用户目录和测试图像 (使用ID_格式)
    for user_id in [1, 2, 3]:
        user_dir = test_dir / f"ID_{user_id}"
        user_dir.mkdir(exist_ok=True)

        # 创建测试图像
        for i in range(5):
            img = Image.new('RGB', (256, 256),
                          (user_id * 50, i * 40, 100))
            img.save(user_dir / f"image_{i:03d}.png")

    # 测试数据加载器
    dataset = MicroDopplerDataset(
        data_dir=str(test_dir),
        resolution=256,
        augment=True
    )

    dataloader = DataLoader(dataset, batch_size=2, shuffle=True)

    # 测试一个batch
    for batch in dataloader:
        print(f"Batch shape: {batch['image'].shape}")
        print(f"User IDs: {batch['user_id']}")
        print(f"User indices: {batch['user_idx']}")
        break

    print("Data loader test passed!")

if __name__ == "__main__":
    test_dataloader()
