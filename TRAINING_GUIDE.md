# ğŸš€ VQ-VAE + Transformer è®­ç»ƒæŒ‡å—

## ğŸ“‹ è®­ç»ƒæµç¨‹æ¦‚è¿°

æœ¬é¡¹ç›®é‡‡ç”¨**ä¸¤é˜¶æ®µè®­ç»ƒ**ç­–ç•¥ï¼š

1. **é˜¶æ®µ1**: è®­ç»ƒVQ-VAEå­¦ä¹ å›¾åƒçš„ç¦»æ•£è¡¨ç¤º
2. **é˜¶æ®µ2**: è®­ç»ƒTransformerä»ç”¨æˆ·IDç”Ÿæˆtokenåºåˆ—

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1: å®Œæ•´è‡ªåŠ¨è®­ç»ƒ (æ¨è)

```bash
# åœ¨Kaggleä¸­è¿è¡Œ
python train_main.py --data_dir /kaggle/input/dataset
```

### æ–¹æ³•2: åˆ†æ­¥è®­ç»ƒ

```bash
# æ­¥éª¤1: ä»…è®­ç»ƒVQ-VAE
python train_main.py --skip_transformer --data_dir /kaggle/input/dataset

# æ­¥éª¤2: ä»…è®­ç»ƒTransformer (éœ€è¦å…ˆå®Œæˆæ­¥éª¤1)
python train_main.py --skip_vqvae --data_dir /kaggle/input/dataset
```

## ğŸ”§ è¯¦ç»†è®­ç»ƒå‚æ•°

### åŸºç¡€å‚æ•°
```bash
python train_main.py \
    --data_dir /kaggle/input/dataset \
    --output_dir /kaggle/working/outputs \
    --resolution 128 \
    --num_users 31 \
    --codebook_size 1024
```

### VQ-VAEå‚æ•°
```bash
python train_main.py \
    --vqvae_epochs 50 \
    --vqvae_lr 1e-4 \
    --commitment_cost 0.25 \
    --ema_decay 0.99 \
    --interpolation lanczos
```

### Transformerå‚æ•°
```bash
python train_main.py \
    --transformer_epochs 100 \
    --transformer_lr 5e-5 \
    --n_embd 512 \
    --n_layer 8 \
    --n_head 8 \
    --use_cross_attention
```

## ğŸ“ è¾“å‡ºæ–‡ä»¶ç»“æ„

è®­ç»ƒå®Œæˆåä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ç»“æ„ï¼š

```
/kaggle/working/outputs/vqvae_transformer/
â”œâ”€â”€ vqvae/                          # VQ-VAEæ¨¡å‹
â”‚   â”œâ”€â”€ final_model/                # diffusersæ ¼å¼ (æ¨è)
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â””â”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ best_model.pth              # æœ€ä½³checkpoint
â”‚   â”œâ”€â”€ checkpoint_epoch_XXX.pth    # è®­ç»ƒcheckpoints
â”‚   â””â”€â”€ samples/                    # é‡å»ºæ ·æœ¬
â””â”€â”€ transformer/                    # Transformeræ¨¡å‹
    â”œâ”€â”€ final_model/                # æœ€ç»ˆæ¨¡å‹
    â”œâ”€â”€ best_model.pth              # æœ€ä½³checkpoint
    â”œâ”€â”€ checkpoint_epoch_XXX.pth    # è®­ç»ƒcheckpoints
    â””â”€â”€ generated_samples/          # ç”Ÿæˆæ ·æœ¬
```

## âœ… æ¨¡å‹å…¼å®¹æ€§æ£€æŸ¥

### VQ-VAEè®­ç»ƒå®Œæˆåæ£€æŸ¥
```python
# æ£€æŸ¥VQ-VAEè¾“å‡ºæ–‡ä»¶
import os
from pathlib import Path

vqvae_path = Path("/kaggle/working/outputs/vqvae_transformer/vqvae")

print("ğŸ“ VQ-VAEè¾“å‡ºæ–‡ä»¶:")
if (vqvae_path / "final_model").exists():
    print("âœ… final_model/ (diffusersæ ¼å¼)")
if (vqvae_path / "best_model.pth").exists():
    print("âœ… best_model.pth (checkpointæ ¼å¼)")

# æµ‹è¯•VQ-VAEåŠ è½½
from models.vqvae_model import MicroDopplerVQVAE
try:
    model = MicroDopplerVQVAE.from_pretrained(vqvae_path / "final_model")
    print("âœ… VQ-VAEæ¨¡å‹åŠ è½½æˆåŠŸ")
except:
    print("âš ï¸ diffusersæ ¼å¼åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨checkpointæ ¼å¼")
```

### Transformerè®­ç»ƒå‰æ£€æŸ¥
```python
# éªŒè¯VQ-VAEæ¨¡å‹å¯ç”¨æ€§
python -c "
from training.train_transformer import TransformerTrainer
import argparse

# æ¨¡æ‹Ÿå‚æ•°
args = argparse.Namespace(
    vqvae_path='/kaggle/working/outputs/vqvae_transformer/vqvae',
    data_dir='/kaggle/input/dataset',
    output_dir='/tmp/test',
    codebook_size=1024,
    num_users=31
)

try:
    trainer = TransformerTrainer(args)
    print('âœ… Transformerè®­ç»ƒå™¨åˆå§‹åŒ–æˆåŠŸ')
except Exception as e:
    print(f'âŒ åˆå§‹åŒ–å¤±è´¥: {e}')
"
```

## ğŸ® GPUä¼˜åŒ–é…ç½®

é¡¹ç›®ä¼šè‡ªåŠ¨æ£€æµ‹GPUå¹¶ä¼˜åŒ–é…ç½®ï¼š

### Tesla P100 (16GB)
- VQ-VAE batch_size: 16
- Transformer batch_size: 8
- æ··åˆç²¾åº¦: å…³é—­

### Tesla T4 (16GB)
- VQ-VAE batch_size: 12
- Transformer batch_size: 6
- æ··åˆç²¾åº¦: å¼€å¯

### å…¶ä»–GPU (â‰¥8GB)
- VQ-VAE batch_size: 8
- Transformer batch_size: 4
- æ··åˆç²¾åº¦: å¼€å¯

## ğŸ” è®­ç»ƒç›‘æ§

### VQ-VAEè®­ç»ƒç›‘æ§
- **é‡å»ºè´¨é‡**: PSNR, SSIMæŒ‡æ ‡
- **ç æœ¬ä½¿ç”¨**: ä½¿ç”¨ç‡ç»Ÿè®¡
- **æŸå¤±æ›²çº¿**: VQæŸå¤± + é‡å»ºæŸå¤±

### Transformerè®­ç»ƒç›‘æ§
- **ç”Ÿæˆè´¨é‡**: å®šæœŸç”Ÿæˆæ ·æœ¬
- **æŸå¤±æ›²çº¿**: äº¤å‰ç†µæŸå¤±
- **ç”¨æˆ·æ¡ä»¶**: éªŒè¯ç”¨æˆ·ç‰¹å¾ä¿æŒ

## âš ï¸ å¸¸è§é—®é¢˜

### 1. VQ-VAEè®­ç»ƒå¤±è´¥
```bash
# æ£€æŸ¥æ•°æ®é›†æ ¼å¼
python test_dataset.py

# é™ä½batch_size
python train_main.py --vqvae_epochs 10 --batch_size 4
```

### 2. Transformeræ‰¾ä¸åˆ°VQ-VAEæ¨¡å‹
```bash
# æ£€æŸ¥VQ-VAEè¾“å‡º
ls -la /kaggle/working/outputs/vqvae_transformer/vqvae/

# æ‰‹åŠ¨æŒ‡å®šVQ-VAEè·¯å¾„
python training/train_transformer.py \
    --vqvae_path /kaggle/working/outputs/vqvae_transformer/vqvae \
    --data_dir /kaggle/input/dataset
```

### 3. å†…å­˜ä¸è¶³
```bash
# å‡å°batch_sizeå’Œæ¨¡å‹å°ºå¯¸
python train_main.py \
    --resolution 64 \
    --codebook_size 512 \
    --n_embd 256 \
    --n_layer 4
```

## ğŸ¯ æ¨èè®­ç»ƒç­–ç•¥

### å¿«é€ŸéªŒè¯ (10åˆ†é’Ÿ)
```bash
python train_main.py \
    --vqvae_epochs 5 \
    --transformer_epochs 10 \
    --data_dir /kaggle/input/dataset
```

### æ ‡å‡†è®­ç»ƒ (2-3å°æ—¶)
```bash
python train_main.py \
    --vqvae_epochs 50 \
    --transformer_epochs 100 \
    --data_dir /kaggle/input/dataset
```

### é«˜è´¨é‡è®­ç»ƒ (6-8å°æ—¶)
```bash
python train_main.py \
    --vqvae_epochs 100 \
    --transformer_epochs 200 \
    --vqvae_lr 5e-5 \
    --transformer_lr 1e-5 \
    --data_dir /kaggle/input/dataset
```

## ğŸ“Š è®­ç»ƒå®Œæˆå

è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹è„šæœ¬è¿›è¡Œç”Ÿæˆå’ŒéªŒè¯ï¼š

```bash
# ç”Ÿæˆæ–°æ ·æœ¬
python generate_main.py \
    --model_dir /kaggle/working/outputs/vqvae_transformer \
    --target_user_id 1 \
    --num_samples 10

# éªŒè¯æ¨¡å‹è´¨é‡
python validate_main.py \
    --model_dir /kaggle/working/outputs/vqvae_transformer \
    --real_data_dir /kaggle/input/dataset
```

ğŸ‰ **ç°åœ¨æ‚¨å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼**
