#!/usr/bin/env python3
"""
ä¾èµ–å’ŒAPIå…¼å®¹æ€§æµ‹è¯•è„šæœ¬
éªŒè¯æ‰€æœ‰åº“ç‰ˆæœ¬å’ŒAPIæ˜¯å¦å…¼å®¹
"""

import sys
import importlib
import subprocess
from packaging import version
import warnings
warnings.filterwarnings("ignore")

# å¿…éœ€çš„ä¾èµ–ç‰ˆæœ¬
REQUIRED_VERSIONS = {
    'torch': '2.0.0',
    'torchvision': '0.15.0',
    'diffusers': '0.25.0',
    'transformers': '4.35.0',
    'accelerate': '0.24.0',
    'PIL': '9.5.0',  # Pillow
    'cv2': '4.8.0',  # opencv-python
    'matplotlib': '3.7.0',
    'skimage': '0.21.0',  # scikit-image
    'sklearn': '1.3.0',  # scikit-learn
    'scipy': '1.11.0',
    'numpy': '1.24.0',
    'tqdm': '4.65.0',
    'einops': '0.7.0'
}

def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    print("ğŸ æ£€æŸ¥Pythonç‰ˆæœ¬...")
    python_version = sys.version_info
    
    if python_version.major < 3 or (python_version.major == 3 and python_version.minor < 8):
        print(f"âŒ Pythonç‰ˆæœ¬è¿‡ä½: {python_version.major}.{python_version.minor}")
        print("   éœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")
        return False
    else:
        print(f"âœ… Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
        return True

def get_package_version(package_name, import_name=None):
    """è·å–åŒ…ç‰ˆæœ¬ï¼Œé¿å…å¯¼å…¥å†²çª"""
    if import_name is None:
        import_name = package_name

    # æœ‰å†²çªçš„åŒ…ä½¿ç”¨pkg_resources
    problematic_packages = ['torchvision', 'transformers']

    if package_name in problematic_packages:
        try:
            import pkg_resources
            return pkg_resources.get_distribution(package_name).version
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è·å– {package_name} ç‰ˆæœ¬: {e}")
            return "unknown"

    try:
        module = importlib.import_module(import_name)

        # å°è¯•ä¸åŒçš„ç‰ˆæœ¬å±æ€§
        for attr in ['__version__', 'version', 'VERSION']:
            if hasattr(module, attr):
                return getattr(module, attr)

        # ç‰¹æ®Šå¤„ç†
        if package_name == 'PIL':
            return module.PILLOW_VERSION
        elif package_name == 'cv2':
            return module.__version__
        elif package_name == 'sklearn':
            return module.__version__
        elif package_name == 'skimage':
            return module.__version__

        return "unknown"

    except ImportError:
        return None
    except Exception as e:
        print(f"âš ï¸  å¯¼å…¥ {import_name} æ—¶å‡ºé”™: {e}")
        # å°è¯•å¤‡ç”¨æ–¹æ³•
        try:
            import pkg_resources
            return pkg_resources.get_distribution(package_name).version
        except:
            return "error"

def check_package_versions():
    """æ£€æŸ¥æ‰€æœ‰åŒ…ç‰ˆæœ¬"""
    print("\nğŸ“¦ æ£€æŸ¥åŒ…ç‰ˆæœ¬...")
    
    # åŒ…åæ˜ å°„
    import_mapping = {
        'PIL': 'PIL',
        'cv2': 'cv2', 
        'sklearn': 'sklearn',
        'skimage': 'skimage'
    }
    
    results = {}
    all_good = True
    
    for package, required_ver in REQUIRED_VERSIONS.items():
        import_name = import_mapping.get(package, package)
        current_ver = get_package_version(package, import_name)
        
        if current_ver is None:
            print(f"âŒ {package}: æœªå®‰è£…")
            results[package] = {'status': 'missing', 'current': None, 'required': required_ver}
            all_good = False
        elif current_ver == "unknown":
            print(f"âš ï¸  {package}: å·²å®‰è£…ä½†æ— æ³•è·å–ç‰ˆæœ¬")
            results[package] = {'status': 'unknown', 'current': 'unknown', 'required': required_ver}
        else:
            try:
                if version.parse(current_ver) >= version.parse(required_ver):
                    print(f"âœ… {package}: {current_ver} (>= {required_ver})")
                    results[package] = {'status': 'ok', 'current': current_ver, 'required': required_ver}
                else:
                    print(f"âš ï¸  {package}: {current_ver} (éœ€è¦ >= {required_ver})")
                    results[package] = {'status': 'outdated', 'current': current_ver, 'required': required_ver}
                    all_good = False
            except Exception as e:
                print(f"âš ï¸  {package}: {current_ver} (ç‰ˆæœ¬æ¯”è¾ƒå¤±è´¥: {e})")
                results[package] = {'status': 'unknown', 'current': current_ver, 'required': required_ver}
    
    return results, all_good

def test_diffusers_api():
    """æµ‹è¯•Diffusers APIå…¼å®¹æ€§"""
    print("\nğŸ”§ æµ‹è¯•Diffusers APIå…¼å®¹æ€§...")
    
    try:
        # æµ‹è¯•AutoencoderKL
        from diffusers import AutoencoderKL
        print("âœ… AutoencoderKL å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•åˆ›å»ºVAE
        vae = AutoencoderKL(
            in_channels=3,
            out_channels=3,
            latent_channels=4,
            sample_size=256,
        )
        print("âœ… AutoencoderKL åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•UNet2DConditionModel
        from diffusers import UNet2DConditionModel
        print("âœ… UNet2DConditionModel å¯¼å…¥æˆåŠŸ")
        
        unet = UNet2DConditionModel(
            sample_size=32,
            in_channels=4,
            out_channels=4,
            cross_attention_dim=768,
        )
        print("âœ… UNet2DConditionModel åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•è°ƒåº¦å™¨
        from diffusers import DDPMScheduler, DDIMScheduler
        print("âœ… è°ƒåº¦å™¨å¯¼å…¥æˆåŠŸ")
        
        scheduler = DDPMScheduler(
            num_train_timesteps=1000,
            beta_start=0.00085,
            beta_end=0.012,
            beta_schedule="scaled_linear"
        )
        print("âœ… DDPMScheduler åˆ›å»ºæˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ Diffusers APIæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_torch_functionality():
    """æµ‹è¯•PyTorchåŠŸèƒ½"""
    print("\nğŸ”¥ æµ‹è¯•PyTorchåŠŸèƒ½...")
    
    try:
        import torch
        import torch.nn as nn
        import torch.nn.functional as F
        
        # æ£€æŸ¥CUDA
        if torch.cuda.is_available():
            device = torch.device("cuda")
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"âœ… CUDAå¯ç”¨: {gpu_name} ({gpu_memory:.1f} GB)")
        else:
            device = torch.device("cpu")
            print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        
        # æµ‹è¯•åŸºæœ¬æ“ä½œ
        x = torch.randn(2, 3, 64, 64).to(device)
        conv = nn.Conv2d(3, 16, 3, padding=1).to(device)
        y = conv(x)
        print(f"âœ… åŸºæœ¬å¼ é‡æ“ä½œæˆåŠŸ: {x.shape} -> {y.shape}")
        
        # æµ‹è¯•æ··åˆç²¾åº¦
        try:
            from torch.cuda.amp import autocast, GradScaler
            with autocast():
                y = conv(x)
            print("âœ… æ··åˆç²¾åº¦æ”¯æŒ")
        except:
            print("âš ï¸  æ··åˆç²¾åº¦ä¸æ”¯æŒ")
        
        return True
        
    except Exception as e:
        print(f"âŒ PyTorchæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½åŠŸèƒ½"""
    print("\nğŸ“Š æµ‹è¯•æ•°æ®åŠ è½½åŠŸèƒ½...")
    
    try:
        import torch
        from torch.utils.data import Dataset, DataLoader
        from PIL import Image
        import numpy as np
        import torchvision.transforms as transforms
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
        class TestDataset(Dataset):
            def __init__(self):
                self.transform = transforms.Compose([
                    transforms.Resize((256, 256)),
                    transforms.ToTensor()
                ])
            
            def __len__(self):
                return 10
            
            def __getitem__(self, idx):
                # åˆ›å»ºå‡å›¾åƒ
                img = Image.new('RGB', (256, 256), (idx*25, 100, 150))
                return {
                    'image': self.transform(img),
                    'user_id': idx % 5,
                    'user_idx': idx % 5
                }
        
        dataset = TestDataset()
        dataloader = DataLoader(dataset, batch_size=2, shuffle=True)
        
        # æµ‹è¯•ä¸€ä¸ªbatch
        for batch in dataloader:
            assert batch['image'].shape == (2, 3, 256, 256)
            assert len(batch['user_id']) == 2
            break
        
        print("âœ… æ•°æ®åŠ è½½æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_training_components():
    """æµ‹è¯•è®­ç»ƒç»„ä»¶"""
    print("\nğŸ‹ï¸ æµ‹è¯•è®­ç»ƒç»„ä»¶...")
    
    try:
        import torch
        import torch.nn as nn
        from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # åˆ›å»ºæ¨¡å‹
        vae = AutoencoderKL(
            in_channels=3,
            out_channels=3,
            latent_channels=4,
            sample_size=256,
        ).to(device)
        
        unet = UNet2DConditionModel(
            sample_size=32,
            in_channels=4,
            out_channels=4,
            cross_attention_dim=768,
        ).to(device)
        
        scheduler = DDPMScheduler(num_train_timesteps=1000)
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        with torch.no_grad():
            # VAEæµ‹è¯•
            test_images = torch.randn(1, 3, 256, 256).to(device)
            posterior = vae.encode(test_images).latent_dist
            latents = posterior.sample()
            reconstructed = vae.decode(latents).sample
            
            print(f"âœ… VAEå‰å‘ä¼ æ’­: {test_images.shape} -> {latents.shape} -> {reconstructed.shape}")
            
            # UNetæµ‹è¯•
            timesteps = torch.randint(0, 1000, (1,)).to(device)
            encoder_hidden_states = torch.randn(1, 1, 768).to(device)
            
            noise_pred = unet(
                latents,
                timesteps,
                encoder_hidden_states=encoder_hidden_states
            ).sample
            
            print(f"âœ… UNetå‰å‘ä¼ æ’­: {latents.shape} -> {noise_pred.shape}")
        
        # æµ‹è¯•ä¼˜åŒ–å™¨
        optimizer = torch.optim.AdamW(vae.parameters(), lr=1e-4)
        print("âœ… ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒç»„ä»¶æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_accelerate():
    """æµ‹è¯•Accelerateåº“"""
    print("\nğŸš€ æµ‹è¯•Accelerateåº“...")
    
    try:
        from accelerate import Accelerator
        
        accelerator = Accelerator()
        print(f"âœ… Acceleratoråˆ›å»ºæˆåŠŸ (è®¾å¤‡: {accelerator.device})")
        
        # æµ‹è¯•æ¨¡å‹å‡†å¤‡
        import torch.nn as nn
        model = nn.Linear(10, 1)
        optimizer = torch.optim.Adam(model.parameters())
        
        model, optimizer = accelerator.prepare(model, optimizer)
        print("âœ… æ¨¡å‹å’Œä¼˜åŒ–å™¨å‡†å¤‡æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ Accelerateæµ‹è¯•å¤±è´¥: {e}")
        return False

def install_missing_packages(results):
    """å®‰è£…ç¼ºå¤±çš„åŒ…"""
    print("\nğŸ“¥ å®‰è£…ç¼ºå¤±æˆ–è¿‡æ—¶çš„åŒ…...")
    
    to_install = []
    for package, info in results.items():
        if info['status'] in ['missing', 'outdated']:
            if package == 'PIL':
                to_install.append('Pillow>=9.5.0')
            elif package == 'cv2':
                to_install.append('opencv-python>=4.8.0')
            elif package == 'sklearn':
                to_install.append('scikit-learn>=1.3.0')
            elif package == 'skimage':
                to_install.append('scikit-image>=0.21.0')
            else:
                to_install.append(f"{package}>={info['required']}")
    
    if to_install:
        print(f"éœ€è¦å®‰è£…: {', '.join(to_install)}")
        
        response = input("æ˜¯å¦è‡ªåŠ¨å®‰è£…? (y/n): ")
        if response.lower() == 'y':
            for package in to_install:
                print(f"å®‰è£… {package}...")
                try:
                    subprocess.check_call([sys.executable, "-m", "pip", "install", package])
                    print(f"âœ… {package} å®‰è£…æˆåŠŸ")
                except subprocess.CalledProcessError as e:
                    print(f"âŒ {package} å®‰è£…å¤±è´¥: {e}")
        else:
            print("è·³è¿‡è‡ªåŠ¨å®‰è£…")
    else:
        print("âœ… æ‰€æœ‰åŒ…éƒ½å·²æ­£ç¡®å®‰è£…")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¾®å¤šæ™®å‹’VAEé¡¹ç›® - ä¾èµ–å’ŒAPIå…¼å®¹æ€§æµ‹è¯•")
    print("=" * 60)
    
    all_tests_passed = True
    
    # 1. Pythonç‰ˆæœ¬æ£€æŸ¥
    if not check_python_version():
        all_tests_passed = False
    
    # 2. åŒ…ç‰ˆæœ¬æ£€æŸ¥
    results, versions_ok = check_package_versions()
    if not versions_ok:
        all_tests_passed = False
        install_missing_packages(results)
        
        # é‡æ–°æ£€æŸ¥
        print("\nğŸ”„ é‡æ–°æ£€æŸ¥åŒ…ç‰ˆæœ¬...")
        results, versions_ok = check_package_versions()
    
    # 3. APIå…¼å®¹æ€§æµ‹è¯•
    if not test_diffusers_api():
        all_tests_passed = False
    
    if not test_torch_functionality():
        all_tests_passed = False
    
    if not test_data_loading():
        all_tests_passed = False
    
    if not test_training_components():
        all_tests_passed = False
    
    if not test_accelerate():
        all_tests_passed = False
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    if all_tests_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¯å¢ƒå·²å‡†å¤‡å°±ç»ª")
        print("âœ… å¯ä»¥å®‰å…¨åœ°å¼€å§‹è®­ç»ƒ")
        
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        print("1. python kaggle_config.py  # éªŒè¯æ•°æ®é›†")
        print("2. python train_kaggle.py --stage all  # å¼€å§‹è®­ç»ƒ")
        
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        print("âš ï¸  è¯·è§£å†³ä¸Šè¿°é—®é¢˜åå†å¼€å§‹è®­ç»ƒ")
        
        print("\nğŸ”§ å¸¸è§è§£å†³æ–¹æ¡ˆ:")
        print("1. å‡çº§pip: pip install --upgrade pip")
        print("2. å®‰è£…/å‡çº§åŒ…: pip install -r requirements.txt")
        print("3. é‡å¯Pythonç¯å¢ƒ")
    
    return all_tests_passed

if __name__ == "__main__":
    main()
