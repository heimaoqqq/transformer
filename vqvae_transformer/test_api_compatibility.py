#!/usr/bin/env python3
"""
APIå…¼å®¹æ€§æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¸åŒç‰ˆæœ¬diffusersçš„APIè·¯å¾„å’ŒåŠŸèƒ½
"""

import importlib
import torch

def test_diffusers_version():
    """æµ‹è¯•diffusersç‰ˆæœ¬"""
    print("ğŸ” æ£€æŸ¥diffusersç‰ˆæœ¬...")
    
    try:
        import diffusers
        version = diffusers.__version__
        print(f"âœ… diffusersç‰ˆæœ¬: {version}")
        return version
    except ImportError:
        print("âŒ diffusersæœªå®‰è£…")
        return None

def test_vqmodel_import_paths():
    """æµ‹è¯•VQModelçš„ä¸åŒå¯¼å…¥è·¯å¾„"""
    print("\nğŸ§ª æµ‹è¯•VQModelå¯¼å…¥è·¯å¾„...")
    
    import_paths = [
        ("diffusers.models.autoencoders.vq_model", "VQModel", "æ–°ç‰ˆAPI (0.24.0+)"),
        ("diffusers.models.vq_model", "VQModel", "æ—§ç‰ˆAPI (0.20.0-0.23.x)"),
        ("diffusers", "VQModel", "ç›´æ¥å¯¼å…¥ (æ›´æ—§ç‰ˆæœ¬)"),
    ]
    
    successful_imports = []
    
    for module_path, class_name, description in import_paths:
        try:
            module = importlib.import_module(module_path)
            vq_class = getattr(module, class_name)
            print(f"âœ… {description}: {module_path}.{class_name}")
            successful_imports.append((vq_class, description))
        except (ImportError, AttributeError) as e:
            print(f"âŒ {description}: {e}")
    
    return successful_imports

def test_vqmodel_creation(vq_class, description):
    """æµ‹è¯•VQModelåˆ›å»º"""
    print(f"\nğŸ—ï¸ æµ‹è¯•VQModelåˆ›å»º ({description})...")
    
    # ä¸åŒçš„é…ç½®å‚æ•°ç»„åˆ
    configs = [
        {
            "name": "ç®€å•é…ç½®",
            "params": {
                "in_channels": 3,
                "out_channels": 3,
                "down_block_types": ["DownEncoderBlock2D"],
                "up_block_types": ["UpDecoderBlock2D"],
                "block_out_channels": [64],
                "layers_per_block": 1,
                "latent_channels": 64,
                "sample_size": 32,
                "num_vq_embeddings": 128,
                "norm_num_groups": 32,
                "vq_embed_dim": 64,
            }
        },
        {
            "name": "æ ‡å‡†é…ç½®",
            "params": {
                "in_channels": 3,
                "out_channels": 3,
                "down_block_types": ["DownEncoderBlock2D", "DownEncoderBlock2D"],
                "up_block_types": ["UpDecoderBlock2D", "UpDecoderBlock2D"],
                "block_out_channels": [128, 256],
                "layers_per_block": 2,
                "latent_channels": 256,
                "sample_size": 64,
                "num_vq_embeddings": 512,
                "norm_num_groups": 32,
                "vq_embed_dim": 256,
            }
        }
    ]
    
    for config in configs:
        try:
            print(f"   å°è¯•{config['name']}...")
            model = vq_class(**config['params'])
            print(f"   âœ… {config['name']}åˆ›å»ºæˆåŠŸ")
            
            # æµ‹è¯•å‰å‘ä¼ æ’­
            sample_size = config['params']['sample_size']
            test_input = torch.randn(1, 3, sample_size, sample_size)
            
            with torch.no_grad():
                result = model.encode(test_input)
                print(f"   âœ… ç¼–ç æˆåŠŸ: {result.latents.shape}")
                
                decoded = model.decode(result.latents)
                print(f"   âœ… è§£ç æˆåŠŸ: {decoded.sample.shape}")
            
            return True, config['name']
            
        except Exception as e:
            print(f"   âŒ {config['name']}å¤±è´¥: {e}")
            continue
    
    return False, None

def test_huggingface_hub():
    """æµ‹è¯•HuggingFace Hub API"""
    print("\nğŸ¤— æµ‹è¯•HuggingFace Hub API...")
    
    try:
        import huggingface_hub
        version = huggingface_hub.__version__
        print(f"âœ… huggingface_hubç‰ˆæœ¬: {version}")
        
        # æµ‹è¯•cached_download
        try:
            from huggingface_hub import cached_download
            print("âœ… cached_download: å¯ç”¨")
            return True
        except ImportError as e:
            print(f"âŒ cached_download: ä¸å¯ç”¨ - {e}")
            
            # å°è¯•æ–°çš„API
            try:
                from huggingface_hub import hf_hub_download
                print("âœ… hf_hub_download: å¯ç”¨ (æ–°API)")
                return True
            except ImportError:
                print("âŒ æ‰€æœ‰ä¸‹è½½APIéƒ½ä¸å¯ç”¨")
                return False
                
    except ImportError:
        print("âŒ huggingface_hubæœªå®‰è£…")
        return False

def test_transformers_api():
    """æµ‹è¯•Transformers API"""
    print("\nğŸ¤– æµ‹è¯•Transformers API...")
    
    try:
        import transformers
        version = transformers.__version__
        print(f"âœ… transformersç‰ˆæœ¬: {version}")
        
        # æµ‹è¯•GPT2
        from transformers import GPT2Config, GPT2LMHeadModel
        
        config = GPT2Config(
            vocab_size=256,
            n_positions=64,
            n_embd=128,
            n_layer=2,
            n_head=4,
            use_cache=False,
        )
        
        model = GPT2LMHeadModel(config)
        print("âœ… GPT2æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_input = torch.randint(0, 256, (1, 16))
        with torch.no_grad():
            output = model(test_input)
            print(f"âœ… GPT2å‰å‘ä¼ æ’­æˆåŠŸ: {output.logits.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Transformersæµ‹è¯•å¤±è´¥: {e}")
        return False

def generate_compatibility_report():
    """ç”Ÿæˆå…¼å®¹æ€§æŠ¥å‘Š"""
    print("\nğŸ“„ ç”Ÿæˆå…¼å®¹æ€§æŠ¥å‘Š...")
    
    report = "# VQ-VAE + Transformer APIå…¼å®¹æ€§æŠ¥å‘Š\n\n"
    
    # ç‰ˆæœ¬ä¿¡æ¯
    report += "## ç‰ˆæœ¬ä¿¡æ¯\n"
    
    packages = ['torch', 'diffusers', 'transformers', 'huggingface_hub', 'accelerate']
    for package in packages:
        try:
            module = importlib.import_module(package)
            version = getattr(module, '__version__', 'unknown')
            report += f"- {package}: {version}\n"
        except ImportError:
            report += f"- {package}: æœªå®‰è£…\n"
    
    report += "\n## æµ‹è¯•ç»“æœ\n"
    
    # è¿è¡Œæµ‹è¯•
    diffusers_version = test_diffusers_version()
    vqmodel_imports = test_vqmodel_import_paths()
    hub_ok = test_huggingface_hub()
    transformers_ok = test_transformers_api()
    
    # VQModelæµ‹è¯•
    vqmodel_ok = False
    working_config = None
    
    for vq_class, description in vqmodel_imports:
        success, config_name = test_vqmodel_creation(vq_class, description)
        if success:
            vqmodel_ok = True
            working_config = f"{description} - {config_name}"
            break
    
    # æ·»åŠ åˆ°æŠ¥å‘Š
    report += f"- diffusersç‰ˆæœ¬: {diffusers_version or 'æœªå®‰è£…'}\n"
    report += f"- VQModelå¯¼å…¥: {'âœ… æˆåŠŸ' if vqmodel_imports else 'âŒ å¤±è´¥'}\n"
    report += f"- VQModelåˆ›å»º: {'âœ… æˆåŠŸ' if vqmodel_ok else 'âŒ å¤±è´¥'}\n"
    if working_config:
        report += f"  - å·¥ä½œé…ç½®: {working_config}\n"
    report += f"- HuggingFace Hub: {'âœ… æˆåŠŸ' if hub_ok else 'âŒ å¤±è´¥'}\n"
    report += f"- Transformers: {'âœ… æˆåŠŸ' if transformers_ok else 'âŒ å¤±è´¥'}\n"
    
    # æ€»ä½“è¯„ä¼°
    report += "\n## æ€»ä½“è¯„ä¼°\n"
    
    if vqmodel_ok and hub_ok and transformers_ok:
        report += "âœ… **ç¯å¢ƒå®Œå…¨å…¼å®¹** - å¯ä»¥å¼€å§‹è®­ç»ƒ\n"
    elif vqmodel_ok and transformers_ok:
        report += "âš ï¸ **åŸºæœ¬å…¼å®¹** - å¯ä»¥è®­ç»ƒï¼Œä½†å¯èƒ½æœ‰ä¸‹è½½é—®é¢˜\n"
    else:
        report += "âŒ **ç¯å¢ƒä¸å…¼å®¹** - éœ€è¦ä¿®å¤ç¯å¢ƒ\n"
        report += "\n### å»ºè®®ä¿®å¤æ­¥éª¤:\n"
        if not vqmodel_ok:
            report += "1. è¿è¡Œ: `python setup_environment.py`\n"
        if not hub_ok:
            report += "2. å®‰è£…å…¼å®¹çš„huggingface_hub: `pip install huggingface-hub==0.17.3`\n"
        if not transformers_ok:
            report += "3. å®‰è£…å…¼å®¹çš„transformers: `pip install transformers==4.35.2`\n"
    
    # ä¿å­˜æŠ¥å‘Š
    with open("api_compatibility_report.md", "w", encoding="utf-8") as f:
        f.write(report)
    
    print("âœ… å…¼å®¹æ€§æŠ¥å‘Šä¿å­˜åˆ°: api_compatibility_report.md")
    
    return vqmodel_ok and hub_ok and transformers_ok

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ VQ-VAE + Transformer APIå…¼å®¹æ€§æµ‹è¯•")
    print("=" * 60)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•å¹¶ç”ŸæˆæŠ¥å‘Š
    overall_success = generate_compatibility_report()
    
    print(f"\n{'='*20} æµ‹è¯•æ€»ç»“ {'='*20}")
    
    if overall_success:
        print("ğŸ‰ æ‰€æœ‰APIæµ‹è¯•é€šè¿‡!")
        print("âœ… ç¯å¢ƒå®Œå…¨å…¼å®¹ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ")
        print("\nğŸš€ ä¸‹ä¸€æ­¥:")
        print("   python train_main.py --data_dir /path/to/data")
    else:
        print("âš ï¸ éƒ¨åˆ†APIæµ‹è¯•å¤±è´¥")
        print("ğŸ’¡ å»ºè®®:")
        print("1. æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: api_compatibility_report.md")
        print("2. è¿è¡Œä¿®å¤è„šæœ¬: python quick_fix_environment.py")
        print("3. é‡æ–°æµ‹è¯•: python test_api_compatibility.py")

if __name__ == "__main__":
    main()
