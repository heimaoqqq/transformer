#!/usr/bin/env python3
"""
ä½¿ç”¨diffusersæ ‡å‡†ç»„ä»¶è®­ç»ƒTransformerçš„ä¸»å…¥å£
åŸºäºæˆç†Ÿçš„ã€ç»è¿‡éªŒè¯çš„diffuserså®ç°
"""

import argparse
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from training.train_diffusers_transformer import DiffusersTransformerTrainer

def main():
    parser = argparse.ArgumentParser(description="ä½¿ç”¨diffusersæ ‡å‡†ç»„ä»¶è®­ç»ƒTransformer")
    
    # æ•°æ®å‚æ•°
    parser.add_argument("--data_dir", type=str, required=True, help="æ•°æ®ç›®å½•")
    parser.add_argument("--vqvae_path", type=str, required=True, help="VQ-VAEæ¨¡å‹è·¯å¾„")
    parser.add_argument("--output_dir", type=str, default="./diffusers_transformer_output", help="è¾“å‡ºç›®å½•")
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument("--vocab_size", type=int, default=1024, help="è¯æ±‡è¡¨å¤§å°")
    parser.add_argument("--max_seq_len", type=int, default=1024, help="æœ€å¤§åºåˆ—é•¿åº¦")
    parser.add_argument("--num_users", type=int, default=31, help="ç”¨æˆ·æ•°é‡")
    parser.add_argument("--num_layers", type=int, default=8, help="Transformerå±‚æ•°")
    parser.add_argument("--num_attention_heads", type=int, default=8, help="æ³¨æ„åŠ›å¤´æ•°")
    parser.add_argument("--attention_head_dim", type=int, default=64, help="æ³¨æ„åŠ›å¤´ç»´åº¦")
    parser.add_argument("--dropout", type=float, default=0.1, help="Dropoutç‡")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--batch_size", type=int, default=8, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--num_epochs", type=int, default=50, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--learning_rate", type=float, default=1e-4, help="å­¦ä¹ ç‡")
    parser.add_argument("--weight_decay", type=float, default=0.01, help="æƒé‡è¡°å‡")
    parser.add_argument("--num_workers", type=int, default=4, help="æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°")
    parser.add_argument("--save_every", type=int, default=10, help="ä¿å­˜æ£€æŸ¥ç‚¹é—´éš”")
    
    args = parser.parse_args()
    
    print("ğŸš€ ä½¿ç”¨diffusersæ ‡å‡†ç»„ä»¶è®­ç»ƒTransformer")
    print("=" * 60)
    print(f"ğŸ“‚ æ•°æ®ç›®å½•: {args.data_dir}")
    print(f"ğŸ¤– VQ-VAEè·¯å¾„: {args.vqvae_path}")
    print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ“Š æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"ğŸ”„ è®­ç»ƒè½®æ•°: {args.num_epochs}")
    print(f"ğŸ“ˆ å­¦ä¹ ç‡: {args.learning_rate}")
    print("=" * 60)
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    trainer = DiffusersTransformerTrainer(args)
    trainer.train()

if __name__ == "__main__":
    main()
