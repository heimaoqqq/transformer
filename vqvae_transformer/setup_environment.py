#!/usr/bin/env python3
"""
VQ-VAE + Transformer ç»Ÿä¸€ç¯å¢ƒå®‰è£…è„šæœ¬
å€Ÿé‰´ultimate_fix_kaggle.pyæ€è·¯ï¼Œä½¿ç”¨ç»è¿‡éªŒè¯çš„å›ºå®šç‰ˆæœ¬ç»„åˆ
"""

import os
import sys
import subprocess
import importlib

def run_command(cmd, description="", ignore_errors=False):
    """è¿è¡Œå‘½ä»¤å¹¶å¤„ç†é”™è¯¯"""
    print(f"ğŸ”„ {description}")

    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        if result.returncode == 0 or ignore_errors:
            print(f"âœ… {description} æˆåŠŸ")
            return True
        else:
            print(f"âŒ {description} å¤±è´¥")
            if result.stderr and not ignore_errors:
                print(f"   é”™è¯¯: {result.stderr.strip()}")
            return False
    except Exception as e:
        print(f"âŒ {description} å¼‚å¸¸: {e}")
        return False

def detect_environment():
    """æ£€æµ‹è¿è¡Œç¯å¢ƒ"""
    print("ğŸ” æ£€æµ‹è¿è¡Œç¯å¢ƒ...")
    
    if any([os.path.exists('/kaggle'), 'KAGGLE_KERNEL_RUN_TYPE' in os.environ]):
        print("âœ… æ£€æµ‹åˆ°Kaggleç¯å¢ƒ")
        return "kaggle"
    
    try:
        import google.colab
        print("âœ… æ£€æµ‹åˆ°Google Colabç¯å¢ƒ")
        return "colab"
    except ImportError:
        pass
    
    print("âœ… æ£€æµ‹åˆ°æœ¬åœ°ç¯å¢ƒ")
    return "local"

def clean_environment():
    """æ¸…ç†ç¯å¢ƒ - ç§»é™¤å¯èƒ½å†²çªçš„åŒ…"""
    print("\nğŸ—‘ï¸ æ¸…ç†å¯èƒ½å†²çªçš„åŒ…...")

    # æ¸…ç†Pythonæ¨¡å—ç¼“å­˜
    try:
        modules_to_clear = ['numpy', 'torch', 'diffusers', 'transformers', 'huggingface_hub', 'accelerate']
        for module in modules_to_clear:
            if module in sys.modules:
                del sys.modules[module]
        print("âœ… Pythonæ¨¡å—ç¼“å­˜å·²æ¸…ç†")
    except:
        pass

    # å¸è½½å¯èƒ½å†²çªçš„åŒ…
    packages_to_remove = [
        "diffusers", "transformers", "accelerate", "huggingface_hub", "huggingface-hub",
        "tokenizers", "safetensors", "datasets", "evaluate", "peft", "trl",
        "jax", "jaxlib", "flax", "optax"  # JAXç›¸å…³åŒ…å¯èƒ½å¯¼è‡´numpyå†²çª
    ]

    for package in packages_to_remove:
        run_command(f"pip uninstall -y {package}", f"å¸è½½ {package}", ignore_errors=True)

    # æ¸…ç†pipç¼“å­˜
    run_command("pip cache purge", "æ¸…ç†pipç¼“å­˜", ignore_errors=True)

    return True

def install_core_packages():
    """å®‰è£…æ ¸å¿ƒåŒ… - ä½¿ç”¨ç»è¿‡éªŒè¯çš„å›ºå®šç‰ˆæœ¬"""
    print("\nğŸ”§ å®‰è£…æ ¸å¿ƒåŒ…...")

    # å‡çº§åŸºç¡€å·¥å…·
    run_command("pip install --upgrade pip setuptools wheel", "å‡çº§åŸºç¡€å·¥å…·")

    # å®‰è£…å…¼å®¹çš„numpyç‰ˆæœ¬ - è§£å†³JAXå…¼å®¹æ€§é—®é¢˜
    numpy_versions = ["1.26.4", "1.24.4", "1.23.5"]
    for version in numpy_versions:
        if run_command(f"pip install numpy=={version}", f"å®‰è£…numpy {version}"):
            break

    # å®‰è£…å…¶ä»–æ ¸å¿ƒä¾èµ– - ä½¿ç”¨å›ºå®šç‰ˆæœ¬
    core_deps = [
        ("pillow==10.0.1", "Pillow"),
        ("requests==2.31.0", "Requests"),
        ("packaging==23.2", "Packaging"),
        ("filelock==3.13.1", "FileLock"),
        ("tqdm==4.66.1", "TQDM"),
        ("pyyaml==6.0.1", "PyYAML"),
        ("typing-extensions==4.8.0", "Typing Extensions"),
        ("regex==2023.10.3", "Regex"),
    ]

    for package, name in core_deps:
        run_command(f"pip install {package}", f"å®‰è£… {name}", ignore_errors=True)

    return True

def check_gpu_environment():
    """æ£€æŸ¥GPUç¯å¢ƒ"""
    print("\nğŸ” æ£€æŸ¥GPUç¯å¢ƒ...")

    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… nvidia-smiå¯ç”¨")
            # æ£€æŸ¥GPUç±»å‹
            lines = result.stdout.split('\n')
            for line in lines:
                if any(gpu in line for gpu in ['Tesla', 'T4', 'P100', 'V100', 'A100']):
                    print(f"   ğŸ¯ æ£€æµ‹åˆ°GPU: {line.strip()}")
                    return True
            print("âš ï¸ nvidia-smiè¿è¡Œä½†æœªæ£€æµ‹åˆ°GPU")
            return False
        else:
            print("âŒ nvidia-smiå¤±è´¥")
            return False
    except Exception as e:
        print(f"âŒ nvidia-smiå¼‚å¸¸: {e}")
        return False

def install_pytorch(env_type):
    """å®‰è£…PyTorch - ä½¿ç”¨ç»è¿‡éªŒè¯çš„å›ºå®šç‰ˆæœ¬"""
    print("\nğŸ”¥ å®‰è£…PyTorch...")

    if env_type == "kaggle":
        try:
            import torch
            print(f"âœ… ä½¿ç”¨Kaggleé¢„è£…PyTorch: {torch.__version__}")
            return True
        except ImportError:
            pass

    # æ£€æŸ¥GPUç¯å¢ƒ
    has_gpu = check_gpu_environment()

    if has_gpu:
        print("ğŸ¯ æ£€æµ‹åˆ°GPUï¼Œå®‰è£…CUDAç‰ˆæœ¬PyTorch")
        # GPUç¯å¢ƒï¼šä½¿ç”¨ç»è¿‡éªŒè¯çš„CUDAç‰ˆæœ¬
        pytorch_options = [
            {
                "cmd": "pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118",
                "desc": "PyTorch 2.1.0 CUDA 11.8ç‰ˆæœ¬"
            },
            {
                "cmd": "pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu118",
                "desc": "PyTorch 2.0.1 CUDA 11.8ç‰ˆæœ¬"
            },
            {
                "cmd": "pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0",
                "desc": "PyTorch 2.1.0 é»˜è®¤ç‰ˆæœ¬"
            }
        ]
    else:
        print("ğŸ’» æœªæ£€æµ‹åˆ°GPUï¼Œå®‰è£…CPUç‰ˆæœ¬PyTorch")
        # CPUç¯å¢ƒï¼šä½¿ç”¨CPUç‰ˆæœ¬
        pytorch_options = [
            {
                "cmd": "pip install torch==2.1.0+cpu torchvision==0.16.0+cpu torchaudio==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu",
                "desc": "PyTorch 2.1.0 CPUç‰ˆæœ¬"
            },
            {
                "cmd": "pip install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1",
                "desc": "PyTorch 1.13.1 ä¿å®ˆç‰ˆæœ¬"
            }
        ]

    for i, option in enumerate(pytorch_options, 1):
        print(f"\nå°è¯•æ–¹æ¡ˆ {i}: {option['desc']}")
        if run_command(option["cmd"], option["desc"]):
            print(f"âœ… PyTorchæ–¹æ¡ˆ {i} å®‰è£…æˆåŠŸ")
            return True

    print("âŒ æ‰€æœ‰PyTorchå®‰è£…æ–¹æ¡ˆéƒ½å¤±è´¥")
    return False

def install_huggingface_stack():
    """å®‰è£…HuggingFaceæŠ€æœ¯æ ˆ - ä½¿ç”¨ç»è¿‡éªŒè¯çš„å›ºå®šç‰ˆæœ¬ç»„åˆ"""
    print("\nğŸ¤— å®‰è£…HuggingFaceæŠ€æœ¯æ ˆ...")

    # ä½¿ç”¨ç»è¿‡éªŒè¯çš„ç¨³å®šç‰ˆæœ¬ç»„åˆ - å€Ÿé‰´ultimate_fix_kaggle.py
    # è¿™äº›ç‰ˆæœ¬ç»è¿‡æµ‹è¯•ï¼Œè§£å†³äº†cached_downloadå…¼å®¹æ€§é—®é¢˜
    hf_packages = [
        ("huggingface_hub==0.17.3", "HuggingFace Hub"),  # æ”¯æŒcached_download
        ("tokenizers==0.14.1", "Tokenizers"),            # ä¸transformerså…¼å®¹
        ("safetensors==0.4.0", "SafeTensors"),           # ç¨³å®šç‰ˆæœ¬
        ("transformers==4.35.2", "Transformers"),        # ç¨³å®šç‰ˆæœ¬ï¼Œæ”¯æŒæ‰€æœ‰åŠŸèƒ½
        ("accelerate==0.24.1", "Accelerate"),            # ç¨³å®šç‰ˆæœ¬ï¼Œæ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ
        ("diffusers==0.24.0", "Diffusers"),              # ä¸huggingface_hubå®Œå…¨å…¼å®¹
    ]

    print("ğŸ”§ ä½¿ç”¨ç»è¿‡éªŒè¯çš„å›ºå®šç‰ˆæœ¬ç»„åˆ...")

    success_count = 0
    for package, name in hf_packages:
        # å…ˆå°è¯•å¼ºåˆ¶é‡è£…ä»¥ç¡®ä¿ç‰ˆæœ¬æ­£ç¡®
        if run_command(f"pip install --force-reinstall {package}", f"å¼ºåˆ¶å®‰è£… {name}"):
            success_count += 1
        else:
            # å¦‚æœå¼ºåˆ¶é‡è£…å¤±è´¥ï¼Œå°è¯•æ™®é€šå®‰è£…
            print(f"   âš ï¸ {name} å¼ºåˆ¶å®‰è£…å¤±è´¥ï¼Œå°è¯•æ™®é€šå®‰è£…...")
            if run_command(f"pip install {package}", f"å®‰è£… {name}"):
                success_count += 1
            else:
                print(f"   âŒ {name} å®‰è£…å¤±è´¥")

    print(f"\nğŸ“Š HuggingFaceåŒ…å®‰è£…ç»“æœ: {success_count}/{len(hf_packages)} æˆåŠŸ")

    # éªŒè¯å…³é”®å…¼å®¹æ€§ - cached_download
    print("\nğŸ” éªŒè¯å…³é”®å…¼å®¹æ€§...")
    try:
        from huggingface_hub import cached_download
        print("âœ… cached_download éªŒè¯æˆåŠŸ")
        return True
    except ImportError:
        print("âŒ cached_download ä»ç„¶ä¸å¯ç”¨")
        print("ğŸ”§ æ‰§è¡Œå¼ºåŠ›ä¿®å¤...")

        # å¼ºåŠ›ä¿®å¤ï¼šå®Œå…¨é‡è£…å…³é”®åŒ…
        critical_packages = [
            "huggingface_hub==0.17.3",
            "diffusers==0.24.0"
        ]

        for package in critical_packages:
            print(f"ğŸ”„ å¼ºåŠ›é‡è£… {package}...")
            package_name = package.split('==')[0]
            run_command(f"pip uninstall {package_name} -y", f"å¸è½½ {package_name}", ignore_errors=True)
            run_command("pip cache purge", "æ¸…ç†ç¼“å­˜", ignore_errors=True)
            run_command(f"pip install --no-cache-dir {package}", f"é‡è£… {package}")

        # æœ€ç»ˆéªŒè¯ - å½»åº•æ¸…ç†æ¨¡å—ç¼“å­˜
        try:
            print("ğŸ§¹ å½»åº•æ¸…ç†Pythonæ¨¡å—ç¼“å­˜...")

            # æ¸…ç†æ‰€æœ‰ç›¸å…³æ¨¡å—å’Œå­æ¨¡å—
            modules_to_clear = []
            for module_name in list(sys.modules.keys()):
                if any(pattern in module_name for pattern in [
                    'huggingface_hub', 'diffusers', 'transformers',
                    'tokenizers', 'safetensors'
                ]):
                    modules_to_clear.append(module_name)

            for module_name in modules_to_clear:
                if module_name in sys.modules:
                    del sys.modules[module_name]
                    print(f"   æ¸…ç†æ¨¡å—: {module_name}")

            print(f"âœ… æ¸…ç†äº† {len(modules_to_clear)} ä¸ªæ¨¡å—")

            # å¼ºåˆ¶é‡æ–°å¯¼å…¥
            print("ğŸ”„ å¼ºåˆ¶é‡æ–°å¯¼å…¥...")
            import importlib

            # é‡æ–°å¯¼å…¥huggingface_hub
            import huggingface_hub
            importlib.reload(huggingface_hub)

            # æµ‹è¯•cached_download
            from huggingface_hub import cached_download
            print("âœ… cached_download å¯¼å…¥æˆåŠŸ")

            # è¿›ä¸€æ­¥æµ‹è¯•APIå¯ç”¨æ€§
            print("ğŸ§ª æµ‹è¯•cached_download API...")
            # ä¸å®é™…ä¸‹è½½ï¼Œåªæµ‹è¯•å‡½æ•°æ˜¯å¦å­˜åœ¨å’Œå¯è°ƒç”¨
            if callable(cached_download):
                print("âœ… cached_download API å¯ç”¨")
                return True
            else:
                print("âŒ cached_download ä¸å¯è°ƒç”¨")
                return False

        except ImportError as e:
            print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
            print("ğŸ”§ å°è¯•æ›¿ä»£API...")

            # å°è¯•æ–°çš„API
            try:
                from huggingface_hub import hf_hub_download
                print("âœ… æ‰¾åˆ°æ›¿ä»£API: hf_hub_download")
                print("âš ï¸ éœ€è¦æ›´æ–°ä»£ç ä½¿ç”¨æ–°API")
                return True
            except ImportError:
                print("âŒ æ‰€æœ‰APIéƒ½ä¸å¯ç”¨")
                print("ğŸ’¡ å»ºè®®:")
                print("1. é‡å¯Pythonå†…æ ¸")
                print("2. æ‰‹åŠ¨å®‰è£…: pip install huggingface_hub==0.17.3 --force-reinstall --no-cache-dir")
                print("3. æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–åŒ…å†²çª")
                return False
        except Exception as e:
            print(f"âŒ å…¶ä»–é”™è¯¯: {e}")
            return False
    except Exception as e:
        print(f"âš ï¸ å…¶ä»–éªŒè¯é—®é¢˜: {e}")
        return success_count == len(hf_packages)

def fix_huggingface_api():
    """ä¸“é—¨ä¿®å¤HuggingFace APIå…¼å®¹æ€§é—®é¢˜"""
    print("\nğŸ”§ HuggingFace APIå…¼å®¹æ€§ä¿®å¤...")

    # æ£€æŸ¥å½“å‰å®‰è£…çš„ç‰ˆæœ¬
    try:
        import huggingface_hub
        current_version = huggingface_hub.__version__
        print(f"ğŸ“Š å½“å‰huggingface_hubç‰ˆæœ¬: {current_version}")
    except ImportError:
        print("âŒ huggingface_hubæœªå®‰è£…")
        return False

    # æµ‹è¯•ä¸åŒçš„API
    api_tests = [
        ("cached_download", "from huggingface_hub import cached_download"),
        ("hf_hub_download", "from huggingface_hub import hf_hub_download"),
        ("snapshot_download", "from huggingface_hub import snapshot_download"),
    ]

    available_apis = []

    for api_name, import_cmd in api_tests:
        try:
            exec(import_cmd)
            available_apis.append(api_name)
            print(f"âœ… {api_name}: å¯ç”¨")
        except ImportError as e:
            print(f"âŒ {api_name}: ä¸å¯ç”¨ - {e}")

    if not available_apis:
        print("âŒ æ‰€æœ‰HuggingFaceä¸‹è½½APIéƒ½ä¸å¯ç”¨")

        # å°è¯•é™çº§åˆ°æ›´ç¨³å®šçš„ç‰ˆæœ¬
        stable_versions = ["0.16.4", "0.15.1", "0.14.1"]

        for version in stable_versions:
            print(f"ğŸ”„ å°è¯•é™çº§åˆ° huggingface_hub=={version}...")

            # å®Œå…¨å¸è½½
            run_command("pip uninstall huggingface_hub -y", f"å¸è½½å½“å‰ç‰ˆæœ¬", ignore_errors=True)
            run_command("pip cache purge", "æ¸…ç†ç¼“å­˜", ignore_errors=True)

            # å®‰è£…æŒ‡å®šç‰ˆæœ¬
            if run_command(f"pip install huggingface_hub=={version} --no-cache-dir", f"å®‰è£…ç‰ˆæœ¬ {version}"):
                # æ¸…ç†æ¨¡å—ç¼“å­˜
                for module_name in list(sys.modules.keys()):
                    if 'huggingface_hub' in module_name:
                        del sys.modules[module_name]

                # é‡æ–°æµ‹è¯•
                try:
                    import huggingface_hub
                    from huggingface_hub import cached_download
                    print(f"âœ… ç‰ˆæœ¬ {version} å·¥ä½œæ­£å¸¸")
                    return True
                except ImportError:
                    print(f"âŒ ç‰ˆæœ¬ {version} ä»ç„¶æœ‰é—®é¢˜")
                    continue

        print("âŒ æ‰€æœ‰ç‰ˆæœ¬éƒ½æ— æ³•è§£å†³APIé—®é¢˜")
        return False

    else:
        print(f"âœ… æ‰¾åˆ°å¯ç”¨çš„API: {', '.join(available_apis)}")

        # å¦‚æœcached_downloadä¸å¯ç”¨ä½†æœ‰å…¶ä»–APIï¼Œæä¾›æ›¿ä»£æ–¹æ¡ˆ
        if "cached_download" not in available_apis:
            print("âš ï¸ cached_downloadä¸å¯ç”¨ï¼Œä½†æœ‰å…¶ä»–APIå¯ç”¨")
            print("ğŸ’¡ å»ºè®®æ›´æ–°ä»£ç ä½¿ç”¨æ–°çš„API:")

            if "hf_hub_download" in available_apis:
                print("   ä½¿ç”¨ hf_hub_download æ›¿ä»£ cached_download")
            elif "snapshot_download" in available_apis:
                print("   ä½¿ç”¨ snapshot_download æ›¿ä»£ cached_download")

        return True

def install_additional_deps():
    """å®‰è£…å…¶ä»–å¿…è¦ä¾èµ– - ä½¿ç”¨å›ºå®šç‰ˆæœ¬"""
    print("\nğŸ“š å®‰è£…å…¶ä»–ä¾èµ–...")

    additional_deps = [
        ("scipy==1.11.4", "SciPy"),
        ("scikit-learn==1.3.0", "Scikit-learn"),
        ("scikit-image==0.21.0", "Scikit-image"),
        ("matplotlib==3.7.2", "Matplotlib"),
        ("opencv-python==4.8.1.78", "OpenCV"),
        ("einops==0.7.0", "Einops"),
        ("tensorboard==2.15.1", "TensorBoard"),
        ("lpips==0.1.4", "LPIPS"),
    ]

    for package, name in additional_deps:
        run_command(f"pip install {package}", f"å®‰è£… {name}", ignore_errors=True)

    return True

def test_critical_imports():
    """æµ‹è¯•å…³é”®å¯¼å…¥"""
    print("\nğŸ§ª æµ‹è¯•å…³é”®å¯¼å…¥...")
    
    critical_tests = [
        ("torch", "PyTorch"),
        ("diffusers", "Diffusers"),
        ("transformers", "Transformers"),
        ("huggingface_hub", "HuggingFace Hub"),
        ("accelerate", "Accelerate"),
    ]
    
    all_good = True
    
    for module_name, display_name in critical_tests:
        try:
            module = importlib.import_module(module_name)
            version = getattr(module, '__version__', 'unknown')
            print(f"âœ… {display_name}: {version}")
        except ImportError as e:
            print(f"âŒ {display_name}: å¯¼å…¥å¤±è´¥ - {e}")
            all_good = False
    
    return all_good

def test_vqmodel_api():
    """æµ‹è¯•VQModel API"""
    print("\nğŸ¨ æµ‹è¯•VQModel API...")
    
    # å°è¯•ä¸åŒçš„å¯¼å…¥è·¯å¾„
    VQModel = None
    
    import_attempts = [
        ("diffusers.models.autoencoders.vq_model", "æ–°ç‰ˆAPI"),
        ("diffusers.models.vq_model", "æ—§ç‰ˆAPI"),
        ("diffusers", "ç›´æ¥å¯¼å…¥"),
    ]
    
    for module_path, description in import_attempts:
        try:
            if module_path == "diffusers":
                from diffusers import VQModel
            else:
                module = importlib.import_module(module_path)
                VQModel = getattr(module, 'VQModel')
            
            print(f"âœ… VQModelå¯¼å…¥æˆåŠŸ: {description}")
            break
        except (ImportError, AttributeError):
            continue
    
    if VQModel is None:
        print("âŒ VQModel: æ‰€æœ‰å¯¼å…¥è·¯å¾„éƒ½å¤±è´¥")
        return False
    
    # æµ‹è¯•åˆ›å»ºå’Œä½¿ç”¨
    try:
        import torch
        model = VQModel(
            in_channels=3,
            out_channels=3,
            down_block_types=["DownEncoderBlock2D"],
            up_block_types=["UpDecoderBlock2D"],
            block_out_channels=[64],
            layers_per_block=1,
            latent_channels=64,
            sample_size=32,
            num_vq_embeddings=128,
            norm_num_groups=32,
            vq_embed_dim=64,
        )
        
        test_input = torch.randn(1, 3, 32, 32)
        with torch.no_grad():
            result = model.encode(test_input)
            decoded = model.decode(result.latents)
            print(f"âœ… VQModelæµ‹è¯•é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"âŒ VQModelåˆ›å»º/æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_transformer_api():
    """æµ‹è¯•Transformer API"""
    print("\nğŸ¤– æµ‹è¯•Transformer API...")
    
    try:
        from transformers import GPT2Config, GPT2LMHeadModel
        
        config = GPT2Config(
            vocab_size=256,
            n_positions=64,
            n_embd=128,
            n_layer=2,
            n_head=4,
            use_cache=False,
        )
        
        model = GPT2LMHeadModel(config)
        
        import torch
        test_input = torch.randint(0, 256, (1, 16))
        with torch.no_grad():
            output = model(test_input)
            print(f"âœ… Transformeræµ‹è¯•é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"âŒ Transformeræµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ VQ-VAE + Transformer ç»Ÿä¸€ç¯å¢ƒå®‰è£…å™¨")
    print("=" * 60)
    print("ğŸ”§ è§£å†³numpy/JAXå…¼å®¹æ€§å’ŒAPIç‰ˆæœ¬é—®é¢˜")
    
    # æ£€æµ‹ç¯å¢ƒ
    env_type = detect_environment()
    print(f"\nğŸ“Š ç¯å¢ƒç±»å‹: {env_type}")
    
    # ç¡®è®¤æ“ä½œ
    if env_type == "local":
        response = input("\næ˜¯å¦ç»§ç»­å®‰è£…? (y/N): ").strip().lower()
        if response != 'y':
            print("âŒ æ“ä½œå·²å–æ¶ˆ")
            return
    
    # å®‰è£…æµç¨‹ - å€Ÿé‰´ultimate_fix_kaggle.pyçš„é˜¶æ®µåŒ–å®‰è£…
    steps = [
        ("æ¸…ç†ç¯å¢ƒ", clean_environment),
        ("å®‰è£…æ ¸å¿ƒåŒ…", install_core_packages),
        ("å®‰è£…PyTorch", lambda: install_pytorch(env_type)),
        ("å®‰è£…HuggingFaceæŠ€æœ¯æ ˆ", install_huggingface_stack),
        ("ä¿®å¤HuggingFace API", fix_huggingface_api),  # æ–°å¢APIä¿®å¤æ­¥éª¤
        ("å®‰è£…å…¶ä»–ä¾èµ–", install_additional_deps),
        ("æµ‹è¯•å…³é”®å¯¼å…¥", test_critical_imports),
        ("æµ‹è¯•VQModel API", test_vqmodel_api),
        ("æµ‹è¯•Transformer API", test_transformer_api),
    ]

    failed_steps = []

    for step_name, step_func in steps:
        print(f"\n{'='*20} {step_name} {'='*20}")
        success = step_func()

        if not success:
            print(f"âŒ {step_name} å¤±è´¥")
            failed_steps.append(step_name)
            # å¯¹äºå…³é”®æ­¥éª¤ï¼Œå¦‚æœå¤±è´¥åˆ™åœæ­¢
            if step_name in ["å®‰è£…PyTorch", "å®‰è£…HuggingFaceæŠ€æœ¯æ ˆ"]:
                print(f"ğŸ’¥ å…³é”®æ­¥éª¤å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                break
        else:
            print(f"âœ… {step_name} æˆåŠŸ")
    
    # æ€»ç»“
    print(f"\n{'='*20} å®‰è£…æ€»ç»“ {'='*20}")
    
    if not failed_steps:
        print("ğŸ‰ ç¯å¢ƒå®‰è£…å®Œå…¨æˆåŠŸ!")
        print("âœ… æ‰€æœ‰ç»„ä»¶æ­£å¸¸å·¥ä½œ")
        print("\nğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒ:")
        print("   python train_main.py --data_dir /path/to/data")
    else:
        print(f"âš ï¸ éƒ¨åˆ†æ­¥éª¤å¤±è´¥: {', '.join(failed_steps)}")
        
        if "æµ‹è¯•å…³é”®å¯¼å…¥" not in failed_steps:
            print("âœ… åŸºç¡€ç¯å¢ƒå®‰è£…æˆåŠŸï¼Œå¯ä»¥å°è¯•è¿è¡Œ")
            print("ğŸ’¡ å»ºè®®é‡å¯Pythonå†…æ ¸åå†æ¬¡æµ‹è¯•")
        else:
            print("âŒ åŸºç¡€ç¯å¢ƒæœ‰é—®é¢˜ï¼Œå»ºè®®:")
            print("1. é‡å¯Pythonå†…æ ¸")
            print("2. é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
            print("3. æ£€æŸ¥ç½‘ç»œè¿æ¥")

if __name__ == "__main__":
    main()
