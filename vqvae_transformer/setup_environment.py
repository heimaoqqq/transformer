#!/usr/bin/env python3
"""
VQ-VAE + Transformer ç»Ÿä¸€ç¯å¢ƒå®‰è£…è„šæœ¬
è§£å†³numpy/JAXå…¼å®¹æ€§å’ŒAPIç‰ˆæœ¬é—®é¢˜
"""

import os
import sys
import subprocess
import importlib

def run_command(cmd, description="", allow_failure=False):
    """è¿è¡Œå‘½ä»¤å¹¶å¤„ç†é”™è¯¯"""
    print(f"ğŸ”„ {description}")
    
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, check=True)
        print(f"âœ… {description} æˆåŠŸ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {description} å¤±è´¥")
        if e.stderr.strip():
            print(f"   é”™è¯¯: {e.stderr.strip()}")
        if allow_failure:
            print("âš ï¸ æ­¤æ­¥éª¤å…è®¸å¤±è´¥ï¼Œç»§ç»­...")
            return True
        return False

def detect_environment():
    """æ£€æµ‹è¿è¡Œç¯å¢ƒ"""
    print("ğŸ” æ£€æµ‹è¿è¡Œç¯å¢ƒ...")
    
    if any([os.path.exists('/kaggle'), 'KAGGLE_KERNEL_RUN_TYPE' in os.environ]):
        print("âœ… æ£€æµ‹åˆ°Kaggleç¯å¢ƒ")
        return "kaggle"
    
    try:
        import google.colab
        print("âœ… æ£€æµ‹åˆ°Google Colabç¯å¢ƒ")
        return "colab"
    except ImportError:
        pass
    
    print("âœ… æ£€æµ‹åˆ°æœ¬åœ°ç¯å¢ƒ")
    return "local"

def install_core_packages():
    """å®‰è£…æ ¸å¿ƒåŒ… - è§£å†³numpy/JAXå…¼å®¹æ€§é—®é¢˜"""
    print("\nğŸ”§ å®‰è£…æ ¸å¿ƒåŒ…...")
    
    # å…ˆå®‰è£…å…¼å®¹çš„numpyç‰ˆæœ¬ - è§£å†³JAXå…¼å®¹æ€§é—®é¢˜
    success = run_command("pip install 'numpy>=1.26.0,<2.0.0'", "å®‰è£…å…¼å®¹çš„numpy")
    if not success:
        run_command("pip install numpy==1.26.4", "å®‰è£…numpy (æŒ‡å®šç‰ˆæœ¬)")
    
    # å®‰è£…å…¶ä»–æ ¸å¿ƒä¾èµ–
    core_deps = [
        "pillow>=9.0.0",
        "requests>=2.28.0", 
        "packaging>=21.0",
        "filelock>=3.0.0",
        "tqdm>=4.64.0",
        "pyyaml>=6.0",
        "typing-extensions>=4.0.0",
        "regex>=2022.0.0",
    ]
    
    for dep in core_deps:
        run_command(f"pip install '{dep}'", f"å®‰è£… {dep.split('>=')[0]}", allow_failure=True)
    
    return True

def install_pytorch(env_type):
    """å®‰è£…PyTorch"""
    print("\nğŸ”¥ å®‰è£…PyTorch...")
    
    if env_type == "kaggle":
        try:
            import torch
            print(f"âœ… ä½¿ç”¨Kaggleé¢„è£…PyTorch: {torch.__version__}")
            return True
        except ImportError:
            pass
    
    # å®‰è£…PyTorch
    cmd = "pip install 'torch>=2.0.0' 'torchvision>=0.15.0' 'torchaudio>=2.0.0' --index-url https://download.pytorch.org/whl/cu118"
    success = run_command(cmd, "å®‰è£…PyTorch (CUDA)")
    
    if not success:
        cmd = "pip install 'torch>=2.0.0' 'torchvision>=0.15.0' 'torchaudio>=2.0.0'"
        run_command(cmd, "å®‰è£…PyTorch (CPU)")
    
    return True

def install_huggingface_stack():
    """å®‰è£…HuggingFaceæŠ€æœ¯æ ˆ"""
    print("\nğŸ¤— å®‰è£…HuggingFaceæŠ€æœ¯æ ˆ...")
    
    # æŒ‰ä¾èµ–é¡ºåºå®‰è£…
    hf_packages = [
        ("huggingface-hub>=0.17.0,<0.25.0", "HuggingFace Hub"),
        ("tokenizers>=0.14.0,<0.20.0", "Tokenizers"),
        ("safetensors>=0.4.0,<0.5.0", "SafeTensors"),
        ("transformers>=4.35.0,<4.45.0", "Transformers"),
        ("accelerate>=0.24.0,<0.35.0", "Accelerate"),
        ("diffusers>=0.24.0,<0.30.0", "Diffusers"),
    ]
    
    for package_spec, name in hf_packages:
        success = run_command(f"pip install '{package_spec}'", f"å®‰è£… {name}")
        if not success:
            package_name = package_spec.split('>=')[0].split('<')[0]
            run_command(f"pip install {package_name}", f"å®‰è£… {name} (æ— ç‰ˆæœ¬é™åˆ¶)", allow_failure=True)
    
    return True

def install_additional_deps():
    """å®‰è£…å…¶ä»–å¿…è¦ä¾èµ–"""
    print("\nğŸ“š å®‰è£…å…¶ä»–ä¾èµ–...")
    
    additional_deps = [
        "scipy>=1.9.0",
        "scikit-learn>=1.1.0", 
        "scikit-image>=0.19.0",
        "matplotlib>=3.5.0",
        "opencv-python>=4.6.0",
        "einops>=0.6.0",
        "tensorboard>=2.10.0",
        "lpips>=0.1.4",
    ]
    
    for dep in additional_deps:
        run_command(f"pip install '{dep}'", f"å®‰è£… {dep.split('>=')[0]}", allow_failure=True)
    
    return True

def test_critical_imports():
    """æµ‹è¯•å…³é”®å¯¼å…¥"""
    print("\nğŸ§ª æµ‹è¯•å…³é”®å¯¼å…¥...")
    
    critical_tests = [
        ("torch", "PyTorch"),
        ("diffusers", "Diffusers"),
        ("transformers", "Transformers"),
        ("huggingface_hub", "HuggingFace Hub"),
        ("accelerate", "Accelerate"),
    ]
    
    all_good = True
    
    for module_name, display_name in critical_tests:
        try:
            module = importlib.import_module(module_name)
            version = getattr(module, '__version__', 'unknown')
            print(f"âœ… {display_name}: {version}")
        except ImportError as e:
            print(f"âŒ {display_name}: å¯¼å…¥å¤±è´¥ - {e}")
            all_good = False
    
    return all_good

def test_vqmodel_api():
    """æµ‹è¯•VQModel API"""
    print("\nğŸ¨ æµ‹è¯•VQModel API...")
    
    # å°è¯•ä¸åŒçš„å¯¼å…¥è·¯å¾„
    VQModel = None
    
    import_attempts = [
        ("diffusers.models.autoencoders.vq_model", "æ–°ç‰ˆAPI"),
        ("diffusers.models.vq_model", "æ—§ç‰ˆAPI"),
        ("diffusers", "ç›´æ¥å¯¼å…¥"),
    ]
    
    for module_path, description in import_attempts:
        try:
            if module_path == "diffusers":
                from diffusers import VQModel
            else:
                module = importlib.import_module(module_path)
                VQModel = getattr(module, 'VQModel')
            
            print(f"âœ… VQModelå¯¼å…¥æˆåŠŸ: {description}")
            break
        except (ImportError, AttributeError):
            continue
    
    if VQModel is None:
        print("âŒ VQModel: æ‰€æœ‰å¯¼å…¥è·¯å¾„éƒ½å¤±è´¥")
        return False
    
    # æµ‹è¯•åˆ›å»ºå’Œä½¿ç”¨
    try:
        import torch
        model = VQModel(
            in_channels=3,
            out_channels=3,
            down_block_types=["DownEncoderBlock2D"],
            up_block_types=["UpDecoderBlock2D"],
            block_out_channels=[64],
            layers_per_block=1,
            latent_channels=64,
            sample_size=32,
            num_vq_embeddings=128,
            norm_num_groups=32,
            vq_embed_dim=64,
        )
        
        test_input = torch.randn(1, 3, 32, 32)
        with torch.no_grad():
            result = model.encode(test_input)
            decoded = model.decode(result.latents)
            print(f"âœ… VQModelæµ‹è¯•é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"âŒ VQModelåˆ›å»º/æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_transformer_api():
    """æµ‹è¯•Transformer API"""
    print("\nğŸ¤– æµ‹è¯•Transformer API...")
    
    try:
        from transformers import GPT2Config, GPT2LMHeadModel
        
        config = GPT2Config(
            vocab_size=256,
            n_positions=64,
            n_embd=128,
            n_layer=2,
            n_head=4,
            use_cache=False,
        )
        
        model = GPT2LMHeadModel(config)
        
        import torch
        test_input = torch.randint(0, 256, (1, 16))
        with torch.no_grad():
            output = model(test_input)
            print(f"âœ… Transformeræµ‹è¯•é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"âŒ Transformeræµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ VQ-VAE + Transformer ç»Ÿä¸€ç¯å¢ƒå®‰è£…å™¨")
    print("=" * 60)
    print("ğŸ”§ è§£å†³numpy/JAXå…¼å®¹æ€§å’ŒAPIç‰ˆæœ¬é—®é¢˜")
    
    # æ£€æµ‹ç¯å¢ƒ
    env_type = detect_environment()
    print(f"\nğŸ“Š ç¯å¢ƒç±»å‹: {env_type}")
    
    # ç¡®è®¤æ“ä½œ
    if env_type == "local":
        response = input("\næ˜¯å¦ç»§ç»­å®‰è£…? (y/N): ").strip().lower()
        if response != 'y':
            print("âŒ æ“ä½œå·²å–æ¶ˆ")
            return
    
    # å®‰è£…æµç¨‹
    steps = [
        ("å®‰è£…æ ¸å¿ƒåŒ…", install_core_packages),
        ("å®‰è£…PyTorch", lambda: install_pytorch(env_type)),
        ("å®‰è£…HuggingFaceæŠ€æœ¯æ ˆ", install_huggingface_stack),
        ("å®‰è£…å…¶ä»–ä¾èµ–", install_additional_deps),
        ("æµ‹è¯•å…³é”®å¯¼å…¥", test_critical_imports),
        ("æµ‹è¯•VQModel API", test_vqmodel_api),
        ("æµ‹è¯•Transformer API", test_transformer_api),
    ]
    
    failed_steps = []
    
    for step_name, step_func in steps:
        print(f"\n{'='*20} {step_name} {'='*20}")
        success = step_func()
        
        if not success:
            print(f"âŒ {step_name} å¤±è´¥")
            failed_steps.append(step_name)
        else:
            print(f"âœ… {step_name} æˆåŠŸ")
    
    # æ€»ç»“
    print(f"\n{'='*20} å®‰è£…æ€»ç»“ {'='*20}")
    
    if not failed_steps:
        print("ğŸ‰ ç¯å¢ƒå®‰è£…å®Œå…¨æˆåŠŸ!")
        print("âœ… æ‰€æœ‰ç»„ä»¶æ­£å¸¸å·¥ä½œ")
        print("\nğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒ:")
        print("   python train_main.py --data_dir /path/to/data")
    else:
        print(f"âš ï¸ éƒ¨åˆ†æ­¥éª¤å¤±è´¥: {', '.join(failed_steps)}")
        
        if "æµ‹è¯•å…³é”®å¯¼å…¥" not in failed_steps:
            print("âœ… åŸºç¡€ç¯å¢ƒå®‰è£…æˆåŠŸï¼Œå¯ä»¥å°è¯•è¿è¡Œ")
            print("ğŸ’¡ å»ºè®®é‡å¯Pythonå†…æ ¸åå†æ¬¡æµ‹è¯•")
        else:
            print("âŒ åŸºç¡€ç¯å¢ƒæœ‰é—®é¢˜ï¼Œå»ºè®®:")
            print("1. é‡å¯Pythonå†…æ ¸")
            print("2. é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
            print("3. æ£€æŸ¥ç½‘ç»œè¿æ¥")

if __name__ == "__main__":
    main()
