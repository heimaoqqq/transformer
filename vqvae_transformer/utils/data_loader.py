#!/usr/bin/env python3
"""
æ•°æ®åŠ è½½å™¨
å¤ç”¨ä¸»é¡¹ç›®çš„æ•°æ®åŠ è½½é€»è¾‘ï¼Œé€‚é…VQ-VAE + Transformeréœ€æ±‚
"""

import os
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
import torch
from torch.utils.data import Dataset, Subset
from PIL import Image
import torchvision.transforms as transforms
from collections import defaultdict
import random
import numpy as np

# æ·»åŠ ä¸»é¡¹ç›®è·¯å¾„ä»¥å¤ç”¨æ•°æ®åŠ è½½å™¨
sys.path.append(str(Path(__file__).parent.parent.parent))

try:
    from utils.data_loader import MicroDopplerDataset as BaseMicroDopplerDataset
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œæä¾›åŸºç¡€å®ç°
    class BaseMicroDopplerDataset(Dataset):
        def __init__(self, data_dir, transform=None, return_user_id=False):
            self.data_dir = Path(data_dir)
            self.transform = transform
            self.return_user_id = return_user_id
            
            # åŠ è½½æ•°æ®
            self.data = []
            self._load_data()
        
        def _load_data(self):
            """åŠ è½½æ•°æ®"""
            for user_dir in self.data_dir.iterdir():
                if user_dir.is_dir() and user_dir.name.startswith('ID'):
                    try:
                        # å¤„ç† ID1, ID_2, ID_3 ç­‰æ ¼å¼
                        dir_name = user_dir.name
                        if '_' in dir_name:
                            user_id = int(dir_name.split('_')[1])  # ID_2 -> 2
                        else:
                            user_id = int(dir_name[2:])  # ID1 -> 1

                        # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
                        for ext in ['*.png', '*.jpg', '*.jpeg']:
                            for img_path in user_dir.glob(ext):
                                self.data.append({
                                    'image_path': str(img_path),
                                    'user_id': user_id,
                                })
                    except ValueError:
                        continue
        
        def __len__(self):
            return len(self.data)
        
        def __getitem__(self, idx):
            item = self.data[idx]

            # åŠ è½½å›¾åƒ
            image = Image.open(item['image_path']).convert('RGB')

            if self.transform:
                image = self.transform(image)

            if self.return_user_id:
                return {
                    'image': image,
                    'user_id': item['user_id']
                }
            else:
                return image

class MicroDopplerDataset(BaseMicroDopplerDataset):
    """
    å¾®å¤šæ™®å‹’æ•°æ®é›†
    æ‰©å±•åŸºç¡€æ•°æ®é›†ä»¥æ”¯æŒVQ-VAE + Transformerçš„éœ€æ±‚
    """
    
    def __init__(
        self,
        data_dir: str,
        transform: Optional[transforms.Compose] = None,
        return_user_id: bool = False,
        user_filter: Optional[List[int]] = None,
        max_samples_per_user: Optional[int] = None,
    ):
        """
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            transform: å›¾åƒå˜æ¢
            return_user_id: æ˜¯å¦è¿”å›ç”¨æˆ·ID
            user_filter: ç”¨æˆ·IDè¿‡æ»¤åˆ—è¡¨
            max_samples_per_user: æ¯ä¸ªç”¨æˆ·çš„æœ€å¤§æ ·æœ¬æ•°
        """
        self.user_filter = user_filter
        self.max_samples_per_user = max_samples_per_user
        
        super().__init__(data_dir, transform, return_user_id)
        
        # åº”ç”¨è¿‡æ»¤å™¨
        if self.user_filter is not None:
            self.data = [item for item in self.data if item['user_id'] in self.user_filter]
        
        # é™åˆ¶æ¯ä¸ªç”¨æˆ·çš„æ ·æœ¬æ•°
        if self.max_samples_per_user is not None:
            self._limit_samples_per_user()
        
        print(f"ğŸ“Š æ•°æ®é›†åŠ è½½å®Œæˆ:")
        print(f"   æ€»æ ·æœ¬æ•°: {len(self.data)}")
        print(f"   ç”¨æˆ·æ•°é‡: {len(set(item['user_id'] for item in self.data))}")
    
    def _limit_samples_per_user(self):
        """é™åˆ¶æ¯ä¸ªç”¨æˆ·çš„æ ·æœ¬æ•°"""
        user_counts = {}
        filtered_data = []
        
        for item in self.data:
            user_id = item['user_id']
            if user_id not in user_counts:
                user_counts[user_id] = 0
            
            if user_counts[user_id] < self.max_samples_per_user:
                filtered_data.append(item)
                user_counts[user_id] += 1
        
        self.data = filtered_data
    
    def get_user_statistics(self) -> Dict[int, int]:
        """è·å–ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯"""
        user_counts = {}
        for item in self.data:
            user_id = item['user_id']
            user_counts[user_id] = user_counts.get(user_id, 0) + 1
        return user_counts
    
    def get_user_samples(self, user_id: int) -> List[str]:
        """è·å–æŒ‡å®šç”¨æˆ·çš„æ‰€æœ‰æ ·æœ¬è·¯å¾„"""
        return [item['image_path'] for item in self.data if item['user_id'] == user_id]

def create_user_data_dict(data_dir: str) -> Dict[int, List[str]]:
    """
    åˆ›å»ºç”¨æˆ·æ•°æ®å­—å…¸
    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„
    Returns:
        user_data: {user_id: [image_paths]}
    """
    data_path = Path(data_dir)
    user_data = {}
    
    for user_dir in data_path.iterdir():
        if user_dir.is_dir() and user_dir.name.startswith('ID'):
            try:
                # å¤„ç† ID1, ID_2, ID_3 ç­‰æ ¼å¼
                dir_name = user_dir.name
                if '_' in dir_name:
                    user_id = int(dir_name.split('_')[1])  # ID_2 -> 2
                else:
                    user_id = int(dir_name[2:])  # ID1 -> 1

                image_paths = []

                # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
                for ext in ['*.png', '*.jpg', '*.jpeg']:
                    image_paths.extend(list(user_dir.glob(ext)))

                if image_paths:
                    user_data[user_id] = [str(p) for p in image_paths]

            except ValueError:
                continue
    
    return user_data

def create_micro_doppler_dataset(
    data_dir: str,
    transform: Optional[transforms.Compose] = None,
    return_user_id: bool = False,
    user_filter: Optional[List[int]] = None,
    max_samples_per_user: Optional[int] = None,
    image_size: int = 128,
    high_quality_resize: bool = True,
) -> MicroDopplerDataset:
    """
    åˆ›å»ºå¾®å¤šæ™®å‹’æ•°æ®é›†

    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„
        transform: å›¾åƒå˜æ¢
        return_user_id: æ˜¯å¦è¿”å›ç”¨æˆ·ID
        user_filter: ç”¨æˆ·IDè¿‡æ»¤åˆ—è¡¨
        max_samples_per_user: æ¯ä¸ªç”¨æˆ·çš„æœ€å¤§æ ·æœ¬æ•°
        image_size: ç›®æ ‡å›¾åƒå°ºå¯¸
        high_quality_resize: æ˜¯å¦ä½¿ç”¨é«˜è´¨é‡ç¼©æ”¾

    Returns:
        MicroDopplerDatasetå®ä¾‹
    """
    if transform is None:
        if high_quality_resize:
            # é«˜è´¨é‡ç¼©æ”¾ï¼šä½¿ç”¨Lanczosæ’å€¼ + æŠ—é”¯é½¿
            transform = transforms.Compose([
                transforms.Resize(
                    (image_size, image_size),
                    interpolation=transforms.InterpolationMode.LANCZOS,
                    antialias=True
                ),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
            ])
        else:
            # æ ‡å‡†ç¼©æ”¾ï¼šåŒçº¿æ€§æ’å€¼
            transform = transforms.Compose([
                transforms.Resize((image_size, image_size)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
            ])

    return MicroDopplerDataset(
        data_dir=data_dir,
        transform=transform,
        return_user_id=return_user_id,
        user_filter=user_filter,
        max_samples_per_user=max_samples_per_user,
    )

def create_balanced_dataset(
    data_dir: str,
    samples_per_user: int = 100,
    transform: Optional[transforms.Compose] = None,
) -> MicroDopplerDataset:
    """
    åˆ›å»ºå¹³è¡¡æ•°æ®é›†
    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„
        samples_per_user: æ¯ä¸ªç”¨æˆ·çš„æ ·æœ¬æ•°
        transform: å›¾åƒå˜æ¢
    Returns:
        dataset: å¹³è¡¡çš„æ•°æ®é›†
    """
    return MicroDopplerDataset(
        data_dir=data_dir,
        transform=transform,
        return_user_id=True,
        max_samples_per_user=samples_per_user,
    )

def get_default_transform(
    resolution: int = 128,
    normalize: bool = True,
    interpolation: str = "lanczos"
) -> transforms.Compose:
    """
    è·å–é»˜è®¤çš„å›¾åƒå˜æ¢
    Args:
        resolution: ç›®æ ‡åˆ†è¾¨ç‡ (ä»256x256ç¼©æ”¾åˆ°æŒ‡å®šå°ºå¯¸)
        normalize: æ˜¯å¦å½’ä¸€åŒ–åˆ°[-1, 1]
        interpolation: æ’å€¼æ–¹æ³• ("lanczos", "bicubic", "bilinear", "antialias")
    Returns:
        transform: å›¾åƒå˜æ¢
    """
    # é€‰æ‹©æ’å€¼æ–¹æ³•
    interpolation_map = {
        "lanczos": transforms.InterpolationMode.LANCZOS,
        "bicubic": transforms.InterpolationMode.BICUBIC,
        "bilinear": transforms.InterpolationMode.BILINEAR,
        "antialias": transforms.InterpolationMode.BILINEAR,  # é…åˆantialias=True
    }

    interp_mode = interpolation_map.get(interpolation, transforms.InterpolationMode.LANCZOS)

    # æ„å»ºå˜æ¢åˆ—è¡¨
    if interpolation == "antialias":
        # ä½¿ç”¨æŠ—é”¯é½¿ç¼©æ”¾ (PyTorch 1.11+)
        transform_list = [
            transforms.Resize((resolution, resolution),
                            interpolation=interp_mode,
                            antialias=True),
            transforms.ToTensor(),  # [0, 1]
        ]
    else:
        transform_list = [
            transforms.Resize((resolution, resolution), interpolation=interp_mode),
            transforms.ToTensor(),  # [0, 1]
        ]

    if normalize:
        # å½’ä¸€åŒ–åˆ°[-1, 1]ï¼Œé€‚é…VQ-VAEè®­ç»ƒ
        transform_list.append(
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        )

    return transforms.Compose(transform_list)

def denormalize_tensor(tensor: torch.Tensor) -> torch.Tensor:
    """
    åå½’ä¸€åŒ–tensorä»[-1, 1]åˆ°[0, 1]
    Args:
        tensor: å½’ä¸€åŒ–çš„tensor [-1, 1]
    Returns:
        tensor: åå½’ä¸€åŒ–çš„tensor [0, 1]
    """
    return (tensor + 1.0) / 2.0

def tensor_to_pil(tensor: torch.Tensor) -> Image.Image:
    """
    å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ
    Args:
        tensor: [C, H, W] tensorï¼ŒèŒƒå›´[-1, 1]æˆ–[0, 1]
    Returns:
        image: PILå›¾åƒ
    """
    # å¦‚æœæ˜¯[-1, 1]èŒƒå›´ï¼Œå…ˆåå½’ä¸€åŒ–
    if tensor.min() < 0:
        tensor = denormalize_tensor(tensor)

    # è½¬æ¢ä¸ºPIL
    tensor = torch.clamp(tensor, 0, 1)
    tensor = (tensor * 255).byte()

    if tensor.dim() == 3:
        tensor = tensor.permute(1, 2, 0)  # [C, H, W] -> [H, W, C]

    return Image.fromarray(tensor.cpu().numpy())

class VQTokenDataset(Dataset):
    """
    VQ Tokenæ•°æ®é›†
    ç”¨äºTransformerè®­ç»ƒï¼ŒåŒ…å«é¢„è®¡ç®—çš„VQ tokens
    """
    
    def __init__(
        self,
        token_data: List[Dict],
        max_seq_len: int = 256,
        pad_token_id: int = 1024,
    ):
        """
        Args:
            token_data: tokenæ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«user_idå’Œtokens
            max_seq_len: æœ€å¤§åºåˆ—é•¿åº¦
            pad_token_id: å¡«å……token ID
        """
        self.token_data = token_data
        self.max_seq_len = max_seq_len
        self.pad_token_id = pad_token_id
        
        print(f"ğŸ“Š VQ Tokenæ•°æ®é›†:")
        print(f"   æ€»åºåˆ—æ•°: {len(self.token_data)}")
        print(f"   æœ€å¤§åºåˆ—é•¿åº¦: {self.max_seq_len}")
    
    def __len__(self):
        return len(self.token_data)
    
    def __getitem__(self, idx):
        item = self.token_data[idx]
        
        user_id = torch.tensor(item['user_id'], dtype=torch.long)
        tokens = item['tokens']
        
        # æˆªæ–­æˆ–å¡«å……åˆ°å›ºå®šé•¿åº¦
        if len(tokens) > self.max_seq_len:
            tokens = tokens[:self.max_seq_len]
        else:
            pad_length = self.max_seq_len - len(tokens)
            pad_tokens = torch.full((pad_length,), self.pad_token_id, dtype=tokens.dtype)
            tokens = torch.cat([tokens, pad_tokens])
        
        return {
            'user_id': user_id,
            'tokens': tokens,
        }

def create_vq_token_dataset(
    vqvae_model,
    data_dir: str,
    transform: transforms.Compose,
    max_seq_len: int = 256,
    device: str = "cuda",
) -> VQTokenDataset:
    """
    åˆ›å»ºVQ Tokenæ•°æ®é›†
    Args:
        vqvae_model: é¢„è®­ç»ƒçš„VQ-VAEæ¨¡å‹
        data_dir: æ•°æ®ç›®å½•
        transform: å›¾åƒå˜æ¢
        max_seq_len: æœ€å¤§åºåˆ—é•¿åº¦
        device: è®¡ç®—è®¾å¤‡
    Returns:
        dataset: VQ Tokenæ•°æ®é›†
    """
    from tqdm import tqdm
    
    # åˆ›å»ºåŸºç¡€æ•°æ®é›†
    base_dataset = MicroDopplerDataset(
        data_dir=data_dir,
        transform=transform,
        return_user_id=True,
    )
    
    # é¢„è®¡ç®—tokens
    vqvae_model.eval()
    token_data = []
    
    with torch.no_grad():
        for i in tqdm(range(len(base_dataset)), desc="é¢„è®¡ç®—VQ tokens"):
            image, user_id = base_dataset[i]
            image_tensor = image.unsqueeze(0).to(device)
            
            # ç¼–ç ä¸ºtokens
            result = vqvae_model.encode(image_tensor, return_dict=True)
            tokens = result['encoding_indices'].flatten().cpu()
            
            token_data.append({
                'user_id': user_id,
                'tokens': tokens,
            })
    
    return VQTokenDataset(token_data, max_seq_len)

def create_stratified_split(dataset, train_ratio=0.8, val_ratio=0.2, random_seed=42):
    """
    åˆ›å»ºåˆ†å±‚æ•°æ®é›†åˆ’åˆ†ï¼Œç¡®ä¿æ¯ä¸ªç”¨æˆ·éƒ½åœ¨è®­ç»ƒé›†å’ŒéªŒè¯é›†ä¸­

    Args:
        dataset: æ•°æ®é›†å¯¹è±¡
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        val_ratio: éªŒè¯é›†æ¯”ä¾‹
        random_seed: éšæœºç§å­

    Returns:
        train_dataset, val_dataset
    """
    print("ğŸ”„ æ‰§è¡Œåˆ†å±‚æ•°æ®é›†åˆ’åˆ†...")

    # è®¾ç½®éšæœºç§å­
    random.seed(random_seed)
    np.random.seed(random_seed)
    torch.manual_seed(random_seed)

    # æŒ‰ç”¨æˆ·åˆ†ç»„æ•°æ®
    user_indices = defaultdict(list)

    for idx in range(len(dataset)):
        try:
            sample = dataset[idx]

            # å¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼
            if isinstance(sample, dict):
                user_id = sample['user_id']
            elif isinstance(sample, (list, tuple)) and len(sample) >= 2:
                if isinstance(sample[1], torch.Tensor):
                    user_id = sample[1].item()
                else:
                    user_id = sample[1]
            else:
                print(f"âš ï¸ è·³è¿‡æœªçŸ¥æ ¼å¼çš„æ ·æœ¬: {type(sample)}")
                continue

            user_indices[user_id].append(idx)

        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ ·æœ¬{idx}æ—¶å‡ºé”™: {e}")
            continue

    print(f"ğŸ“Š å‘ç° {len(user_indices)} ä¸ªç”¨æˆ·")
    for user_id, indices in user_indices.items():
        print(f"   ç”¨æˆ·{user_id}: {len(indices)}ä¸ªæ ·æœ¬")

    # ä¸ºæ¯ä¸ªç”¨æˆ·åˆ†é…è®­ç»ƒé›†å’ŒéªŒè¯é›†æ ·æœ¬
    train_indices = []
    val_indices = []

    for user_id, indices in user_indices.items():
        # éšæœºæ‰“ä¹±è¯¥ç”¨æˆ·çš„æ ·æœ¬
        random.shuffle(indices)

        # è®¡ç®—åˆ†å‰²ç‚¹
        n_samples = len(indices)
        n_train = max(1, int(n_samples * train_ratio))  # è‡³å°‘1ä¸ªè®­ç»ƒæ ·æœ¬
        n_val = max(1, n_samples - n_train)  # è‡³å°‘1ä¸ªéªŒè¯æ ·æœ¬

        # å¦‚æœæ ·æœ¬å¤ªå°‘ï¼Œè°ƒæ•´åˆ†é…
        if n_samples < 2:
            train_indices.extend(indices)
            val_indices.extend(indices)  # å¤åˆ¶åˆ°éªŒè¯é›†
            print(f"   âš ï¸ ç”¨æˆ·{user_id}æ ·æœ¬å¤ªå°‘({n_samples})ï¼Œè®­ç»ƒé›†å’ŒéªŒè¯é›†å…±äº«")
        else:
            train_indices.extend(indices[:n_train])
            val_indices.extend(indices[n_train:n_train + n_val])
            print(f"   âœ… ç”¨æˆ·{user_id}: è®­ç»ƒé›†{n_train}ä¸ª, éªŒè¯é›†{n_val}ä¸ª")

    # åˆ›å»ºå­æ•°æ®é›†
    train_dataset = Subset(dataset, train_indices)
    val_dataset = Subset(dataset, val_indices)

    print(f"\nğŸ“Š æ•°æ®é›†åˆ’åˆ†å®Œæˆ:")
    print(f"   æ€»æ ·æœ¬æ•°: {len(dataset)}")
    print(f"   è®­ç»ƒé›†: {len(train_dataset)} ({len(train_dataset)/len(dataset)*100:.1f}%)")
    print(f"   éªŒè¯é›†: {len(val_dataset)} ({len(val_dataset)/len(dataset)*100:.1f}%)")

    return train_dataset, val_dataset

def create_datasets_with_split(data_dir, train_ratio=0.8, val_ratio=0.2, return_user_id=True, random_seed=42, image_size=128, high_quality_resize=True):
    """
    åˆ›å»ºå¸¦æœ‰è‡ªåŠ¨åˆ’åˆ†çš„æ•°æ®é›†

    Args:
        data_dir: æ•°æ®ç›®å½•
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        val_ratio: éªŒè¯é›†æ¯”ä¾‹
        return_user_id: æ˜¯å¦è¿”å›ç”¨æˆ·ID
        random_seed: éšæœºç§å­
        image_size: ç›®æ ‡å›¾åƒå°ºå¯¸
        high_quality_resize: æ˜¯å¦ä½¿ç”¨é«˜è´¨é‡ç¼©æ”¾

    Returns:
        train_dataset, val_dataset
    """
    print("ğŸš€ åˆ›å»ºå¸¦æœ‰è‡ªåŠ¨åˆ’åˆ†çš„æ•°æ®é›†...")

    # åˆ›å»ºå®Œæ•´æ•°æ®é›†
    full_dataset = create_micro_doppler_dataset(
        data_dir=data_dir,
        return_user_id=return_user_id,
        image_size=image_size,
        high_quality_resize=high_quality_resize
    )

    # æ‰§è¡Œåˆ†å±‚åˆ’åˆ†
    train_dataset, val_dataset = create_stratified_split(
        dataset=full_dataset,
        train_ratio=train_ratio,
        val_ratio=val_ratio,
        random_seed=random_seed
    )

    return train_dataset, val_dataset
