#!/usr/bin/env python3
"""
Transformerè®­ç»ƒè¯Šæ–­å·¥å…·
åˆ†æPSNRåœæ»é—®é¢˜ï¼Œæ£€æŸ¥ç”Ÿæˆè´¨é‡å’Œtokenåˆ†å¸ƒ
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import sys
from tqdm import tqdm
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from models.vqvae_model import MicroDopplerVQVAE
from models.transformer_model import MicroDopplerTransformer
from utils.data_loader import MicroDopplerDataset

def load_models(vqvae_path, transformer_path):
    """åŠ è½½VQ-VAEå’ŒTransformeræ¨¡å‹"""
    print("ğŸ“‚ åŠ è½½æ¨¡å‹...")
    
    # åŠ è½½VQ-VAE
    vqvae = MicroDopplerVQVAE.from_pretrained(vqvae_path)
    vqvae.eval()
    print("âœ… VQ-VAEåŠ è½½æˆåŠŸ")
    
    # åŠ è½½Transformer
    checkpoint = torch.load(transformer_path, map_location='cpu')
    
    transformer = MicroDopplerTransformer(
        vocab_size=checkpoint['args'].codebook_size,
        max_seq_len=1024,
        num_users=checkpoint['args'].num_users,
        n_embd=checkpoint['args'].n_embd,
        n_layer=checkpoint['args'].n_layer,
        n_head=checkpoint['args'].n_head,
        use_cross_attention=True,
    )
    
    transformer.load_state_dict(checkpoint['model_state_dict'])
    transformer.eval()
    print("âœ… TransformeråŠ è½½æˆåŠŸ")
    
    return vqvae, transformer

def analyze_token_generation(transformer, vqvae, device, num_samples=10):
    """åˆ†ætokenç”Ÿæˆè´¨é‡"""
    print("ğŸ” åˆ†ætokenç”Ÿæˆ...")
    
    transformer.to(device)
    vqvae.to(device)
    
    # ç”Ÿæˆå¤šä¸ªç”¨æˆ·çš„token
    user_ids = torch.tensor([1, 5, 10, 15, 20], device=device)
    
    generated_tokens_list = []
    
    for user_id in user_ids:
        print(f"   ç”Ÿæˆç”¨æˆ·{user_id.item()}çš„token...")
        
        # ç”Ÿæˆtokenåºåˆ—
        with torch.no_grad():
            generated_tokens = generate_tokens(transformer, user_id.unsqueeze(0), device)
            
            if generated_tokens is not None:
                generated_tokens_list.append(generated_tokens[0].cpu().numpy())
                
                # åˆ†ætokenåˆ†å¸ƒ
                unique_tokens = np.unique(generated_tokens[0].cpu().numpy())
                print(f"     å”¯ä¸€tokenæ•°é‡: {len(unique_tokens)}")
                print(f"     tokenèŒƒå›´: [{unique_tokens.min()}, {unique_tokens.max()}]")
    
    # åˆ†ætokenå¤šæ ·æ€§
    if generated_tokens_list:
        analyze_token_diversity(generated_tokens_list)
    
    return generated_tokens_list

def generate_tokens(transformer, user_ids, device, max_length=1024):
    """ç”Ÿæˆtokenåºåˆ—"""
    try:
        batch_size = user_ids.shape[0]
        
        # å¼€å§‹token
        generated = torch.full((batch_size, 1), transformer.user_token_id, device=device)
        
        for step in range(max_length):
            # å‡†å¤‡è¾“å…¥
            inputs = transformer.prepare_inputs(user_ids, None)
            inputs['input_ids'] = generated
            inputs['attention_mask'] = torch.ones_like(generated)
            
            # å‰å‘ä¼ æ’­
            if transformer.use_cross_attention:
                outputs = transformer.transformer(
                    input_ids=inputs['input_ids'],
                    attention_mask=inputs['attention_mask'],
                    encoder_hidden_states=inputs['encoder_hidden_states'],
                    encoder_attention_mask=inputs['encoder_attention_mask'],
                )
            else:
                outputs = transformer.transformer(
                    input_ids=inputs['input_ids'],
                    attention_mask=inputs['attention_mask'],
                )
            
            # è·å–ä¸‹ä¸€ä¸ªtoken
            next_token_logits = outputs.logits[:, -1, :] / 1.0  # temperature=1.0
            
            # é™åˆ¶åˆ°æœ‰æ•ˆèŒƒå›´
            if next_token_logits.shape[-1] > 1024:
                next_token_logits = next_token_logits[:, :1024]
            
            # é‡‡æ ·
            next_token = torch.multinomial(torch.softmax(next_token_logits, dim=-1), 1)
            next_token = torch.clamp(next_token, 0, 1023)
            
            # æ·»åŠ åˆ°åºåˆ—
            generated = torch.cat([generated, next_token], dim=1)
            
            if generated.shape[1] >= max_length + 1:
                break
        
        # è¿”å›å›¾åƒtokenï¼ˆå»æ‰ç”¨æˆ·tokenï¼‰
        return generated[:, 1:]
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        return None

def analyze_token_diversity(token_lists):
    """åˆ†ætokenå¤šæ ·æ€§"""
    print("ğŸ“Š Tokenå¤šæ ·æ€§åˆ†æ:")
    
    # è®¡ç®—æ¯ä¸ªåºåˆ—çš„å”¯ä¸€tokenæ¯”ä¾‹
    diversity_scores = []
    for tokens in token_lists:
        unique_ratio = len(np.unique(tokens)) / len(tokens)
        diversity_scores.append(unique_ratio)
    
    avg_diversity = np.mean(diversity_scores)
    print(f"   å¹³å‡å”¯ä¸€tokenæ¯”ä¾‹: {avg_diversity:.3f}")
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰åºåˆ—éƒ½ç›¸åŒ
    if len(token_lists) > 1:
        all_same = all(np.array_equal(token_lists[0], tokens) for tokens in token_lists[1:])
        print(f"   æ‰€æœ‰åºåˆ—æ˜¯å¦ç›¸åŒ: {'æ˜¯' if all_same else 'å¦'}")
    
    # åˆ†ætokenåˆ†å¸ƒ
    all_tokens = np.concatenate(token_lists)
    unique_tokens = np.unique(all_tokens)
    print(f"   æ€»ä½“å”¯ä¸€tokenæ•°é‡: {len(unique_tokens)} / 1024")
    print(f"   ç æœ¬åˆ©ç”¨ç‡: {len(unique_tokens)/1024*100:.1f}%")

def test_vqvae_reconstruction(vqvae, device, data_dir):
    """æµ‹è¯•VQ-VAEé‡å»ºè´¨é‡"""
    print("ğŸ” æµ‹è¯•VQ-VAEé‡å»ºè´¨é‡...")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])
    
    dataset = MicroDopplerDataset(data_dir, transform=transform, return_user_id=True)
    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)
    
    vqvae.to(device)
    
    with torch.no_grad():
        for images, _ in dataloader:
            images = images.to(device)
            
            # VQ-VAEç¼–ç -è§£ç 
            encoded = vqvae.encode(images, return_dict=True)
            tokens = encoded['encoding_indices']
            
            print(f"   åŸå§‹å›¾åƒå½¢çŠ¶: {images.shape}")
            print(f"   Tokenå½¢çŠ¶: {tokens.shape}")
            print(f"   TokenèŒƒå›´: [{tokens.min().item()}, {tokens.max().item()}]")
            
            # é‡å»º
            reconstructed = vqvae.decode(encoded['latents'])
            
            # è®¡ç®—PSNR
            mse = torch.mean((images - reconstructed) ** 2)
            psnr = 20 * torch.log10(2.0 / torch.sqrt(mse))  # èŒƒå›´[-1,1]ï¼Œæ‰€ä»¥max=2
            
            print(f"   VQ-VAEé‡å»ºPSNR: {psnr.item():.2f} dB")
            break

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Transformerè®­ç»ƒè¯Šæ–­")
    parser.add_argument("--vqvae_path", type=str, required=True, help="VQ-VAEæ¨¡å‹è·¯å¾„")
    parser.add_argument("--transformer_path", type=str, required=True, help="Transformeræ¨¡å‹è·¯å¾„")
    parser.add_argument("--data_dir", type=str, required=True, help="æ•°æ®é›†è·¯å¾„")
    
    args = parser.parse_args()
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
    
    try:
        # 1. åŠ è½½æ¨¡å‹
        vqvae, transformer = load_models(args.vqvae_path, args.transformer_path)
        
        # 2. æµ‹è¯•VQ-VAEé‡å»º
        test_vqvae_reconstruction(vqvae, device, args.data_dir)
        
        # 3. åˆ†æTransformerç”Ÿæˆ
        token_lists = analyze_token_generation(transformer, vqvae, device)
        
        # 4. ç»™å‡ºè¯Šæ–­ç»“è®º
        print("\nğŸ¯ è¯Šæ–­ç»“è®º:")
        if not token_lists:
            print("âŒ Transformerç”Ÿæˆå¤±è´¥ï¼Œå¯èƒ½å­˜åœ¨ä¸¥é‡é—®é¢˜")
        else:
            print("âœ… Transformerèƒ½å¤Ÿç”Ÿæˆtoken")
            print("ğŸ’¡ å»ºè®®æ£€æŸ¥ç”Ÿæˆçš„å›¾åƒè´¨é‡å’Œtokenå¤šæ ·æ€§")
            
    except Exception as e:
        print(f"âŒ è¯Šæ–­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
