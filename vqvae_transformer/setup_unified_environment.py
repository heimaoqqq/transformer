#!/usr/bin/env python3
"""
VQ-VAE + Transformer ç»Ÿä¸€ç¯å¢ƒé…ç½®è„šæœ¬
åŸºäºdiffuserså®˜æ–¹é…ç½®ï¼Œæ”¯æŒVQ-VAEå’ŒTransformerè®­ç»ƒ

åŠŸèƒ½ï¼š
- å®‰è£…PyTorch GPUç‰ˆæœ¬
- ä½¿ç”¨diffuserså®˜æ–¹é…ç½®: diffusers[torch] + transformers
- æ™ºèƒ½é€‰æ‹©diffusersç‰ˆæœ¬ï¼Œç¡®ä¿VQModelå¯ç”¨
- å®‰è£…å®Œæ•´çš„å›¾åƒå¤„ç†å’Œåºåˆ—ç”Ÿæˆä¾èµ–
- æµ‹è¯•VQ-VAEå’ŒTransformerç¯å¢ƒå®Œæ•´æ€§

ç‰ˆæœ¬ç­–ç•¥ï¼š
- éµå¾ªdiffuserså®˜æ–¹é…ç½®: pip install diffusers[torch] transformers
- æ™ºèƒ½é™çº§: å¦‚æœVQModelä¸å¯ç”¨ï¼Œè‡ªåŠ¨é™çº§åˆ°ç¨³å®šç‰ˆæœ¬
- ç»Ÿä¸€ç®¡ç†: ä¸€ä¸ªç¯å¢ƒæ”¯æŒä¸¤ä¸ªè®­ç»ƒé˜¶æ®µ
"""

import os
import sys
import subprocess
import importlib
from pathlib import Path

def run_command(cmd, description="", timeout=600):
    """è¿è¡Œå‘½ä»¤å¹¶è¿”å›æ˜¯å¦æˆåŠŸ"""
    print(f"ğŸ”„ {description}")
    print(f"   å‘½ä»¤: {cmd}")
    
    try:
        result = subprocess.run(
            cmd, 
            shell=True, 
            capture_output=True, 
            text=True, 
            timeout=timeout
        )
        
        if result.returncode == 0:
            print(f"âœ… {description} æˆåŠŸ")
            return True
        else:
            print(f"âŒ {description} å¤±è´¥")
            if result.stderr:
                print(f"   é”™è¯¯: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        print(f"â° {description} è¶…æ—¶ (>{timeout}ç§’)")
        return False
    except Exception as e:
        print(f"âŒ {description} å¼‚å¸¸: {e}")
        return False

def install_pytorch():
    """å®‰è£…PyTorch GPUç‰ˆæœ¬"""
    print("ğŸ”¥ å®‰è£…GPUç‰ˆæœ¬PyTorch...")
    
    pytorch_options = [
        ("pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121", "PyTorchæ–¹æ¡ˆ 1"),
        ("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121", "PyTorchæ–¹æ¡ˆ 2"),
        ("pip install torch torchvision torchaudio", "PyTorchæ–¹æ¡ˆ 3 (CPUå¤‡ç”¨)"),
    ]
    
    for cmd, description in pytorch_options:
        print(f"\nå°è¯•{description}...")
        if run_command(cmd, f"ğŸ”„ {description}"):
            print(f"âœ… å®‰è£…PyTorch GPUç‰ˆæœ¬ æˆåŠŸ")
            return True
    
    print("âŒ æ‰€æœ‰PyTorchå®‰è£…æ–¹æ¡ˆéƒ½å¤±è´¥")
    return False

def test_vqmodel_import():
    """æµ‹è¯•VQModelå¯¼å…¥æ˜¯å¦æˆåŠŸ"""
    try:
        import subprocess
        import sys

        # åŸºäºç½‘ä¸Šè°ƒç ”ï¼Œæ­£ç¡®çš„å¯¼å…¥è·¯å¾„æ˜¯ diffusers.models.autoencoders.vq_model
        import_tests = [
            "from diffusers.models.autoencoders.vq_model import VQModel; print('SUCCESS_CORRECT_PATH')",
            "from diffusers.models.vq_model import VQModel; print('SUCCESS_OLD_PATH')",
            "from diffusers import VQModel; print('SUCCESS_DIRECT_IMPORT')",
        ]

        for i, test_code in enumerate(import_tests, 1):
            result = subprocess.run([
                sys.executable, "-c", test_code
            ], capture_output=True, text=True, timeout=30)

            if result.returncode == 0 and "SUCCESS" in result.stdout:
                print(f"âœ… VQModelå¯¼å…¥æˆåŠŸ (è·¯å¾„{i})")
                return True

        # å¦‚æœæ‰€æœ‰è·¯å¾„éƒ½å¤±è´¥ï¼Œæ˜¾ç¤ºæœ€åä¸€ä¸ªé”™è¯¯
        print(f"VQModelå¯¼å…¥å¤±è´¥: {result.stderr}")
        return False

    except Exception as e:
        print(f"VQModelæµ‹è¯•å¼‚å¸¸: {e}")
        return False

def install_core_dependencies():
    """å®‰è£…æ ¸å¿ƒä¾èµ– - ä½¿ç”¨ç¡®å®šæ”¯æŒVQModelçš„ç‰ˆæœ¬"""
    print("ğŸ¨ å®‰è£…æ ¸å¿ƒä¾èµ–...")
    print("ğŸ’¡ ä½¿ç”¨ç¡®å®šæ”¯æŒVQModelçš„ç‰ˆæœ¬ç»„åˆ")

    # å…ˆå¸è½½æ‰€æœ‰ç›¸å…³åŒ…ï¼ŒåŒ…æ‹¬peft
    run_command("pip uninstall -y huggingface_hub diffusers transformers accelerate torchao peft", "æ¸…ç†æ‰€æœ‰ç›¸å…³åŒ…")
    run_command("pip cache purge", "æ¸…ç†pipç¼“å­˜")

    # ç¬¬ä¸€æ­¥ï¼šä¿®å¤NumPyç‰ˆæœ¬å†²çª
    print("\nğŸ”§ ä¿®å¤NumPyç‰ˆæœ¬å†²çª...")
    if not run_command("pip install 'numpy<2.0' --force-reinstall", "é™çº§NumPyåˆ°1.xç‰ˆæœ¬"):
        return False

    # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨ç¡®å®šæ”¯æŒVQModelçš„ç‰ˆæœ¬ç»„åˆ
    print("\nğŸ”§ å®‰è£…ç¡®å®šæ”¯æŒVQModelçš„ç‰ˆæœ¬ç»„åˆ...")

    # åŸºäºç½‘ä¸Šè°ƒç ”ï¼ŒVQModelåœ¨diffusers 0.31ç‰ˆæœ¬è¢«ç§»é™¤ï¼Œ0.30.xæ˜¯æœ€åæ”¯æŒçš„ç‰ˆæœ¬
    known_working_versions = [
        # ç‰ˆæœ¬ç»„åˆ1: diffusers 0.30.x (æœ€åæ”¯æŒVQModelçš„ç‰ˆæœ¬)
        {
            "huggingface_hub": "0.20.3",
            "transformers": "4.36.2",
            "diffusers": "0.30.3",
            "accelerate": "0.25.0",
            "peft": "0.6.2"
        },
        # ç‰ˆæœ¬ç»„åˆ2: diffusers 0.29.x (ç¨³å®šç‰ˆæœ¬)
        {
            "huggingface_hub": "0.19.4",
            "transformers": "4.35.2",
            "diffusers": "0.29.2",
            "accelerate": "0.24.1",
            "peft": "0.5.0"
        },
        # ç‰ˆæœ¬ç»„åˆ3: diffusers 0.28.x (ä¿å®ˆç‰ˆæœ¬)
        {
            "huggingface_hub": "0.18.0",
            "transformers": "4.34.1",
            "diffusers": "0.28.2",
            "accelerate": "0.23.0",
            "peft": "0.4.0"
        }
    ]

    vqmodel_available = False

    for i, versions in enumerate(known_working_versions, 1):
        print(f"\nå°è¯•ç‰ˆæœ¬ç»„åˆ {i}:")
        for package, version in versions.items():
            print(f"  {package}=={version}")

        # æŒ‰é¡ºåºå®‰è£…
        install_success = True
        for package, version in versions.items():
            if not run_command(f"pip install '{package}=={version}'", f"å®‰è£… {package} {version}"):
                install_success = False
                break

        if install_success:
            # æµ‹è¯•VQModel
            if test_vqmodel_import():
                print(f"âœ… ç‰ˆæœ¬ç»„åˆ {i} VQModelå¯ç”¨")
                vqmodel_available = True
                break
            else:
                print(f"âŒ ç‰ˆæœ¬ç»„åˆ {i} VQModelä¸å¯ç”¨")
        else:
            print(f"âŒ ç‰ˆæœ¬ç»„åˆ {i} å®‰è£…å¤±è´¥")

    if not vqmodel_available:
        print("âŒ æ‰€æœ‰å·²çŸ¥ç‰ˆæœ¬ç»„åˆéƒ½å¤±è´¥")
        print("ğŸ’¡ å»ºè®®ä½¿ç”¨åˆ†é˜¶æ®µè®­ç»ƒä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
        return False

    # ç¬¬ä¸‰æ­¥ï¼šå®‰è£…å…¶ä»–æ ¸å¿ƒä¾èµ–
    core_packages = [
        ("safetensors>=0.3.0,<0.5.0", "SafeTensors"),
        ("tokenizers>=0.13.0,<0.16.0", "Tokenizers"),
    ]

    success_count = 5  # 5ä¸ªæ ¸å¿ƒåŒ…å·²æˆåŠŸ
    for package, description in core_packages:
        if run_command(f"pip install '{package}'", f"å®‰è£… {description}"):
            success_count += 1

    # éªŒè¯ç‰ˆæœ¬å…¼å®¹æ€§
    print("\nğŸ”§ éªŒè¯ç‰ˆæœ¬å…¼å®¹æ€§...")
    run_command("pip check", "æ£€æŸ¥ä¾èµ–å†²çª")

    total_packages = 5 + len(core_packages)
    print(f"\nğŸ“Š æ ¸å¿ƒä¾èµ–å®‰è£…ç»“æœ: {success_count}/{total_packages} æˆåŠŸ")
    return success_count >= total_packages - 1 and vqmodel_available



def install_additional_dependencies():
    """å®‰è£…é¢å¤–ä¾èµ– - å…¼å®¹ç‰ˆæœ¬"""
    print("ğŸ“š å®‰è£…é¢å¤–ä¾èµ–...")

    # ç¡®ä¿NumPyç‰ˆæœ¬æ­£ç¡®
    run_command("pip install 'numpy<2.0' --force-reinstall", "ç¡®ä¿NumPy 1.xç‰ˆæœ¬")

    additional_packages = [
        # æ•°æ®å¤„ç† (å…¼å®¹NumPy 1.xçš„ç‰ˆæœ¬)
        "pillow>=9.0.0",
        "opencv-python>=4.8.0",
        "matplotlib>=3.7.0",
        "scikit-image>=0.20.0",

        # æœºå™¨å­¦ä¹ å·¥å…·
        "scikit-learn>=1.3.0",
        "einops>=0.6.0",
        "tqdm>=4.65.0",

        # å…¶ä»–å·¥å…·
        "scipy>=1.10.0",
    ]

    success_count = 0
    for package in additional_packages:
        if run_command(f"pip install '{package}'", f"å®‰è£… {package}"):
            success_count += 1

    # ç‰¹æ®Šå¤„ç†lpips (å¯é€‰ä¾èµ–)
    print("\nğŸ¨ å®‰è£…æ„ŸçŸ¥æŸå¤±åº“...")
    if run_command("pip install lpips", "å®‰è£… lpips (å¯é€‰)"):
        success_count += 1
    else:
        print("âš ï¸ lpipså®‰è£…å¤±è´¥ï¼Œè·³è¿‡ (å¯é€‰ä¾èµ–)")

    print(f"\nğŸ“Š é¢å¤–ä¾èµ–å®‰è£…ç»“æœ: {success_count}/{len(additional_packages)+1} æˆåŠŸ")
    return success_count >= len(additional_packages) - 2  # å…è®¸2ä¸ªå¤±è´¥

def test_unified_environment():
    """æµ‹è¯•ç»Ÿä¸€ç¯å¢ƒ"""
    print("ğŸ§ª æµ‹è¯•ç»Ÿä¸€ç¯å¢ƒ...")
    
    # æ¸…ç†æ¨¡å—ç¼“å­˜
    modules_to_clear = ['torch', 'diffusers', 'transformers', 'huggingface_hub', 'accelerate']
    for module_name in modules_to_clear:
        if module_name in sys.modules:
            del sys.modules[module_name]
    
    # åŸºç¡€æµ‹è¯•
    tests = [
        ("PyTorch", "torch"),
        ("Diffusers", "diffusers"),
        ("Transformers", "transformers"),
        ("HuggingFace Hub", "huggingface_hub"),
        ("Accelerate", "accelerate"),
    ]
    
    success_count = 0
    for name, module in tests:
        try:
            imported_module = importlib.import_module(module)
            version = getattr(imported_module, '__version__', 'unknown')
            print(f"âœ… {name}: {version}")
            success_count += 1
        except ImportError:
            print(f"âŒ {name}: å¯¼å…¥å¤±è´¥")
    
    # æµ‹è¯•PyTorch CUDA
    try:
        import torch
        if torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨: {torch.version.cuda}")
            print(f"âœ… GPUæ•°é‡: {torch.cuda.device_count()}")
        else:
            print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
    except Exception as e:
        print(f"âŒ PyTorchæµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•VQModel
    try:
        from diffusers.models.autoencoders.vq_model import VQModel
        print("âœ… VQModel: å¯ç”¨ (VQ-VAEæ”¯æŒ)")
    except ImportError as e:
        print(f"âŒ VQModel: å¯¼å…¥å¤±è´¥ - {e}")
    
    # æµ‹è¯•GPT2
    try:
        from transformers import GPT2Config, GPT2LMHeadModel
        print("âœ… GPT2: å¯ç”¨ (Transformeræ”¯æŒ)")
    except ImportError as e:
        print(f"âŒ GPT2: å¯¼å…¥å¤±è´¥ - {e}")
    
    print(f"\nğŸ“Š ç»Ÿä¸€ç¯å¢ƒæµ‹è¯•ç»“æœ: {success_count}/{len(tests)} æˆåŠŸ")
    return success_count >= len(tests) - 1

def check_package_versions():
    """æ£€æŸ¥å…³é”®åŒ…çš„ç‰ˆæœ¬"""
    print("ğŸ“‹ æ£€æŸ¥å…³é”®åŒ…ç‰ˆæœ¬...")

    packages_to_check = {
        'torch': '2.0.0',
        'torchvision': '0.15.0',
        'diffusers': '0.20.0',
        'transformers': '4.20.0',
        'numpy': '1.21.0',
        'pillow': '8.0.0',
        'matplotlib': '3.5.0',
        'tqdm': '4.60.0',
    }

    all_good = True

    for package, min_version in packages_to_check.items():
        try:
            module = importlib.import_module(package)
            version = getattr(module, '__version__', 'unknown')
            print(f"   âœ… {package}: {version}")
        except ImportError:
            print(f"   âŒ {package}: æœªå®‰è£…")
            all_good = False

    return all_good

def test_step_training_compatibility():
    """æµ‹è¯•åˆ†æ­¥è®­ç»ƒå…¼å®¹æ€§"""
    print("ğŸ§ª æµ‹è¯•åˆ†æ­¥è®­ç»ƒå…¼å®¹æ€§...")

    try:
        # æµ‹è¯•VQ-VAEç»„ä»¶
        print("   æµ‹è¯•VQ-VAEç»„ä»¶...")
        test_code = """
import torch
from diffusers import VQModel

# åˆ›å»ºæµ‹è¯•VQModel
model = VQModel(
    in_channels=3,
    out_channels=3,
    down_block_types=["DownEncoderBlock2D", "DownEncoderBlock2D"],
    up_block_types=["UpDecoderBlock2D", "UpDecoderBlock2D"],
    block_out_channels=[128, 256],
    layers_per_block=2,
    act_fn="silu",
    latent_channels=4,
    norm_num_groups=32,
    vq_embed_dim=256,
    num_vq_embeddings=1024,
)

# æµ‹è¯•ç¼–ç è§£ç 
x = torch.randn(1, 3, 64, 64)
encoded = model.encode(x)
decoded = model.decode(encoded.latents)
print("VQ-VAEæµ‹è¯•æˆåŠŸ")
"""

        result = subprocess.run([
            sys.executable, "-c", test_code
        ], capture_output=True, text=True, timeout=60)

        if result.returncode == 0:
            print("   âœ… VQ-VAEç»„ä»¶æµ‹è¯•é€šè¿‡")
        else:
            print(f"   âŒ VQ-VAEç»„ä»¶æµ‹è¯•å¤±è´¥: {result.stderr}")
            return False

        # æµ‹è¯•Transformerç»„ä»¶
        print("   æµ‹è¯•Transformerç»„ä»¶...")
        test_code = """
import torch
from diffusers import Transformer2DModel

# åˆ›å»ºæµ‹è¯•Transformer
model = Transformer2DModel(
    num_attention_heads=8,
    attention_head_dim=64,
    in_channels=4,
    num_layers=4,
    dropout=0.1,
    norm_num_groups=32,
    activation_fn="gelu",
)

# æµ‹è¯•å‰å‘ä¼ æ’­
x = torch.randn(1, 4, 16, 16)
output = model(x)
print("Transformeræµ‹è¯•æˆåŠŸ")
"""

        result = subprocess.run([
            sys.executable, "-c", test_code
        ], capture_output=True, text=True, timeout=60)

        if result.returncode == 0:
            print("   âœ… Transformerç»„ä»¶æµ‹è¯•é€šè¿‡")
            return True
        else:
            print(f"   âŒ Transformerç»„ä»¶æµ‹è¯•å¤±è´¥: {result.stderr}")
            return False

    except Exception as e:
        print(f"   âŒ å…¼å®¹æ€§æµ‹è¯•å¼‚å¸¸: {e}")
        return False

def create_training_scripts_info():
    """åˆ›å»ºè®­ç»ƒè„šæœ¬ä¿¡æ¯æ–‡ä»¶"""
    print("ğŸ“ åˆ›å»ºè®­ç»ƒè„šæœ¬ä¿¡æ¯...")

    info = {
        "step1_vqvae": {
            "script": "train_step1_vqvae.py",
            "description": "ç¬¬ä¸€æ­¥ï¼šè®­ç»ƒVQ-VAEæ¨¡å‹",
            "example_command": "python train_step1_vqvae.py --data_dir /path/to/data --output_dir ./step1_output",
            "output": "VQ-VAEæ¨¡å‹ä¿å­˜åœ¨ ./step1_output/vqvae_best/"
        },
        "step2_transformer": {
            "script": "train_step2_transformer.py",
            "description": "ç¬¬äºŒæ­¥ï¼šåŸºäºé¢„è®­ç»ƒVQ-VAEè®­ç»ƒTransformer",
            "example_command": "python train_step2_transformer.py --vqvae_path ./step1_output/vqvae_best --data_dir /path/to/data",
            "output": "Transformeræ¨¡å‹ä¿å­˜åœ¨ ./step2_output/transformer_best/"
        },
        "unified_training": {
            "script": "train_pure_diffusers.py",
            "description": "ç»Ÿä¸€è®­ç»ƒï¼šåŒæ—¶è®­ç»ƒVQ-VAEå’ŒTransformer",
            "example_command": "python train_pure_diffusers.py --data_dir /path/to/data",
            "output": "å®Œæ•´æ¨¡å‹ä¿å­˜åœ¨ ./pure_diffusers_output/"
        }
    }

    try:
        import json
        with open("training_info.json", "w", encoding="utf-8") as f:
            json.dump(info, f, indent=2, ensure_ascii=False)
        print("   âœ… è®­ç»ƒä¿¡æ¯æ–‡ä»¶å·²åˆ›å»º: training_info.json")
        return True
    except Exception as e:
        print(f"   âŒ åˆ›å»ºä¿¡æ¯æ–‡ä»¶å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ VQ-VAE + Transformer ç»Ÿä¸€ç¯å¢ƒé…ç½®")
    print("=" * 60)
    print("æ”¯æŒåˆ†æ­¥è®­ç»ƒå’Œç»Ÿä¸€è®­ç»ƒä¸¤ç§æ¨¡å¼")
    print("åŸºäºdiffusersæ ‡å‡†ç»„ä»¶çš„å®Œæ•´å®ç°")
    print("=" * 60)

    steps = [
        ("å®‰è£…PyTorch", install_pytorch),
        ("å®‰è£…æ ¸å¿ƒä¾èµ–", install_core_dependencies),
        ("å®‰è£…é¢å¤–ä¾èµ–", install_additional_dependencies),
        ("æµ‹è¯•ç¯å¢ƒ", test_unified_environment),
        ("æ£€æŸ¥åŒ…ç‰ˆæœ¬", check_package_versions),
        ("æµ‹è¯•åˆ†æ­¥è®­ç»ƒå…¼å®¹æ€§", test_step_training_compatibility),
        ("åˆ›å»ºè®­ç»ƒè„šæœ¬ä¿¡æ¯", create_training_scripts_info),
    ]

    for step_name, step_func in steps:
        print(f"\n{'='*20} {step_name} {'='*20}")
        if not step_func():
            print(f"\nâŒ {step_name}å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ...")

    print("\nğŸ‰ ç¯å¢ƒé…ç½®å®Œæˆï¼")
    print("=" * 60)
    print("ğŸ“‹ å¯ç”¨çš„è®­ç»ƒæ¨¡å¼:")
    print()
    print("ï¿½ åˆ†æ­¥è®­ç»ƒæ¨¡å¼ (æ¨è):")
    print("   1ï¸âƒ£ ç¬¬ä¸€æ­¥ - è®­ç»ƒVQ-VAE:")
    print("      python train_step1_vqvae.py --data_dir /path/to/data")
    print("   2ï¸âƒ£ ç¬¬äºŒæ­¥ - è®­ç»ƒTransformer:")
    print("      python train_step2_transformer.py --vqvae_path ./step1_vqvae_output/vqvae_best --data_dir /path/to/data")
    print()
    print("ï¿½ ç»Ÿä¸€è®­ç»ƒæ¨¡å¼:")
    print("   python train_pure_diffusers.py --data_dir /path/to/data")
    print()
    print("ğŸ“„ è¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹: training_info.json")

if __name__ == "__main__":
    main()
