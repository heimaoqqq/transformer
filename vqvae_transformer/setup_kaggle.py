#!/usr/bin/env python3
"""
Kaggleä¸“ç”¨ç¯å¢ƒå®‰è£…è„šæœ¬
é’ˆå¯¹Kaggleç¯å¢ƒä¼˜åŒ–ï¼Œç¡®ä¿APIå…¼å®¹æ€§
"""

import os
import sys
import subprocess
import importlib

def run_command(cmd, description=""):
    """è¿è¡Œå‘½ä»¤å¹¶å¤„ç†é”™è¯¯"""
    print(f"ğŸ”„ {description}")
    print(f"   å‘½ä»¤: {cmd}")
    
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, check=True)
        print(f"âœ… {description} æˆåŠŸ")
        if result.stdout:
            print(f"   è¾“å‡º: {result.stdout.strip()}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {description} å¤±è´¥")
        print(f"   é”™è¯¯: {e.stderr}")
        return False

def check_kaggle_environment():
    """æ£€æŸ¥Kaggleç¯å¢ƒ"""
    print("ğŸ  æ£€æŸ¥Kaggleç¯å¢ƒ...")
    
    # æ£€æŸ¥æ˜¯å¦åœ¨Kaggleç¯å¢ƒä¸­
    kaggle_indicators = [
        os.path.exists('/kaggle'),
        'KAGGLE_KERNEL_RUN_TYPE' in os.environ,
        'KAGGLE_URL_BASE' in os.environ,
    ]
    
    if any(kaggle_indicators):
        print("âœ… æ£€æµ‹åˆ°Kaggleç¯å¢ƒ")
        
        # æ£€æŸ¥GPU
        if os.path.exists('/opt/bin/nvidia-smi'):
            result = subprocess.run('nvidia-smi', shell=True, capture_output=True)
            if result.returncode == 0:
                print("âœ… GPUå¯ç”¨")
                return "gpu"
            else:
                print("âš ï¸ GPUä¸å¯ç”¨")
                return "cpu"
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°nvidia-smi")
            return "cpu"
    else:
        print("âš ï¸ ä¸åœ¨Kaggleç¯å¢ƒä¸­")
        return "local"

def uninstall_kaggle_conflicts():
    """å¸è½½Kaggleç¯å¢ƒä¸­å¯èƒ½å†²çªçš„åŒ…"""
    print("\nğŸ—‘ï¸ å¸è½½Kaggleç¯å¢ƒä¸­çš„å†²çªåŒ…...")
    
    # Kaggleé¢„è£…çš„åŒ…å¯èƒ½ç‰ˆæœ¬ä¸å…¼å®¹
    packages_to_uninstall = [
        "diffusers", "transformers", "accelerate",
        "huggingface-hub", "tokenizers", "safetensors"
    ]
    
    for package in packages_to_uninstall:
        cmd = f"pip uninstall {package} -y"
        run_command(cmd, f"å¸è½½ {package}")

def install_kaggle_pytorch():
    """åœ¨Kaggleç¯å¢ƒä¸­å®‰è£…PyTorch"""
    print("\nğŸ”¥ æ£€æŸ¥PyTorch...")
    
    try:
        import torch
        print(f"âœ… PyTorchå·²å®‰è£…: {torch.__version__}")
        
        # æ£€æŸ¥ç‰ˆæœ¬æ˜¯å¦å…¼å®¹
        if "2.1" in torch.__version__ or "2.0" in torch.__version__:
            print("âœ… PyTorchç‰ˆæœ¬å…¼å®¹")
            return True
        else:
            print(f"âš ï¸ PyTorchç‰ˆæœ¬å¯èƒ½ä¸å…¼å®¹: {torch.__version__}")
            
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        
    # åœ¨Kaggleä¸­é€šå¸¸ä¸éœ€è¦é‡è£…PyTorchï¼Œå› ä¸ºé¢„è£…ç‰ˆæœ¬é€šå¸¸å¯ç”¨
    print("â„¹ï¸ ä½¿ç”¨Kaggleé¢„è£…çš„PyTorchç‰ˆæœ¬")
    return True

def install_kaggle_huggingface():
    """åœ¨Kaggleç¯å¢ƒä¸­å®‰è£…HuggingFace"""
    print("\nğŸ¤— å®‰è£…HuggingFaceç”Ÿæ€ç³»ç»Ÿ...")
    
    # ä½¿ç”¨--no-depsé¿å…ä¾èµ–å†²çªï¼Œç„¶åæ‰‹åŠ¨å®‰è£…å¿…è¦ä¾èµ–
    hf_packages = [
        "huggingface-hub==0.19.4",
        "tokenizers==0.15.0",
        "safetensors==0.4.1", 
        "transformers==4.36.2",
        "accelerate==0.25.0",
        "diffusers==0.25.1",
    ]
    
    for package in hf_packages:
        # å…ˆå°è¯•æ­£å¸¸å®‰è£…
        if not run_command(f"pip install {package}", f"å®‰è£… {package}"):
            # å¦‚æœå¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶å®‰è£…
            run_command(f"pip install {package} --force-reinstall --no-deps", f"å¼ºåˆ¶å®‰è£… {package}")
    
    return True

def install_kaggle_other():
    """å®‰è£…å…¶ä»–å¿…è¦ä¾èµ–"""
    print("\nğŸ“¦ å®‰è£…å…¶ä»–ä¾èµ–...")
    
    # åªå®‰è£…å¯èƒ½ç¼ºå¤±çš„åŒ…
    other_packages = [
        "einops==0.7.0",
        "lpips==0.1.4",
    ]
    
    for package in other_packages:
        run_command(f"pip install {package}", f"å®‰è£… {package}")
    
    return True

def verify_kaggle_installation():
    """éªŒè¯Kaggleç¯å¢ƒä¸­çš„å®‰è£…"""
    print("\nğŸ” éªŒè¯å®‰è£…...")
    
    critical_packages = {
        'torch': None,  # ä¸æ£€æŸ¥å…·ä½“ç‰ˆæœ¬ï¼Œä½¿ç”¨Kaggleé¢„è£…ç‰ˆæœ¬
        'diffusers': '0.25.1',
        'transformers': '4.36.2', 
        'accelerate': '0.25.0',
    }
    
    all_good = True
    
    for package, expected_version in critical_packages.items():
        try:
            module = importlib.import_module(package)
            actual_version = getattr(module, '__version__', 'unknown')
            
            if expected_version is None or expected_version in actual_version:
                print(f"âœ… {package}: {actual_version}")
            else:
                print(f"âš ï¸ {package}: æœŸæœ› {expected_version}, å®é™… {actual_version}")
                # åœ¨Kaggleç¯å¢ƒä¸­ï¼Œç‰ˆæœ¬ä¸å®Œå…¨åŒ¹é…å¯èƒ½ä»ç„¶å¯ç”¨
                
        except ImportError as e:
            print(f"âŒ {package}: å¯¼å…¥å¤±è´¥ - {e}")
            all_good = False
    
    return all_good

def test_kaggle_apis():
    """æµ‹è¯•Kaggleç¯å¢ƒä¸­çš„API"""
    print("\nğŸ§ª æµ‹è¯•APIå…¼å®¹æ€§...")
    
    # æµ‹è¯•VQ-VAE API
    try:
        from diffusers.models.autoencoders.vq_model import VQModel
        print("âœ… VQModel APIå¯ç”¨")
        
        # ç®€å•æµ‹è¯•
        import torch
        model = VQModel(
            in_channels=3, out_channels=3,
            down_block_types=["DownEncoderBlock2D"],
            up_block_types=["UpDecoderBlock2D"],
            block_out_channels=[128],
            layers_per_block=1,
            latent_channels=128,
            sample_size=32,
            num_vq_embeddings=256,
            norm_num_groups=32,
            vq_embed_dim=128,
        )
        
        test_input = torch.randn(1, 3, 32, 32)
        with torch.no_grad():
            result = model.encode(test_input)
            print("âœ… VQModelæµ‹è¯•é€šè¿‡")
            
    except Exception as e:
        print(f"âŒ VQModelæµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•Transformer API
    try:
        from transformers import GPT2Config, GPT2LMHeadModel
        
        config = GPT2Config(vocab_size=256, n_positions=64, n_embd=128, n_layer=2, n_head=4)
        model = GPT2LMHeadModel(config)
        
        test_input = torch.randint(0, 256, (1, 16))
        with torch.no_grad():
            output = model(test_input)
            print("âœ… Transformeræµ‹è¯•é€šè¿‡")
            
    except Exception as e:
        print(f"âŒ Transformeræµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def optimize_kaggle_settings():
    """ä¼˜åŒ–Kaggleç¯å¢ƒè®¾ç½®"""
    print("\nâš™ï¸ ä¼˜åŒ–Kaggleè®¾ç½®...")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'
    os.environ['PYTHONUNBUFFERED'] = '1'
    
    # æ£€æŸ¥å¯ç”¨å†…å­˜
    try:
        import torch
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"âœ… GPUå†…å­˜: {gpu_memory:.1f}GB")
            
            if gpu_memory >= 15:
                print("   æ¨èé…ç½®: VQ-VAE batch_size=16, Transformer batch_size=8")
            else:
                print("   æ¨èé…ç½®: VQ-VAE batch_size=12, Transformer batch_size=6")
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°GPU")
            
    except Exception as e:
        print(f"âš ï¸ å†…å­˜æ£€æŸ¥å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ  Kaggle VQ-VAE + Transformer ç¯å¢ƒé…ç½®")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒ
    env_type = check_kaggle_environment()
    
    if env_type == "local":
        print("âš ï¸ ä¸åœ¨Kaggleç¯å¢ƒä¸­ï¼Œå»ºè®®ä½¿ç”¨ setup_environment.py")
        return
    
    # å¸è½½å†²çªåŒ…
    uninstall_kaggle_conflicts()
    
    # æ£€æŸ¥PyTorch
    if not install_kaggle_pytorch():
        print("âŒ PyTorché…ç½®å¤±è´¥")
        return
    
    # å®‰è£…HuggingFace
    if not install_kaggle_huggingface():
        print("âŒ HuggingFaceå®‰è£…å¤±è´¥")
        return
    
    # å®‰è£…å…¶ä»–ä¾èµ–
    install_kaggle_other()
    
    # éªŒè¯å®‰è£…
    if not verify_kaggle_installation():
        print("âš ï¸ éƒ¨åˆ†åŒ…éªŒè¯å¤±è´¥ï¼Œä½†å¯èƒ½ä»ç„¶å¯ç”¨")
    
    # æµ‹è¯•API
    if not test_kaggle_apis():
        print("âŒ APIæµ‹è¯•å¤±è´¥")
        return
    
    # ä¼˜åŒ–è®¾ç½®
    optimize_kaggle_settings()
    
    print("\nğŸ‰ Kaggleç¯å¢ƒé…ç½®å®Œæˆ!")
    print("âœ… å¯ä»¥å¼€å§‹è®­ç»ƒ:")
    print("   python train_main.py --data_dir /kaggle/input/dataset")
    
    # ä¿å­˜é…ç½®ä¿¡æ¯
    with open("/kaggle/working/kaggle_setup_complete.txt", "w") as f:
        f.write("Kaggle VQ-VAE + Transformer environment setup completed successfully\n")
        f.write(f"Python: {sys.version}\n")
        
        try:
            import torch, diffusers, transformers
            f.write(f"PyTorch: {torch.__version__}\n")
            f.write(f"Diffusers: {diffusers.__version__}\n") 
            f.write(f"Transformers: {transformers.__version__}\n")
        except:
            pass
    
    print("ğŸ“„ é…ç½®ä¿¡æ¯ä¿å­˜åˆ°: /kaggle/working/kaggle_setup_complete.txt")

if __name__ == "__main__":
    main()
