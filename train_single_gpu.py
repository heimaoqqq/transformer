#!/usr/bin/env python3
"""
å•GPUè®­ç»ƒå¯åŠ¨å™¨ - é¿å…å¤šGPUé€šä¿¡å¼€é”€
"""

import os
import sys
import subprocess
import torch
from pathlib import Path

def setup_single_gpu_environment():
    """è®¾ç½®å•GPUç¯å¢ƒ"""
    # å¼ºåˆ¶ä½¿ç”¨å•GPU
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    
    # ä¼˜åŒ–è®¾ç½®
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'
    os.environ['PYTHONUNBUFFERED'] = '1'
    
    # å¯ç”¨ä¼˜åŒ–
    torch.backends.cudnn.benchmark = True

def launch_single_gpu_training():
    """å¯åŠ¨å•GPUè®­ç»ƒ"""
    
    setup_single_gpu_environment()
    
    print("ğŸš€ å¯åŠ¨å•GPUé«˜æ•ˆè®­ç»ƒ...")
    print("ğŸ’¡ é¿å…å¤šGPUé€šä¿¡å¼€é”€")
    
    # æ˜¾ç¤ºGPUä¿¡æ¯
    if torch.cuda.is_available():
        props = torch.cuda.get_device_properties(0)
        print(f"   ğŸ® ä½¿ç”¨GPU: {props.name} - {props.total_memory / 1024**3:.1f} GB")
        
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
    
    cmd = [
        "python", "-u",
        "training/train_vae.py",
        "--data_dir", "/kaggle/input/dataset",
        "--output_dir", "/kaggle/working/outputs/vae",
        "--batch_size", "8",        # å•GPUå¯ä»¥ç”¨æ›´å¤§æ‰¹æ¬¡
        "--num_epochs", "30",
        "--learning_rate", "0.0002",
        "--mixed_precision", "fp16",
        "--gradient_accumulation_steps", "1", # å®æ—¶æ›´æ–°
        "--kl_weight", "1e-6",
        "--perceptual_weight", "0.0",
        "--freq_weight", "0.05",
        "--resolution", "256",
        "--num_workers", "2",       # å¤šçº¿ç¨‹æ•°æ®åŠ è½½
        "--save_interval", "5",
        "--log_interval", "2",
        "--sample_interval", "50",
        "--experiment_name", "kaggle_vae_single_gpu"
    ]
    
    print(f"ğŸ“Š å•GPUé…ç½®:")
    print(f"   ğŸ—ï¸  æ¶æ„: 3å±‚ä¸‹é‡‡æ · (55Må‚æ•°)")
    print(f"   ğŸ“¦ æ‰¹æ¬¡å¤§å°: 8")
    print(f"   ğŸ”¢ æ··åˆç²¾åº¦: FP16")
    print(f"   ğŸ§µ æ•°æ®çº¿ç¨‹: 2")
    print(f"   âš¡ æ¢¯åº¦ç´¯ç§¯: 1 (å®æ—¶)")
    print(f"   ğŸ’¾ é¢„æœŸå†…å­˜: ~4-6GB")
    print(f"   ğŸš€ é¢„æœŸé€Ÿåº¦: 2-3å€æå‡")
    
    print(f"\nCommand: {' '.join(cmd)}")
    print("=" * 80)
    
    try:
        # å¯åŠ¨è®­ç»ƒ
        process = subprocess.Popen(
            cmd,
            stdout=None,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=0
        )
        
        return_code = process.wait()
        
        if return_code == 0:
            print("\nâœ… å•GPUè®­ç»ƒå®Œæˆ!")
            return True
        else:
            print(f"\nâŒ è®­ç»ƒå¤±è´¥ (é€€å‡ºç : {return_code})")
            return False
            
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        process.terminate()
        return False
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¯åŠ¨å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å•GPUé«˜æ•ˆè®­ç»ƒ")
    print("=" * 50)
    
    print("ğŸ¯ ä¼˜åŒ–ç­–ç•¥:")
    print("   âœ… é¿å…å¤šGPUé€šä¿¡å¼€é”€")
    print("   âœ… 3å±‚ä¸‹é‡‡æ · (55Må‚æ•°)")
    print("   âœ… å¤§æ‰¹æ¬¡è®­ç»ƒ (batch_size=8)")
    print("   âœ… å®æ—¶æ¢¯åº¦æ›´æ–°")
    print("   âœ… FP16æ··åˆç²¾åº¦")
    
    print("\nğŸ“Š é¢„æœŸæ”¹è¿›:")
    print("   ğŸš€ è®­ç»ƒé€Ÿåº¦: +200-300%")
    print("   â±ï¸  æ¯è½®æ—¶é—´: 53åˆ†é’Ÿâ†’15-20åˆ†é’Ÿ")
    print("   ğŸ’¾ å†…å­˜ä½¿ç”¨: ~6GB")
    print("   ğŸ¯ è´¨é‡: ä¿æŒ (256Ã—256)")
    
    print("\nğŸ’¡ ä¸ºä»€ä¹ˆå•GPUå¯èƒ½æ›´å¿«:")
    print("   - é¿å…GPUé—´é€šä¿¡å»¶è¿Ÿ")
    print("   - å‡å°‘åŒæ­¥å¼€é”€")
    print("   - ç®€åŒ–å†…å­˜ç®¡ç†")
    print("   - é™ä½ç³»ç»Ÿå¤æ‚åº¦")
    
    success = launch_single_gpu_training()
    
    if success:
        print("\nğŸ‰ å•GPUè®­ç»ƒå®Œæˆ!")
        print("ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: /kaggle/working/outputs/vae/final_model")
    else:
        print("\nâŒ è®­ç»ƒå¤±è´¥!")
        sys.exit(1)

if __name__ == "__main__":
    main()
