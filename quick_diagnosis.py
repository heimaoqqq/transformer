#!/usr/bin/env python3
"""
å¿«é€Ÿè¯Šæ–­è„šæœ¬ï¼šæ£€æŸ¥PSNRåœæ»é—®é¢˜
åˆ†æç”Ÿæˆçš„tokenåºåˆ—å’Œå›¾åƒè´¨é‡
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

def analyze_generated_tokens():
    """åˆ†æç”Ÿæˆçš„tokenåºåˆ—"""
    print("ğŸ” åˆ†æç”Ÿæˆçš„tokenåºåˆ—...")
    
    # æ¨¡æ‹Ÿç”Ÿæˆçš„tokenåºåˆ—ï¼ˆä»è®­ç»ƒæ—¥å¿—å¯ä»¥çœ‹åˆ°èŒƒå›´æ˜¯[0, 1019]ï¼‰
    # è¿™é‡Œæˆ‘ä»¬åˆ†æå‡ ç§å¯èƒ½çš„æƒ…å†µ
    
    # æƒ…å†µ1ï¼šå®Œå…¨éšæœºçš„token
    random_tokens = torch.randint(0, 1020, (5, 1024))
    print(f"éšæœºtokenç¤ºä¾‹:")
    print(f"  å”¯ä¸€tokenæ•°é‡: {torch.unique(random_tokens[0]).shape[0]}/1024")
    print(f"  tokenåˆ†å¸ƒ: min={random_tokens.min()}, max={random_tokens.max()}")
    
    # æƒ…å†µ2ï¼šé‡å¤çš„tokenï¼ˆæ¨¡å¼å´©æºƒï¼‰
    repeated_tokens = torch.full((5, 1024), 100)  # å…¨æ˜¯100
    print(f"\né‡å¤tokenç¤ºä¾‹:")
    print(f"  å”¯ä¸€tokenæ•°é‡: {torch.unique(repeated_tokens[0]).shape[0]}/1024")
    
    # æƒ…å†µ3ï¼šæœ‰é™å¤šæ ·æ€§çš„token
    limited_tokens = torch.randint(0, 50, (5, 1024))  # åªä½¿ç”¨å‰50ä¸ªtoken
    print(f"\næœ‰é™å¤šæ ·æ€§tokenç¤ºä¾‹:")
    print(f"  å”¯ä¸€tokenæ•°é‡: {torch.unique(limited_tokens[0]).shape[0]}/1024")
    print(f"  tokenåˆ†å¸ƒ: min={limited_tokens.min()}, max={limited_tokens.max()}")

def check_vqvae_decoding():
    """æ£€æŸ¥VQ-VAEè§£ç æ˜¯å¦æ­£å¸¸"""
    print("\nğŸ” æ£€æŸ¥VQ-VAEè§£ç ...")
    
    try:
        from models.vqvae_model import MicroDopplerVQVAE
        
        # è¿™é‡Œéœ€è¦å®é™…çš„VQ-VAEæ¨¡å‹è·¯å¾„
        print("éœ€è¦åŠ è½½å®é™…çš„VQ-VAEæ¨¡å‹æ¥æµ‹è¯•è§£ç ...")
        print("å»ºè®®æ‰‹åŠ¨è¿è¡Œä»¥ä¸‹æµ‹è¯•:")
        print("1. åŠ è½½VQ-VAEæ¨¡å‹")
        print("2. åˆ›å»ºæµ‹è¯•tokenåºåˆ—")
        print("3. æµ‹è¯•è§£ç è¿‡ç¨‹")
        print("4. æ£€æŸ¥è¾“å‡ºå›¾åƒæ˜¯å¦åˆç†")
        
    except Exception as e:
        print(f"æ— æ³•åŠ è½½VQ-VAEæ¨¡å‹: {e}")

def analyze_psnr_calculation():
    """åˆ†æPSNRè®¡ç®—æ˜¯å¦æ­£ç¡®"""
    print("\nğŸ” åˆ†æPSNRè®¡ç®—...")
    
    # æ¨¡æ‹ŸPSNRè®¡ç®—
    def calculate_psnr(img1, img2, max_val=2.0):
        """è®¡ç®—PSNR"""
        mse = torch.mean((img1 - img2) ** 2)
        if mse == 0:
            return float('inf')
        psnr = 20 * torch.log10(max_val / torch.sqrt(mse))
        return psnr.item()
    
    # æµ‹è¯•ä¸åŒæƒ…å†µçš„PSNR
    # æƒ…å†µ1ï¼šå®Œå…¨ç›¸åŒçš„å›¾åƒ
    img1 = torch.randn(3, 128, 128)
    img2 = img1.clone()
    psnr_identical = calculate_psnr(img1, img2)
    print(f"ç›¸åŒå›¾åƒPSNR: {psnr_identical:.2f} dB (åº”è¯¥æ˜¯inf)")
    
    # æƒ…å†µ2ï¼šè½»å¾®å·®å¼‚çš„å›¾åƒ
    img2_slight = img1 + torch.randn_like(img1) * 0.01
    psnr_slight = calculate_psnr(img1, img2_slight)
    print(f"è½»å¾®å·®å¼‚PSNR: {psnr_slight:.2f} dB (åº”è¯¥å¾ˆé«˜)")
    
    # æƒ…å†µ3ï¼šå¾ˆå¤§å·®å¼‚çš„å›¾åƒ
    img2_large = torch.randn_like(img1)
    psnr_large = calculate_psnr(img1, img2_large)
    print(f"å¾ˆå¤§å·®å¼‚PSNR: {psnr_large:.2f} dB (åº”è¯¥å¾ˆä½)")
    
    # æƒ…å†µ4ï¼šé»‘è‰²å›¾åƒ vs æ­£å¸¸å›¾åƒ
    black_img = torch.zeros_like(img1)
    normal_img = torch.randn_like(img1) * 0.5
    psnr_black = calculate_psnr(black_img, normal_img)
    print(f"é»‘è‰²vsæ­£å¸¸å›¾åƒPSNR: {psnr_black:.2f} dB")
    
    print(f"\næˆ‘ä»¬çš„è®­ç»ƒPSNR: ~9 dB")
    print(f"è¿™è¡¨æ˜ç”Ÿæˆçš„å›¾åƒä¸åŸå›¾å·®å¼‚å¾ˆå¤§ï¼Œå¯èƒ½æ¥è¿‘éšæœºå™ªå£°æ°´å¹³")

def suggest_debugging_steps():
    """å»ºè®®è°ƒè¯•æ­¥éª¤"""
    print("\nğŸ¯ å»ºè®®çš„è°ƒè¯•æ­¥éª¤:")
    
    print("\n1. æ£€æŸ¥ç”Ÿæˆçš„æ ·æœ¬å›¾åƒ:")
    print("   - æŸ¥çœ‹ /kaggle/working/outputs/vqvae_transformer/transformer/samples/")
    print("   - æ£€æŸ¥å›¾åƒæ˜¯å¦æ˜¯é»‘è‰²ã€å™ªå£°æˆ–æœ‰æ„ä¹‰çš„ç»“æ„")
    
    print("\n2. åˆ†ætokenç”Ÿæˆè´¨é‡:")
    print("   - æ£€æŸ¥ç”Ÿæˆçš„tokenæ˜¯å¦æœ‰å¤šæ ·æ€§")
    print("   - éªŒè¯ä¸åŒç”¨æˆ·æ˜¯å¦ç”Ÿæˆä¸åŒçš„tokenåºåˆ—")
    
    print("\n3. éªŒè¯VQ-VAEè§£ç :")
    print("   - ç”¨å·²çŸ¥çš„å¥½tokenæµ‹è¯•VQ-VAEè§£ç ")
    print("   - ç¡®è®¤force_not_quantize=Trueæ˜¯å¦æ­£ç¡®")
    
    print("\n4. æ£€æŸ¥è¯„ä¼°é€»è¾‘:")
    print("   - éªŒè¯PSNRè®¡ç®—æ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„å›¾åƒèŒƒå›´")
    print("   - ç¡®è®¤åŸå›¾å’Œç”Ÿæˆå›¾çš„é¢„å¤„ç†æ˜¯å¦ä¸€è‡´")
    
    print("\n5. å¯èƒ½çš„ä¿®å¤æ–¹æ¡ˆ:")
    print("   - å¦‚æœå›¾åƒæ˜¯é»‘è‰²ï¼šVQ-VAEè§£ç é—®é¢˜")
    print("   - å¦‚æœå›¾åƒæ˜¯å™ªå£°ï¼šç”Ÿæˆæ¨¡å¼å´©æºƒ")
    print("   - å¦‚æœå›¾åƒçœ‹èµ·æ¥æ­£å¸¸ä½†PSNRä½ï¼šè¯„ä¼°é€»è¾‘é—®é¢˜")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš¨ Transformerè®­ç»ƒPSNRåœæ»é—®é¢˜è¯Šæ–­")
    print("="*50)
    
    analyze_generated_tokens()
    check_vqvae_decoding()
    analyze_psnr_calculation()
    suggest_debugging_steps()
    
    print("\n" + "="*50)
    print("ğŸ“‹ è¯Šæ–­å®Œæˆï¼è¯·æ ¹æ®å»ºè®®è¿›è¡Œè¿›ä¸€æ­¥è°ƒè¯•ã€‚")

if __name__ == "__main__":
    main()
