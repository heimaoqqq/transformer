#!/usr/bin/env python3
"""
Kaggleå¿«é€Ÿä¿®å¤è„šæœ¬ - ä¸€é”®è§£å†³ç‰ˆæœ¬å†²çª
"""

import subprocess
import sys

def run_pip(command, description=""):
    """è¿è¡Œpipå‘½ä»¤"""
    print(f"ğŸ”„ {description}")
    try:
        result = subprocess.run(f"pip {command}", shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… {description} - æˆåŠŸ")
            return True
        else:
            print(f"âŒ {description} - å¤±è´¥: {result.stderr}")
            return False
    except Exception as e:
        print(f"âŒ {description} - å¼‚å¸¸: {e}")
        return False

def quick_fix():
    """å¿«é€Ÿä¿®å¤ç‰ˆæœ¬å†²çª"""
    print("ğŸš€ Kaggleå¿«é€Ÿä¿®å¤å·¥å…·")
    print("=" * 40)
    
    # 1. å®‰è£…PyTorch (å¦‚æœéœ€è¦)
    print("\n1ï¸âƒ£ ç¡®ä¿PyTorchæ­£ç¡®ç‰ˆæœ¬...")
    run_pip("install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu121", 
            "å®‰è£…PyTorch 2.1.0")
    
    # 2. å®‰è£…æ ¸å¿ƒä¾èµ– (æŒ‡å®šå…¼å®¹ç‰ˆæœ¬)
    print("\n2ï¸âƒ£ å®‰è£…æ ¸å¿ƒä¾èµ–...")

    # å…ˆå®‰è£…å…¼å®¹çš„huggingface_hub
    run_pip("install 'huggingface_hub>=0.20.0,<0.25.0'", "å®‰è£…å…¼å®¹çš„ huggingface_hub")

    # ç„¶åå®‰è£…å…¶ä»–åŒ…
    packages = [
        "diffusers>=0.27.0",
        "transformers>=4.35.0",
        "accelerate>=0.24.0",
        "einops",
        "opencv-python"
    ]

    for package in packages:
        run_pip(f"install {package}", f"å®‰è£… {package}")
    
    # 3. æµ‹è¯•å¯¼å…¥
    print("\n3ï¸âƒ£ æµ‹è¯•å¯¼å…¥...")
    test_modules = [
        ('torch', 'PyTorch'),
        ('diffusers', 'Diffusers'),
        ('transformers', 'Transformers')
    ]
    
    success = 0
    for module, name in test_modules:
        try:
            exec(f"import {module}")
            print(f"âœ… {name} å¯¼å…¥æˆåŠŸ")
            success += 1
        except Exception as e:
            print(f"âŒ {name} å¯¼å…¥å¤±è´¥: {e}")
    
    # 4. æµ‹è¯•VAEåŠŸèƒ½
    print("\n4ï¸âƒ£ æµ‹è¯•VAEåŠŸèƒ½...")
    try:
        from diffusers import AutoencoderKL
        import torch
        
        vae = AutoencoderKL(
            in_channels=3,
            out_channels=3, 
            latent_channels=4,
            sample_size=32
        )
        
        with torch.no_grad():
            test_input = torch.randn(1, 3, 32, 32)
            latents = vae.encode(test_input).latent_dist.sample()
            reconstructed = vae.decode(latents).sample
        
        print("âœ… VAEåŠŸèƒ½æµ‹è¯•é€šè¿‡")
        print(f"   è¾“å…¥: {test_input.shape}")
        print(f"   æ½œåœ¨: {latents.shape}")
        print(f"   é‡å»º: {reconstructed.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ VAEåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    if quick_fix():
        print("\nğŸ‰ ä¿®å¤æˆåŠŸï¼")
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        print("   python train_kaggle.py --stage all")
    else:
        print("\nâš ï¸  ä¿®å¤æœªå®Œå…¨æˆåŠŸï¼Œä½†å¯ä»¥å°è¯•è®­ç»ƒ")
        print("\nğŸ“‹ æ•…éšœæ’é™¤:")
        print("   1. é‡å¯Kaggleå†…æ ¸")
        print("   2. é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
        print("   3. æˆ–è¿è¡Œ: python fix_versions_kaggle.py")

if __name__ == "__main__":
    main()
