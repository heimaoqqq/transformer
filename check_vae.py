#!/usr/bin/env python3
"""
VAEè®­ç»ƒæ£€æŸ¥å·¥å…· - é›†æˆç‰ˆ
æ£€æŸ¥è®­ç»ƒçŠ¶æ€ã€æ¨¡å‹è´¨é‡å’Œé‡å»ºæ•ˆæœ
"""

import os
import json
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from diffusers import AutoencoderKL
from utils.data_loader import MicroDopplerDataset
from torch.utils.data import DataLoader
import argparse

class VAEChecker:
    """VAEæ£€æŸ¥å™¨"""
    
    def __init__(self, output_dir="/kaggle/working/outputs", data_dir="/kaggle/input/dataset"):
        self.output_dir = Path(output_dir)
        self.data_dir = data_dir
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
    def check_training_status(self):
        """æ£€æŸ¥è®­ç»ƒçŠ¶æ€"""
        print("ğŸ“Š VAEè®­ç»ƒçŠ¶æ€æ£€æŸ¥")
        print("=" * 50)
        
        if not self.output_dir.exists():
            print("âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œå¯èƒ½è¿˜æ²¡æœ‰å¼€å§‹è®­ç»ƒ")
            print("ğŸ’¡ è¿è¡Œ: python train_celeba_standard.py")
            return False
        
        # æŸ¥æ‰¾è®­ç»ƒç›®å½•
        training_dirs = [d for d in self.output_dir.iterdir() if d.is_dir()]
        
        if not training_dirs:
            print("âŒ æœªæ‰¾åˆ°è®­ç»ƒç›®å½•")
            return False
        
        print(f"ğŸ” æ‰¾åˆ° {len(training_dirs)} ä¸ªè®­ç»ƒç›®å½•")
        
        available_models = []
        for train_dir in training_dirs:
            final_model = train_dir / "final_model"
            if final_model.exists() and (final_model / "config.json").exists():
                available_models.append(final_model)
                print(f"âœ… å¯ç”¨æ¨¡å‹: {train_dir.name}")
                self._check_model_details(final_model)
        
        return len(available_models) > 0
    
    def _check_model_details(self, model_dir):
        """æ£€æŸ¥æ¨¡å‹è¯¦ç»†ä¿¡æ¯"""
        config_path = model_dir / "config.json"
        
        if config_path.exists():
            try:
                with open(config_path, 'r') as f:
                    config = json.load(f)
                
                print(f"   ğŸ“Š æ¨¡å‹é…ç½®:")
                print(f"     - è¾“å…¥é€šé“: {config.get('in_channels', 'N/A')}")
                print(f"     - æ½œåœ¨é€šé“: {config.get('latent_channels', 'N/A')}")
                print(f"     - ä¸‹é‡‡æ ·å±‚: {len(config.get('down_block_types', []))}")
                print(f"     - é€šé“é…ç½®: {config.get('block_out_channels', 'N/A')}")
                
            except Exception as e:
                print(f"   âŒ é…ç½®è¯»å–å¤±è´¥: {e}")
    
    def test_model_loading(self, model_path=None):
        """æµ‹è¯•æ¨¡å‹åŠ è½½"""
        print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹åŠ è½½")
        
        if model_path is None:
            # è‡ªåŠ¨æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
            for train_dir in self.output_dir.iterdir():
                if train_dir.is_dir():
                    final_model = train_dir / "final_model"
                    if final_model.exists():
                        model_path = final_model
                        break
        
        if model_path is None:
            print("âŒ æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹")
            return None, None
        
        try:
            print(f"ğŸ”„ åŠ è½½æ¨¡å‹: {model_path}")
            vae = AutoencoderKL.from_pretrained(str(model_path))
            vae = vae.to(self.device)
            vae.eval()
            
            # æ¨¡å‹ä¿¡æ¯
            total_params = sum(p.numel() for p in vae.parameters())
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   ğŸ“Š å‚æ•°é‡: {total_params:,}")
            print(f"   ğŸ’¾ æ¨¡å‹å¤§å°: {total_params * 4 / 1024**2:.1f} MB")
            
            # æµ‹è¯•å‰å‘ä¼ æ’­
            test_input = torch.randn(1, 3, 64, 64).to(self.device)
            with torch.no_grad():
                posterior = vae.encode(test_input).latent_dist
                latent = posterior.sample()
                output = vae.decode(latent).sample
            
            print(f"âœ… å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")
            print(f"   ğŸ“ å‹ç¼©æ¯”: {test_input.numel() / latent.numel():.1f}:1")
            
            return vae, model_path
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None, None
    
    def check_reconstruction_quality(self, vae=None, num_samples=8):
        """æ£€æŸ¥é‡å»ºè´¨é‡"""
        print(f"\nğŸ¨ é‡å»ºè´¨é‡æ£€æŸ¥ ({num_samples} å¼ å›¾åƒ)")

        if vae is None:
            vae, _ = self.test_model_loading()
            if vae is None:
                return None

        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            dataset = MicroDopplerDataset(
                data_dir=self.data_dir,
                resolution=64,  # CelebAæ ‡å‡†
                augment=False,
                split="test"
            )

            print(f"ğŸ“Š æµ‹è¯•æ•°æ®: {len(dataset)} å¼ å›¾åƒ")

            # éšæœºé€‰æ‹©æ ·æœ¬
            indices = torch.randperm(len(dataset))[:num_samples]

            # åˆ›å»ºæ›´å¤§çš„å›¾åƒç½‘æ ¼
            fig, axes = plt.subplots(3, num_samples, figsize=(num_samples * 2, 6))

            # å¦‚æœåªæœ‰ä¸€ä¸ªæ ·æœ¬ï¼Œç¡®ä¿axesæ˜¯2Dæ•°ç»„
            if num_samples == 1:
                axes = axes.reshape(3, 1)

            mse_scores = []
            psnr_scores = []

            print(f"ğŸ”„ æ­£åœ¨é‡å»º {num_samples} å¼ å›¾åƒ...")

            with torch.no_grad():
                for i, idx in enumerate(indices):
                    # è·å–åŸå§‹å›¾åƒ
                    sample = dataset[idx]
                    original = sample['image'].unsqueeze(0).to(self.device)
                    user_id = sample.get('user_id', 'N/A')

                    # VAEé‡å»º
                    posterior = vae.encode(original).latent_dist
                    latent = posterior.sample()
                    reconstructed = vae.decode(latent).sample

                    # è½¬æ¢ä¸ºnumpy
                    orig_np = original.squeeze().cpu().numpy().transpose(1, 2, 0)
                    recon_np = reconstructed.squeeze().cpu().numpy().transpose(1, 2, 0)

                    # ç¡®ä¿æ•°å€¼èŒƒå›´åœ¨[0,1]
                    orig_np = np.clip(orig_np, 0, 1)
                    recon_np = np.clip(recon_np, 0, 1)

                    # è®¡ç®—æŒ‡æ ‡
                    mse = np.mean((orig_np - recon_np) ** 2)
                    psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')
                    mse_scores.append(mse)
                    psnr_scores.append(psnr)

                    # æ˜¾ç¤ºåŸå§‹å›¾åƒ
                    axes[0, i].imshow(orig_np)
                    axes[0, i].set_title(f'åŸå§‹ {i+1}\nUser: {user_id}', fontsize=10)
                    axes[0, i].axis('off')

                    # æ˜¾ç¤ºé‡å»ºå›¾åƒ
                    axes[1, i].imshow(recon_np)
                    axes[1, i].set_title(f'é‡å»º {i+1}\nPSNR: {psnr:.1f}dB', fontsize=10)
                    axes[1, i].axis('off')

                    # å·®å¼‚å›¾ (çƒ­åŠ›å›¾)
                    diff = np.abs(orig_np - recon_np)
                    # è½¬æ¢ä¸ºç°åº¦ç”¨äºçƒ­åŠ›å›¾
                    diff_gray = np.mean(diff, axis=2)
                    im = axes[2, i].imshow(diff_gray, cmap='hot', vmin=0, vmax=0.3)
                    axes[2, i].set_title(f'å·®å¼‚ {i+1}\nMSE: {mse:.4f}', fontsize=10)
                    axes[2, i].axis('off')

                    print(f"   âœ… æ ·æœ¬ {i+1}: PSNR={psnr:.1f}dB, MSE={mse:.4f}")

            # æ·»åŠ é¢œè‰²æ¡
            plt.colorbar(im, ax=axes[2, :], orientation='horizontal',
                        fraction=0.05, pad=0.1, label='é‡å»ºè¯¯å·®')

            plt.suptitle(f'VAEé‡å»ºè´¨é‡æ£€æŸ¥ - {num_samples} å¼ å¾®å¤šæ™®å‹’å›¾åƒ', fontsize=14, y=0.98)
            plt.tight_layout()

            # ä¿å­˜é«˜è´¨é‡å›¾åƒ
            save_path = "/kaggle/working/vae_reconstruction_comparison.png"
            plt.savefig(save_path, dpi=200, bbox_inches='tight', facecolor='white')
            plt.show()

            print(f"âœ… é‡å»ºå¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
            
            # è®¡ç®—æ€»ä½“æŒ‡æ ‡
            avg_mse = np.mean(mse_scores)
            psnr = 20 * np.log10(1.0 / np.sqrt(avg_mse)) if avg_mse > 0 else float('inf')
            
            # è®¡ç®—ç›¸å…³ç³»æ•°
            all_orig = []
            all_recon = []
            
            with torch.no_grad():
                for idx in indices[:4]:  # ä½¿ç”¨å‰4ä¸ªæ ·æœ¬è®¡ç®—ç›¸å…³æ€§
                    sample = dataset[idx]
                    original = sample['image'].unsqueeze(0).to(self.device)
                    posterior = vae.encode(original).latent_dist
                    latent = posterior.sample()
                    reconstructed = vae.decode(latent).sample
                    
                    all_orig.append(original.cpu().numpy().flatten())
                    all_recon.append(reconstructed.cpu().numpy().flatten())
            
            correlation = np.corrcoef(np.concatenate(all_orig), np.concatenate(all_recon))[0, 1]
            
            # æ˜¾ç¤ºæŒ‡æ ‡
            print(f"\nğŸ“Š é‡å»ºè´¨é‡æŒ‡æ ‡:")
            print(f"   MSE: {avg_mse:.6f}")
            print(f"   PSNR: {psnr:.2f} dB")
            print(f"   ç›¸å…³ç³»æ•°: {correlation:.4f}")
            
            # è´¨é‡è¯„ä¼°
            print(f"\nğŸ¯ è´¨é‡è¯„ä¼°:")
            if psnr > 25:
                print("âœ… é‡å»ºè´¨é‡: ä¼˜ç§€ (PSNR > 25dB)")
            elif psnr > 20:
                print("âœ… é‡å»ºè´¨é‡: è‰¯å¥½ (PSNR > 20dB)")
            elif psnr > 15:
                print("âš ï¸  é‡å»ºè´¨é‡: ä¸€èˆ¬ (PSNR > 15dB)")
            else:
                print("âŒ é‡å»ºè´¨é‡: è¾ƒå·® (PSNR < 15dB)")
            
            if correlation > 0.9:
                print("âœ… ç›¸å…³æ€§: å¾ˆé«˜")
            elif correlation > 0.8:
                print("âœ… ç›¸å…³æ€§: é«˜")
            elif correlation > 0.7:
                print("âš ï¸  ç›¸å…³æ€§: ä¸­ç­‰")
            else:
                print("âŒ ç›¸å…³æ€§: ä½")
            
            print(f"\nğŸ“ ç»“æœä¿å­˜: {save_path}")
            
            return {
                'mse': avg_mse,
                'psnr': psnr,
                'correlation': correlation
            }
            
        except Exception as e:
            print(f"âŒ é‡å»ºæ£€æŸ¥å¤±è´¥: {e}")
            return None
    
    def full_check(self):
        """å®Œæ•´æ£€æŸ¥æµç¨‹"""
        print("ğŸ” VAEå®Œæ•´æ£€æŸ¥")
        print("=" * 60)
        
        # 1. æ£€æŸ¥è®­ç»ƒçŠ¶æ€
        if not self.check_training_status():
            print("\nğŸ’¡ è¯·å…ˆå®ŒæˆVAEè®­ç»ƒ:")
            print("   python train_celeba_standard.py")
            return
        
        # 2. æµ‹è¯•æ¨¡å‹åŠ è½½
        vae, model_path = self.test_model_loading()
        if vae is None:
            return
        
        # 3. æ£€æŸ¥é‡å»ºè´¨é‡
        metrics = self.check_reconstruction_quality(vae)
        
        # 4. æ€»ç»“å’Œå»ºè®®
        print(f"\n" + "=" * 60)
        print(f"ğŸ“‹ æ£€æŸ¥æ€»ç»“:")
        
        if metrics:
            if metrics['psnr'] > 20 and metrics['correlation'] > 0.8:
                print("ğŸ‰ VAEè®­ç»ƒæˆåŠŸï¼æ¨¡å‹è´¨é‡è‰¯å¥½")
                print("âœ… å¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥æ‰©æ•£æ¨¡å‹è®­ç»ƒ")
            elif metrics['psnr'] > 15:
                print("âš ï¸  VAEè´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®ä¼˜åŒ–")
                print("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
                print("   - é™ä½KLæƒé‡ (--kl_weight 1e-7)")
                print("   - å»¶é•¿è®­ç»ƒæ—¶é—´")
                print("   - è°ƒæ•´å­¦ä¹ ç‡")
            else:
                print("âŒ VAEè´¨é‡è¾ƒå·®ï¼Œéœ€è¦é‡æ–°è®­ç»ƒ")
                print("ğŸ’¡ é‡æ–°è®­ç»ƒå»ºè®®:")
                print("   - æ£€æŸ¥æ•°æ®è´¨é‡")
                print("   - é™ä½KLæƒé‡")
                print("   - å¢åŠ è®­ç»ƒè½®æ•°")
        
        print(f"\nğŸ® ä½¿ç”¨çš„è®¾å¤‡: {self.device}")
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")

    def analyze_latent_space(self, vae=None):
        """åˆ†ææ½œåœ¨ç©ºé—´"""
        print(f"\nğŸ” æ½œåœ¨ç©ºé—´åˆ†æ")

        if vae is None:
            vae, _ = self.test_model_loading()
            if vae is None:
                return

        try:
            dataset = MicroDopplerDataset(
                data_dir=self.data_dir,
                resolution=64,
                augment=False,
                split="test"
            )

            # æ”¶é›†æ½œåœ¨å‘é‡
            latents_list = []
            num_samples = min(50, len(dataset))

            with torch.no_grad():
                for i in range(num_samples):
                    sample = dataset[i]
                    image = sample['image'].unsqueeze(0).to(self.device)
                    posterior = vae.encode(image).latent_dist
                    latent = posterior.sample()
                    latents_list.append(latent.cpu().numpy())

            latents = np.concatenate(latents_list, axis=0)

            print(f"ğŸ“Š æ½œåœ¨ç©ºé—´ç»Ÿè®¡ ({num_samples} æ ·æœ¬):")
            print(f"   å½¢çŠ¶: {latents.shape}")
            print(f"   å‡å€¼: {np.mean(latents):.4f}")
            print(f"   æ ‡å‡†å·®: {np.std(latents):.4f}")
            print(f"   æœ€å°å€¼: {np.min(latents):.4f}")
            print(f"   æœ€å¤§å€¼: {np.max(latents):.4f}")

            # åˆ†ææ¯ä¸ªé€šé“
            print(f"   å„é€šé“ç»Ÿè®¡:")
            for c in range(latents.shape[1]):
                channel_data = latents[:, c, :, :]
                print(f"     é€šé“{c}: å‡å€¼={np.mean(channel_data):.3f}, æ ‡å‡†å·®={np.std(channel_data):.3f}")

        except Exception as e:
            print(f"âŒ æ½œåœ¨ç©ºé—´åˆ†æå¤±è´¥: {e}")

    def generate_reconstruction_grid(self, vae=None, num_samples=8, save_individual=True):
        """ç”Ÿæˆé‡å»ºå›¾åƒç½‘æ ¼ï¼Œå¯é€‰æ‹©ä¿å­˜å•ç‹¬å›¾åƒ"""
        print(f"\nğŸ–¼ï¸  ç”Ÿæˆé‡å»ºå›¾åƒç½‘æ ¼ ({num_samples} å¼ )")

        if vae is None:
            vae, _ = self.test_model_loading()
            if vae is None:
                return None

        try:
            dataset = MicroDopplerDataset(
                data_dir=self.data_dir,
                resolution=64,
                augment=False,
                split="test"
            )

            # éšæœºé€‰æ‹©æ ·æœ¬
            indices = torch.randperm(len(dataset))[:num_samples]

            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = Path("/kaggle/working/reconstruction_samples")
            output_dir.mkdir(exist_ok=True)

            # ç”Ÿæˆå¤§ç½‘æ ¼å›¾
            fig, axes = plt.subplots(2, num_samples, figsize=(num_samples * 2.5, 5))
            if num_samples == 1:
                axes = axes.reshape(2, 1)

            all_metrics = []

            with torch.no_grad():
                for i, idx in enumerate(indices):
                    sample = dataset[idx]
                    original = sample['image'].unsqueeze(0).to(self.device)
                    user_id = sample.get('user_id', f'sample_{idx}')

                    # VAEé‡å»º
                    posterior = vae.encode(original).latent_dist
                    latent = posterior.sample()
                    reconstructed = vae.decode(latent).sample

                    # è½¬æ¢ä¸ºnumpy
                    orig_np = original.squeeze().cpu().numpy().transpose(1, 2, 0)
                    recon_np = reconstructed.squeeze().cpu().numpy().transpose(1, 2, 0)
                    orig_np = np.clip(orig_np, 0, 1)
                    recon_np = np.clip(recon_np, 0, 1)

                    # è®¡ç®—æŒ‡æ ‡
                    mse = np.mean((orig_np - recon_np) ** 2)
                    psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')
                    all_metrics.append({'mse': mse, 'psnr': psnr, 'user_id': user_id})

                    # ç½‘æ ¼å›¾æ˜¾ç¤º
                    axes[0, i].imshow(orig_np)
                    axes[0, i].set_title(f'åŸå§‹-{i+1}\nUser: {user_id}', fontsize=9)
                    axes[0, i].axis('off')

                    axes[1, i].imshow(recon_np)
                    axes[1, i].set_title(f'é‡å»º-{i+1}\nPSNR: {psnr:.1f}dB', fontsize=9)
                    axes[1, i].axis('off')

                    # ä¿å­˜å•ç‹¬çš„å¯¹æ¯”å›¾
                    if save_individual:
                        fig_single, axes_single = plt.subplots(1, 3, figsize=(12, 4))

                        # åŸå§‹å›¾åƒ
                        axes_single[0].imshow(orig_np)
                        axes_single[0].set_title(f'åŸå§‹å›¾åƒ\nUser: {user_id}', fontsize=12)
                        axes_single[0].axis('off')

                        # é‡å»ºå›¾åƒ
                        axes_single[1].imshow(recon_np)
                        axes_single[1].set_title(f'é‡å»ºå›¾åƒ\nPSNR: {psnr:.1f}dB', fontsize=12)
                        axes_single[1].axis('off')

                        # å·®å¼‚å›¾
                        diff = np.abs(orig_np - recon_np)
                        diff_gray = np.mean(diff, axis=2)
                        im = axes_single[2].imshow(diff_gray, cmap='hot', vmin=0, vmax=0.3)
                        axes_single[2].set_title(f'é‡å»ºè¯¯å·®\nMSE: {mse:.4f}', fontsize=12)
                        axes_single[2].axis('off')

                        plt.colorbar(im, ax=axes_single[2], fraction=0.046, pad=0.04)
                        plt.suptitle(f'VAEé‡å»ºå¯¹æ¯” - æ ·æœ¬ {i+1}', fontsize=14)
                        plt.tight_layout()

                        single_path = output_dir / f"reconstruction_sample_{i+1}_user_{user_id}.png"
                        plt.savefig(single_path, dpi=150, bbox_inches='tight', facecolor='white')
                        plt.close(fig_single)

                        print(f"   ğŸ’¾ ä¿å­˜å•ç‹¬å›¾åƒ: {single_path.name}")

            # ä¿å­˜ç½‘æ ¼å›¾
            plt.suptitle(f'VAEé‡å»ºè´¨é‡ç½‘æ ¼ - {num_samples} å¼ å¾®å¤šæ™®å‹’å›¾åƒ', fontsize=14)
            plt.tight_layout()

            grid_path = "/kaggle/working/vae_reconstruction_grid.png"
            plt.savefig(grid_path, dpi=200, bbox_inches='tight', facecolor='white')
            plt.show()

            # ç»Ÿè®¡æ€»ç»“
            avg_psnr = np.mean([m['psnr'] for m in all_metrics])
            avg_mse = np.mean([m['mse'] for m in all_metrics])

            print(f"\nğŸ“Š ç”Ÿæˆæ€»ç»“:")
            print(f"   ğŸ–¼ï¸  ç½‘æ ¼å›¾: {grid_path}")
            print(f"   ğŸ“ å•ç‹¬å›¾åƒ: {output_dir} ({num_samples} å¼ )")
            print(f"   ğŸ“ˆ å¹³å‡PSNR: {avg_psnr:.2f} dB")
            print(f"   ğŸ“‰ å¹³å‡MSE: {avg_mse:.6f}")

            return all_metrics

        except Exception as e:
            print(f"âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
            return None

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="VAEæ£€æŸ¥å·¥å…·")
    parser.add_argument("--mode", choices=["status", "quick", "full", "latent", "generate"], default="full",
                       help="æ£€æŸ¥æ¨¡å¼: status(çŠ¶æ€), quick(å¿«é€Ÿ), full(å®Œæ•´), latent(æ½œåœ¨ç©ºé—´), generate(ç”Ÿæˆå›¾åƒ)")
    parser.add_argument("--output_dir", default="/kaggle/working/outputs",
                       help="è¾“å‡ºç›®å½•è·¯å¾„")
    parser.add_argument("--data_dir", default="/kaggle/input/dataset",
                       help="æ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--num_samples", type=int, default=8,
                       help="é‡å»ºæ£€æŸ¥çš„æ ·æœ¬æ•°é‡")
    parser.add_argument("--save_individual", action="store_true",
                       help="æ˜¯å¦ä¿å­˜å•ç‹¬çš„é‡å»ºå¯¹æ¯”å›¾")
    
    args = parser.parse_args()
    
    checker = VAEChecker(args.output_dir, args.data_dir)
    
    if args.mode == "status":
        checker.check_training_status()
    elif args.mode == "quick":
        vae, _ = checker.test_model_loading()
        if vae:
            checker.check_reconstruction_quality(vae, args.num_samples)
    elif args.mode == "latent":
        checker.analyze_latent_space()
    elif args.mode == "generate":
        vae, _ = checker.test_model_loading()
        if vae:
            checker.generate_reconstruction_grid(vae, args.num_samples, args.save_individual)
    else:  # full
        checker.full_check()

if __name__ == "__main__":
    main()
