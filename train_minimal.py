#!/usr/bin/env python3
"""
æç®€è®­ç»ƒå™¨ - æœ€å°å¼€é”€ï¼Œæœ€å¤§æ•ˆç‡
"""

import os
import sys
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/kaggle/working/VAE')

def setup_minimal_environment():
    """è®¾ç½®æç®€ç¯å¢ƒ"""
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # å•GPU
    os.environ['PYTHONUNBUFFERED'] = '1'
    torch.backends.cudnn.benchmark = True

def create_minimal_vae():
    """åˆ›å»ºæç®€VAE"""
    from diffusers import AutoencoderKL
    
    vae = AutoencoderKL(
        in_channels=3,
        out_channels=3,
        down_block_types=[
            "DownEncoderBlock2D",  # 256â†’128
            "DownEncoderBlock2D",  # 128â†’64
            "DownEncoderBlock2D"   # 64â†’32
        ],
        up_block_types=[
            "UpDecoderBlock2D",    # 32â†’64
            "UpDecoderBlock2D",    # 64â†’128
            "UpDecoderBlock2D"     # 128â†’256
        ],
        block_out_channels=[128, 256, 512],
        latent_channels=4,
        sample_size=256,
        layers_per_block=2,
    )
    
    return vae

def minimal_training():
    """æç®€è®­ç»ƒå¾ªç¯"""
    
    setup_minimal_environment()
    
    print("ğŸš€ æç®€é«˜æ•ˆè®­ç»ƒ")
    print("=" * 50)
    
    device = torch.device("cuda:0")
    
    # 1. åˆ›å»ºæ¨¡å‹
    print("ğŸ“¦ åˆ›å»ºVAEæ¨¡å‹...")
    vae = create_minimal_vae()
    vae = vae.to(device)
    vae.train()
    
    # å¯ç”¨æ··åˆç²¾åº¦
    scaler = torch.cuda.amp.GradScaler()
    
    # 2. åˆ›å»ºæ•°æ®é›†
    print("ğŸ“ åŠ è½½æ•°æ®é›†...")
    from utils.data_loader import MicroDopplerDataset
    
    dataset = MicroDopplerDataset(
        data_dir="/kaggle/input/dataset",
        resolution=256,
        split="train"
    )
    
    dataloader = DataLoader(
        dataset,
        batch_size=8,  # å¤§æ‰¹æ¬¡
        shuffle=True,
        num_workers=2,
        pin_memory=True,
        drop_last=True
    )
    
    print(f"   æ•°æ®é›†å¤§å°: {len(dataset)}")
    print(f"   æ‰¹æ¬¡æ•°: {len(dataloader)}")
    
    # 3. åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        vae.parameters(),
        lr=2e-4,
        betas=(0.9, 0.999),
        weight_decay=1e-2
    )
    
    # 4. æŸå¤±å‡½æ•°
    mse_loss = nn.MSELoss()
    
    # 5. è®­ç»ƒå¾ªç¯
    print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    
    num_epochs = 20  # å‡å°‘epochæ•°
    global_step = 0
    
    for epoch in range(num_epochs):
        epoch_start_time = time.time()
        
        progress_bar = tqdm(
            dataloader,
            desc=f"Epoch {epoch+1}/{num_epochs}",
            dynamic_ncols=True
        )
        
        epoch_loss = 0.0
        
        for step, batch in enumerate(progress_bar):
            step_start_time = time.time()
            
            # è·å–æ•°æ®
            images = batch['image'].to(device, non_blocking=True)
            
            # å‰å‘ä¼ æ’­ (æ··åˆç²¾åº¦)
            with torch.cuda.amp.autocast():
                posterior = vae.encode(images).latent_dist
                latents = posterior.sample()
                reconstruction = vae.decode(latents).sample
                
                # è®¡ç®—æŸå¤±
                recon_loss = mse_loss(reconstruction, images)
                kl_loss = posterior.kl().mean()
                total_loss = recon_loss + 1e-6 * kl_loss
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            scaler.scale(total_loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            # ç»Ÿè®¡
            epoch_loss += total_loss.item()
            global_step += 1
            
            step_time = time.time() - step_start_time
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'loss': f"{total_loss.item():.4f}",
                'recon': f"{recon_loss.item():.4f}",
                'kl': f"{kl_loss.item():.6f}",
                'step_time': f"{step_time:.2f}s"
            })
            
            # å®šæœŸæ¸…ç†å†…å­˜
            if step % 100 == 0:
                torch.cuda.empty_cache()
        
        epoch_time = time.time() - epoch_start_time
        avg_loss = epoch_loss / len(dataloader)
        
        print(f"Epoch {epoch+1} å®Œæˆ:")
        print(f"   æ—¶é—´: {epoch_time/60:.1f}åˆ†é’Ÿ")
        print(f"   å¹³å‡æŸå¤±: {avg_loss:.4f}")
        print(f"   é¢„è®¡å‰©ä½™: {epoch_time * (num_epochs - epoch - 1) / 60:.1f}åˆ†é’Ÿ")
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % 5 == 0:
            save_path = f"/kaggle/working/vae_epoch_{epoch+1}.pth"
            torch.save(vae.state_dict(), save_path)
            print(f"   ä¿å­˜æ£€æŸ¥ç‚¹: {save_path}")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_path = "/kaggle/working/vae_final.pth"
    torch.save(vae.state_dict(), final_path)
    print(f"âœ… è®­ç»ƒå®Œæˆ! æ¨¡å‹ä¿å­˜: {final_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("âš¡ æç®€é«˜æ•ˆVAEè®­ç»ƒ")
    print("=" * 50)
    
    print("ğŸ¯ æç®€ç­–ç•¥:")
    print("   âœ… å•GPUé¿å…é€šä¿¡å¼€é”€")
    print("   âœ… æ··åˆç²¾åº¦åŠ é€Ÿ")
    print("   âœ… å¤§æ‰¹æ¬¡æé«˜æ•ˆç‡")
    print("   âœ… å»é™¤ä¸å¿…è¦çš„æ¡†æ¶")
    print("   âœ… 3å±‚ä¸‹é‡‡æ · (55Må‚æ•°)")
    
    print("\nğŸ“Š é¢„æœŸæ•ˆæœ:")
    print("   ğŸš€ è®­ç»ƒé€Ÿåº¦: æœ€å¤§åŒ–")
    print("   â±ï¸  æ¯è½®æ—¶é—´: 10-15åˆ†é’Ÿ")
    print("   ğŸ’¾ å†…å­˜ä½¿ç”¨: ~6GB")
    print("   ğŸ¯ è´¨é‡: ä¿æŒ")
    
    try:
        minimal_training()
        print("\nğŸ‰ æç®€è®­ç»ƒæˆåŠŸ!")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
