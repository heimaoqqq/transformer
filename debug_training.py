#!/usr/bin/env python3
"""
è°ƒè¯•è®­ç»ƒè„šæœ¬ - æ‰¾å‡ºè®­ç»ƒå¡ä½çš„åŸå› 
"""

import os
import sys
import torch
import torch.nn as nn
from pathlib import Path
from tqdm import tqdm
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir
sys.path.insert(0, str(project_root))

def test_gpu_setup():
    """æµ‹è¯•GPUè®¾ç½®"""
    print("ğŸ” æµ‹è¯•GPUè®¾ç½®...")
    
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨")
        return False
    
    gpu_count = torch.cuda.device_count()
    print(f"âœ… æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    for i in range(gpu_count):
        props = torch.cuda.get_device_properties(i)
        print(f"   GPU {i}: {props.name} - {props.total_memory / 1024**3:.1f} GB")
    
    return True

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("\nğŸ” æµ‹è¯•æ•°æ®åŠ è½½...")
    
    try:
        from utils.data_loader import MicroDopplerDataset
        from torch.utils.data import DataLoader
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = MicroDopplerDataset(
            data_dir="/kaggle/input/dataset",
            resolution=256,
            split="train"
        )
        
        print(f"âœ… æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        dataloader = DataLoader(
            dataset,
            batch_size=2,  # å°æ‰¹æ¬¡æµ‹è¯•
            shuffle=False,
            num_workers=0,  # å•çº¿ç¨‹æµ‹è¯•
            pin_memory=True
        )
        
        print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡
        print("ğŸ”„ æµ‹è¯•åŠ è½½ç¬¬ä¸€ä¸ªæ‰¹æ¬¡...")
        start_time = time.time()
        
        for i, batch in enumerate(dataloader):
            load_time = time.time() - start_time
            print(f"âœ… æ‰¹æ¬¡ {i} åŠ è½½æˆåŠŸ ({load_time:.2f}s)")
            print(f"   å›¾åƒå½¢çŠ¶: {batch['image'].shape}")
            print(f"   ç”¨æˆ·ç´¢å¼•: {batch['user_idx'].shape}")
            
            if i >= 2:  # åªæµ‹è¯•å‰3ä¸ªæ‰¹æ¬¡
                break
            
            start_time = time.time()
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\nğŸ” æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    try:
        from diffusers import AutoencoderKL
        
        print("ğŸ”„ åˆ›å»ºVAEæ¨¡å‹...")
        vae = AutoencoderKL(
            in_channels=3,
            out_channels=3,
            down_block_types=[
                "DownEncoderBlock2D",
                "DownEncoderBlock2D",
                "DownEncoderBlock2D",
                "DownEncoderBlock2D",
            ],
            up_block_types=[
                "UpDecoderBlock2D",
                "UpDecoderBlock2D", 
                "UpDecoderBlock2D",
                "UpDecoderBlock2D",
            ],
            block_out_channels=[128, 256, 512, 512],
            latent_channels=4,
            sample_size=256,
        )
        
        print("âœ… VAEæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # ç§»åŠ¨åˆ°GPU
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        vae = vae.to(device)
        print(f"âœ… æ¨¡å‹ç§»åŠ¨åˆ° {device}")
        
        return vae, device
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def test_forward_pass(vae, device):
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print("\nğŸ” æµ‹è¯•å‰å‘ä¼ æ’­...")
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 2
        test_images = torch.randn(batch_size, 3, 256, 256).to(device)
        print(f"âœ… æµ‹è¯•æ•°æ®åˆ›å»ºæˆåŠŸ: {test_images.shape}")
        
        # æµ‹è¯•ç¼–ç 
        print("ğŸ”„ æµ‹è¯•VAEç¼–ç ...")
        start_time = time.time()
        
        with torch.no_grad():
            posterior = vae.encode(test_images).latent_dist
            latents = posterior.sample()
        
        encode_time = time.time() - start_time
        print(f"âœ… ç¼–ç æˆåŠŸ ({encode_time:.2f}s): {latents.shape}")
        
        # æµ‹è¯•è§£ç 
        print("ğŸ”„ æµ‹è¯•VAEè§£ç ...")
        start_time = time.time()
        
        with torch.no_grad():
            reconstruction = vae.decode(latents).sample
        
        decode_time = time.time() - start_time
        print(f"âœ… è§£ç æˆåŠŸ ({decode_time:.2f}s): {reconstruction.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_accelerate_setup():
    """æµ‹è¯•Accelerateè®¾ç½®"""
    print("\nğŸ” æµ‹è¯•Accelerateè®¾ç½®...")
    
    try:
        from accelerate import Accelerator
        
        accelerator = Accelerator(
            gradient_accumulation_steps=2,
            mixed_precision="fp16"
        )
        
        print(f"âœ… Acceleratoråˆ›å»ºæˆåŠŸ")
        print(f"   è®¾å¤‡: {accelerator.device}")
        print(f"   è¿›ç¨‹æ•°: {accelerator.num_processes}")
        print(f"   åˆ†å¸ƒå¼ç±»å‹: {accelerator.distributed_type}")
        print(f"   æ˜¯å¦ä¸»è¿›ç¨‹: {accelerator.is_main_process}")
        
        return accelerator
        
    except Exception as e:
        print(f"âŒ Accelerateè®¾ç½®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_training_step():
    """æµ‹è¯•å®Œæ•´çš„è®­ç»ƒæ­¥éª¤"""
    print("\nğŸ” æµ‹è¯•å®Œæ•´è®­ç»ƒæ­¥éª¤...")
    
    # æµ‹è¯•æ‰€æœ‰ç»„ä»¶
    if not test_gpu_setup():
        return False
    
    if not test_data_loading():
        return False
    
    vae, device = test_model_creation()
    if vae is None:
        return False
    
    if not test_forward_pass(vae, device):
        return False
    
    accelerator = test_accelerate_setup()
    if accelerator is None:
        return False
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ è®­ç»ƒè°ƒè¯•å·¥å…·")
    print("=" * 50)
    
    success = test_training_step()
    
    if success:
        print("\nâœ… è°ƒè¯•å®Œæˆ - æ²¡æœ‰å‘ç°é—®é¢˜")
        print("ğŸ’¡ å»ºè®®: å°è¯•å‡å°‘æ‰¹æ¬¡å¤§å°æˆ–æ£€æŸ¥æ•°æ®é›†")
    else:
        print("\nâŒ å‘ç°é—®é¢˜ - è¯·æŸ¥çœ‹ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main()
