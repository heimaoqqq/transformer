#!/usr/bin/env python3
"""
æ¨ç†è·¯å¾„ä¿®å¤è„šæœ¬
è‡ªåŠ¨æ£€æµ‹å’Œä¿®å¤æ¨ç†æ‰€éœ€çš„æ–‡ä»¶è·¯å¾„
"""

import os
from pathlib import Path
import argparse

def find_model_files():
    """æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶ä½ç½®"""
    print("ğŸ” æœç´¢æ¨¡å‹æ–‡ä»¶...")
    
    # å¯èƒ½çš„VAEè·¯å¾„
    vae_paths = [
        "/kaggle/input/final-model",
        "/kaggle/input/vae-model", 
        "/kaggle/input/vae",
        "/kaggle/working/outputs/vae_*/final_model"
    ]
    
    # å¯èƒ½çš„æ‰©æ•£æ¨¡å‹è·¯å¾„
    diffusion_paths = [
        "/kaggle/input/diffusion-final-model",
        "/kaggle/input/diffusion-model",
        "/kaggle/working/outputs/diffusion/final_model"
    ]
    
    found_files = {}
    
    # æŸ¥æ‰¾VAE
    print("\n1ï¸âƒ£ æŸ¥æ‰¾VAEæ¨¡å‹...")
    for path in vae_paths:
        if Path(path).exists():
            config_file = Path(path) / "config.json"
            weight_file = Path(path) / "diffusion_pytorch_model.safetensors"
            if config_file.exists() and weight_file.exists():
                found_files['vae'] = str(path)
                print(f"  âœ… æ‰¾åˆ°VAE: {path}")
                break
    else:
        print("  âŒ æœªæ‰¾åˆ°VAEæ¨¡å‹")
    
    # æŸ¥æ‰¾UNet
    print("\n2ï¸âƒ£ æŸ¥æ‰¾UNetæ¨¡å‹...")
    for path in diffusion_paths:
        unet_path = Path(path) / "unet"
        if unet_path.exists():
            config_file = unet_path / "config.json"
            weight_file = unet_path / "diffusion_pytorch_model.safetensors"
            if config_file.exists() and weight_file.exists():
                found_files['unet'] = str(unet_path)
                print(f"  âœ… æ‰¾åˆ°UNet: {unet_path}")
                break
    else:
        print("  âŒ æœªæ‰¾åˆ°UNetæ¨¡å‹")
    
    # æŸ¥æ‰¾æ¡ä»¶ç¼–ç å™¨
    print("\n3ï¸âƒ£ æŸ¥æ‰¾æ¡ä»¶ç¼–ç å™¨...")
    for path in diffusion_paths:
        condition_file = Path(path) / "condition_encoder.pt"
        if condition_file.exists():
            found_files['condition_encoder'] = str(condition_file)
            print(f"  âœ… æ‰¾åˆ°æ¡ä»¶ç¼–ç å™¨: {condition_file}")
            break
        # ä¹Ÿæ£€æŸ¥ç›®å½•æœ¬èº«
        elif Path(path).exists():
            found_files['condition_encoder'] = str(path)  # ç›®å½•è·¯å¾„ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨å¤„ç†
            print(f"  âœ… æ‰¾åˆ°æ¡ä»¶ç¼–ç å™¨ç›®å½•: {path}")
            break
    else:
        print("  âŒ æœªæ‰¾åˆ°æ¡ä»¶ç¼–ç å™¨")
    
    return found_files

def generate_inference_command(found_files, user_ids=None, output_dir=None):
    """ç”Ÿæˆæ­£ç¡®çš„æ¨ç†å‘½ä»¤"""
    if not all(key in found_files for key in ['vae', 'unet', 'condition_encoder']):
        print("âŒ ç¼ºå°‘å¿…è¦çš„æ¨¡å‹æ–‡ä»¶ï¼Œæ— æ³•ç”Ÿæˆæ¨ç†å‘½ä»¤")
        return None
    
    user_ids = user_ids or [1, 5, 10, 15]
    output_dir = output_dir or "/kaggle/working/generated_images"
    
    command = f"""python inference/generate.py \\
    --vae_path "{found_files['vae']}" \\
    --unet_path "{found_files['unet']}" \\
    --condition_encoder_path "{found_files['condition_encoder']}" \\
    --num_users 31 \\
    --user_ids {' '.join(map(str, user_ids))} \\
    --num_images_per_user 3 \\
    --num_inference_steps 50 \\
    --guidance_scale 7.5 \\
    --output_dir "{output_dir}\""""
    
    return command

def create_inference_script(found_files, output_file="run_inference.sh"):
    """åˆ›å»ºå¯æ‰§è¡Œçš„æ¨ç†è„šæœ¬"""
    command = generate_inference_command(found_files)
    if command is None:
        return False
    
    script_content = f"""#!/bin/bash
# è‡ªåŠ¨ç”Ÿæˆçš„æ¨ç†è„šæœ¬
# ç”Ÿæˆæ—¶é—´: $(date)

echo "ğŸš€ å¼€å§‹å¾®å¤šæ™®å‹’å›¾åƒç”Ÿæˆ..."
echo "ğŸ“ ä½¿ç”¨çš„æ¨¡å‹æ–‡ä»¶:"
echo "  VAE: {found_files['vae']}"
echo "  UNet: {found_files['unet']}"
echo "  æ¡ä»¶ç¼–ç å™¨: {found_files['condition_encoder']}"
echo ""

{command}

echo ""
echo "âœ… æ¨ç†å®Œæˆï¼"
echo "ğŸ“ ç”Ÿæˆçš„å›¾åƒä¿å­˜åœ¨: /kaggle/working/generated_images/"
"""
    
    with open(output_file, 'w') as f:
        f.write(script_content)
    
    # ä½¿è„šæœ¬å¯æ‰§è¡Œ
    os.chmod(output_file, 0o755)
    
    print(f"ğŸ“ æ¨ç†è„šæœ¬å·²ä¿å­˜: {output_file}")
    return True

def main():
    parser = argparse.ArgumentParser(description="ä¿®å¤æ¨ç†è·¯å¾„å¹¶ç”Ÿæˆæ¨ç†å‘½ä»¤")
    parser.add_argument("--user_ids", type=int, nargs="+", default=[1, 5, 10, 15], help="è¦ç”Ÿæˆçš„ç”¨æˆ·ID")
    parser.add_argument("--output_dir", type=str, default="/kaggle/working/generated_images", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--create_script", action="store_true", help="åˆ›å»ºå¯æ‰§è¡Œçš„æ¨ç†è„šæœ¬")
    
    args = parser.parse_args()
    
    print("ğŸ”§ æ¨ç†è·¯å¾„ä¿®å¤å·¥å…·")
    print("=" * 50)
    
    # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    found_files = find_model_files()
    
    print("\nğŸ“‹ æ‰¾åˆ°çš„æ–‡ä»¶:")
    for key, path in found_files.items():
        print(f"  {key}: {path}")
    
    # ç”Ÿæˆæ¨ç†å‘½ä»¤
    print("\nğŸš€ æ¨ç†å‘½ä»¤:")
    command = generate_inference_command(found_files, args.user_ids, args.output_dir)
    
    if command:
        print("```bash")
        print(command)
        print("```")
        
        # åˆ›å»ºè„šæœ¬æ–‡ä»¶
        if args.create_script:
            create_inference_script(found_files)
    
    # æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
    print("\nğŸ” æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥:")
    all_good = True
    
    for key, path in found_files.items():
        if Path(path).exists():
            if Path(path).is_file():
                size = Path(path).stat().st_size / (1024**2)
                print(f"  âœ… {key}: {size:.1f} MB")
            else:
                print(f"  âœ… {key}: ç›®å½•å­˜åœ¨")
        else:
            print(f"  âŒ {key}: æ–‡ä»¶ä¸å­˜åœ¨")
            all_good = False
    
    if all_good:
        print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹æ¨ç†ï¼")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥è®­ç»ƒæ˜¯å¦å®Œæˆ")

if __name__ == "__main__":
    main()
