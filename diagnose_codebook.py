#!/usr/bin/env python3
"""
ç æœ¬è¯Šæ–­è„šæœ¬
å®æ—¶æ£€æŸ¥VQ-VAEè®­ç»ƒè¿‡ç¨‹ä¸­çš„ç æœ¬çŠ¶æ€
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import argparse

def load_model_for_diagnosis(output_dir):
    """åŠ è½½æ¨¡å‹è¿›è¡Œè¯Šæ–­ - æ”¯æŒfinal_modelå’Œcheckpoint"""
    output_path = Path(output_dir)

    # ä¼˜å…ˆå°è¯•åŠ è½½final_model (diffusersæ ¼å¼)
    final_model_path = output_path / "final_model"
    if final_model_path.exists():
        print(f"ğŸ“‚ æ£€æµ‹åˆ°final_modelç›®å½•: {final_model_path}")
        try:
            # å¯¼å…¥æ¨¡å‹ç±»
            import sys
            sys.path.append(str(output_path.parent.parent))
            from models.vqvae_model import MicroDopplerVQVAE

            # åŠ è½½æ¨¡å‹
            model = MicroDopplerVQVAE.from_pretrained(final_model_path)
            print(f"âœ… æˆåŠŸåŠ è½½final_model")

            # åˆ›å»ºä¼ªcheckpointæ ¼å¼ä»¥å…¼å®¹ç°æœ‰åˆ†æå‡½æ•°
            checkpoint = {
                'model_state_dict': model.state_dict(),
                'epoch': 'final_model',
                'args': None,  # final_modelä¸­æ²¡æœ‰è®­ç»ƒå‚æ•°
            }
            return checkpoint

        except Exception as e:
            print(f"âš ï¸ final_modelåŠ è½½å¤±è´¥: {e}")
            print("ğŸ”„ å°è¯•checkpointæ ¼å¼...")

    # å¤‡é€‰ï¼šæŸ¥æ‰¾æœ€æ–°çš„checkpoint
    checkpoints = list(output_path.glob("checkpoint_epoch_*.pth"))
    if checkpoints:
        latest_checkpoint = max(checkpoints, key=lambda x: int(x.stem.split('_')[-1]))
        print(f"ğŸ“‚ åŠ è½½checkpoint: {latest_checkpoint}")
        return torch.load(latest_checkpoint, map_location='cpu', weights_only=False)

    # å°è¯•best_model.pth
    best_model_path = output_path / "best_model.pth"
    if best_model_path.exists():
        print(f"ğŸ“‚ åŠ è½½best_model: {best_model_path}")
        return torch.load(best_model_path, map_location='cpu', weights_only=False)

    print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶")
    return None

def analyze_codebook_collapse(checkpoint):
    """åˆ†æç æœ¬åç¼©æƒ…å†µ"""
    print("\nğŸ” ç æœ¬åç¼©è¯Šæ–­:")
    
    # è·å–æ¨¡å‹çŠ¶æ€
    model_state = checkpoint['model_state_dict']
    
    # æŸ¥æ‰¾é‡åŒ–å™¨çš„åµŒå…¥æƒé‡
    embedding_key = None
    for key in model_state.keys():
        if 'quantize' in key and 'embedding' in key and 'weight' in key:
            embedding_key = key
            break
    
    if embedding_key is None:
        print("âŒ æœªæ‰¾åˆ°é‡åŒ–å™¨åµŒå…¥æƒé‡")
        return
    
    embeddings = model_state[embedding_key]  # [n_embed, embed_dim]
    print(f"ğŸ“Š ç æœ¬å½¢çŠ¶: {embeddings.shape}")
    
    # è®¡ç®—åµŒå…¥å‘é‡ä¹‹é—´çš„è·ç¦»
    n_embed, embed_dim = embeddings.shape
    
    # è®¡ç®—æ‰€æœ‰åµŒå…¥å‘é‡çš„æˆå¯¹è·ç¦»
    distances = torch.cdist(embeddings, embeddings, p=2)
    
    # å»é™¤å¯¹è§’çº¿ï¼ˆè‡ªå·±ä¸è‡ªå·±çš„è·ç¦»ï¼‰
    mask = ~torch.eye(n_embed, dtype=bool)
    min_distances = distances[mask].view(n_embed, n_embed-1).min(dim=1)[0]
    
    # åˆ†æè·ç¦»åˆ†å¸ƒ
    mean_min_dist = min_distances.mean().item()
    std_min_dist = min_distances.std().item()
    
    print(f"ğŸ“ æœ€å°è·ç¦»ç»Ÿè®¡:")
    print(f"   å¹³å‡æœ€å°è·ç¦»: {mean_min_dist:.4f}")
    print(f"   æ ‡å‡†å·®: {std_min_dist:.4f}")
    
    # æ£€æŸ¥åç¼©æŒ‡æ ‡
    collapse_threshold = 0.01  # å¦‚æœæœ€å°è·ç¦»å°äºè¿™ä¸ªå€¼ï¼Œè®¤ä¸ºå¯èƒ½åç¼©
    collapsed_codes = (min_distances < collapse_threshold).sum().item()
    
    print(f"ğŸš¨ åç¼©åˆ†æ:")
    print(f"   ç–‘ä¼¼åç¼©ç æœ¬æ•°: {collapsed_codes}/{n_embed}")
    print(f"   åç¼©æ¯”ä¾‹: {collapsed_codes/n_embed*100:.1f}%")
    
    if collapsed_codes > n_embed * 0.1:  # è¶…è¿‡10%åç¼©
        print("âš ï¸ è­¦å‘Š: æ£€æµ‹åˆ°ä¸¥é‡ç æœ¬åç¼©!")
    elif collapsed_codes > 0:
        print("âš ï¸ æ³¨æ„: æ£€æµ‹åˆ°è½»å¾®ç æœ¬åç¼©")
    else:
        print("âœ… ç æœ¬çŠ¶æ€è‰¯å¥½ï¼Œæ— æ˜æ˜¾åç¼©")
    
    # å¯è§†åŒ–è·ç¦»åˆ†å¸ƒ
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 3, 1)
    plt.hist(min_distances.numpy(), bins=50, alpha=0.7)
    plt.axvline(collapse_threshold, color='red', linestyle='--', label=f'åç¼©é˜ˆå€¼ ({collapse_threshold})')
    plt.xlabel('æœ€å°è·ç¦»')
    plt.ylabel('é¢‘æ¬¡')
    plt.title('ç æœ¬æœ€å°è·ç¦»åˆ†å¸ƒ')
    plt.legend()
    
    plt.subplot(1, 3, 2)
    plt.imshow(distances.numpy(), cmap='viridis')
    plt.colorbar()
    plt.title('ç æœ¬è·ç¦»çŸ©é˜µ')
    plt.xlabel('ç æœ¬ç´¢å¼•')
    plt.ylabel('ç æœ¬ç´¢å¼•')
    
    plt.subplot(1, 3, 3)
    # æ˜¾ç¤ºåµŒå…¥å‘é‡çš„èŒƒæ•°
    norms = torch.norm(embeddings, dim=1)
    plt.hist(norms.numpy(), bins=50, alpha=0.7)
    plt.xlabel('åµŒå…¥å‘é‡èŒƒæ•°')
    plt.ylabel('é¢‘æ¬¡')
    plt.title('åµŒå…¥å‘é‡èŒƒæ•°åˆ†å¸ƒ')
    
    plt.tight_layout()
    plt.savefig('codebook_diagnosis.png', dpi=150, bbox_inches='tight')
    plt.show()
    
    return {
        'mean_min_distance': mean_min_dist,
        'collapsed_codes': collapsed_codes,
        'collapse_ratio': collapsed_codes/n_embed,
        'total_codes': n_embed
    }

def analyze_training_dynamics(checkpoint):
    """åˆ†æè®­ç»ƒåŠ¨æ€"""
    print("\nğŸ“ˆ è®­ç»ƒåŠ¨æ€åˆ†æ:")

    epoch = checkpoint['epoch']
    print(f"ğŸ“… å½“å‰epoch: {epoch}")

    # æ£€æŸ¥ä¼˜åŒ–å™¨çŠ¶æ€
    if 'optimizer_state_dict' in checkpoint:
        optimizer_state = checkpoint['optimizer_state_dict']
        if 'param_groups' in optimizer_state:
            lr = optimizer_state['param_groups'][0]['lr']
            print(f"ğŸ“š å½“å‰å­¦ä¹ ç‡: {lr:.2e}")
    else:
        print("ğŸ“š å­¦ä¹ ç‡: N/A (final_model)")

    # æ£€æŸ¥è®­ç»ƒå‚æ•°
    if 'args' in checkpoint and checkpoint['args'] is not None:
        args = checkpoint['args']
        print(f"ğŸ¯ è®­ç»ƒé…ç½®:")
        print(f"   ç æœ¬å¤§å°: {args.codebook_size}")
        print(f"   Commitmentæƒé‡: {args.commitment_cost}")
        print(f"   EMAè¡°å‡: {getattr(args, 'ema_decay', 'N/A')}")
    else:
        print("ğŸ¯ è®­ç»ƒé…ç½®: N/A (final_modelæ ¼å¼)")

def main():
    parser = argparse.ArgumentParser(description="VQ-VAEç æœ¬è¯Šæ–­å·¥å…·")
    parser.add_argument("--output_dir", type=str, 
                       default="/kaggle/working/outputs/vqvae_transformer/vqvae",
                       help="VQ-VAEè¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    print("ğŸ”¬ VQ-VAEç æœ¬è¯Šæ–­å·¥å…·")
    print("=" * 50)
    
    # åŠ è½½æ¨¡å‹è¿›è¡Œè¯Šæ–­
    checkpoint = load_model_for_diagnosis(args.output_dir)
    if checkpoint is None:
        return
    
    # åˆ†æè®­ç»ƒåŠ¨æ€
    analyze_training_dynamics(checkpoint)
    
    # åˆ†æç æœ¬åç¼©
    stats = analyze_codebook_collapse(checkpoint)
    
    print("\nğŸ’¡ å»ºè®®:")
    if stats['collapse_ratio'] > 0.1:
        print("ğŸ”§ ä¸¥é‡åç¼©ï¼Œå»ºè®®:")
        print("   1. é™ä½commitment_cost (å¦‚0.1)")
        print("   2. å¢åŠ ema_decay (å¦‚0.995)")
        print("   3. é™ä½å­¦ä¹ ç‡")
    elif stats['collapse_ratio'] > 0.05:
        print("âš ï¸ è½»å¾®åç¼©ï¼Œå»ºè®®:")
        print("   1. ç›‘æ§åç»­è®­ç»ƒ")
        print("   2. è€ƒè™‘è°ƒæ•´commitment_cost")
    else:
        print("âœ… ç æœ¬çŠ¶æ€è‰¯å¥½ï¼Œç»§ç»­è®­ç»ƒ")

if __name__ == "__main__":
    main()
