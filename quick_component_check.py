#!/usr/bin/env python3
"""
å¿«é€Ÿç»„ä»¶æ£€æŸ¥ - 5åˆ†é’Ÿå†…åˆ¤æ–­æ˜¯VQ-VAEè¿˜æ˜¯Transformerçš„é—®é¢˜
"""

import torch
import torch.nn.functional as F
import numpy as np
from pathlib import Path
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def quick_vqvae_check(vqvae_path="models/vqvae_model", data_dir="data/processed"):
    """å¿«é€Ÿæ£€æŸ¥VQ-VAEè´¨é‡"""
    print("ğŸ” å¿«é€ŸVQ-VAEæ£€æŸ¥...")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    try:
        # 1. åŠ è½½VQ-VAE
        from diffusers import VQModel
        
        if Path(vqvae_path + "/config.json").exists():
            vqvae = VQModel.from_pretrained(vqvae_path)
        else:
            print("âŒ æœªæ‰¾åˆ°VQ-VAEæ¨¡å‹")
            return False
        
        vqvae.to(device)
        vqvae.eval()
        
        # 2. åŠ è½½æµ‹è¯•æ•°æ®
        from vqvae_transformer.utils.data_loader import MicroDopplerDataset
        from torch.utils.data import DataLoader

        # å°è¯•ä¸åŒçš„æ•°æ®åŠ è½½æ–¹å¼
        try:
            dataset = MicroDopplerDataset(data_dir=data_dir, split='test')
        except TypeError:
            try:
                dataset = MicroDopplerDataset(data_dir=data_dir)
            except Exception:
                dataset = MicroDopplerDataset(data_dir)

        dataloader = DataLoader(dataset, batch_size=4, shuffle=False, num_workers=0)
        test_batch = next(iter(dataloader))
        
        images = test_batch['image'].to(device)
        
        # 3. å¿«é€Ÿé‡å»ºæµ‹è¯•
        with torch.no_grad():
            encoded = vqvae.encode(images)
            latents = encoded.latents if hasattr(encoded, 'latents') else encoded
            
            quantized_output = vqvae.quantize(latents)
            quantized = quantized_output.quantized if hasattr(quantized_output, 'quantized') else quantized_output
            indices = quantized_output.indices if hasattr(quantized_output, 'indices') else None
            
            decoded = vqvae.decode(quantized)
            reconstructed = decoded.sample if hasattr(decoded, 'sample') else decoded
            
            # 4. å…³é”®æŒ‡æ ‡
            mse_loss = F.mse_loss(reconstructed, images).item()
            psnr = 20 * torch.log10(1.0 / torch.sqrt(torch.tensor(mse_loss))).item()
            
            if indices is not None:
                unique_tokens = len(torch.unique(indices))
                usage_ratio = unique_tokens / 1024
            else:
                usage_ratio = 0
            
            print(f"   MSEæŸå¤±: {mse_loss:.6f}")
            print(f"   PSNR: {psnr:.2f} dB")
            print(f"   ç æœ¬ä½¿ç”¨ç‡: {usage_ratio:.2%}")
            
            # 5. åˆ¤æ–­
            vqvae_issues = []
            if mse_loss > 0.1:
                vqvae_issues.append("é‡å»ºè¯¯å·®è¿‡é«˜")
            if psnr < 15:
                vqvae_issues.append("PSNRè¿‡ä½")
            if usage_ratio < 0.1:
                vqvae_issues.append("ç æœ¬ä½¿ç”¨ç‡è¿‡ä½")
            
            if vqvae_issues:
                print(f"   âŒ VQ-VAEé—®é¢˜: {', '.join(vqvae_issues)}")
                return False
            else:
                print("   âœ… VQ-VAEè´¨é‡è‰¯å¥½")
                return True
                
    except Exception as e:
        print(f"âŒ VQ-VAEæ£€æŸ¥å¤±è´¥: {e}")
        return False

def quick_transformer_check(transformer_path, vqvae_path="models/vqvae_model", data_dir="data/processed"):
    """å¿«é€Ÿæ£€æŸ¥Transformerè´¨é‡"""
    print("ğŸ” å¿«é€ŸTransformeræ£€æŸ¥...")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    try:
        # 1. åŠ è½½æ¨¡å‹
        from diffusers import VQModel
        from vqvae_transformer.models.transformer_model import MicroDopplerTransformer
        
        # VQ-VAE
        vqvae = VQModel.from_pretrained(vqvae_path)
        vqvae.to(device)
        vqvae.eval()
        
        # Transformer - ä¿®å¤PyTorch 2.6çš„weights_onlyé—®é¢˜
        checkpoint = torch.load(transformer_path, map_location=device, weights_only=False)
        transformer = MicroDopplerTransformer(
            vocab_size=1024,
            max_seq_len=1024,
            num_users=31,
            d_model=256,
            nhead=8,
            num_layers=6
        )
        transformer.load_state_dict(checkpoint['model_state_dict'])
        transformer.to(device)
        transformer.eval()
        
        # 2. åŠ è½½æµ‹è¯•æ•°æ®
        from vqvae_transformer.utils.data_loader import MicroDopplerDataset
        from torch.utils.data import DataLoader

        # å°è¯•ä¸åŒçš„æ•°æ®åŠ è½½æ–¹å¼
        try:
            dataset = MicroDopplerDataset(data_dir=data_dir, split='test')
        except TypeError:
            try:
                dataset = MicroDopplerDataset(data_dir=data_dir)
            except Exception:
                dataset = MicroDopplerDataset(data_dir)

        dataloader = DataLoader(dataset, batch_size=2, shuffle=False, num_workers=0)
        test_batch = next(iter(dataloader))
        
        images = test_batch['image'].to(device)
        user_ids = test_batch['user_id'].to(device)
        
        # 3. å¿«é€Ÿç”Ÿæˆæµ‹è¯•
        with torch.no_grad():
            # è·å–çœŸå®tokens
            encoded = vqvae.encode(images)
            latents = encoded.latents if hasattr(encoded, 'latents') else encoded
            quantized_output = vqvae.quantize(latents)
            real_tokens = quantized_output.indices.flatten(1) if hasattr(quantized_output, 'indices') else None
            
            if real_tokens is None:
                print("âŒ æ— æ³•è·å–çœŸå®tokens")
                return False
            
            # ç”Ÿæˆå°‘é‡tokensè¿›è¡Œæµ‹è¯•
            batch_size = user_ids.shape[0]
            generated = torch.zeros((batch_size, 1), dtype=torch.long, device=device)
            
            for i in range(50):  # åªç”Ÿæˆ50ä¸ªtokenè¿›è¡Œå¿«é€Ÿæµ‹è¯•
                outputs = transformer(input_ids=generated, user_ids=user_ids)
                next_token_logits = outputs.logits[:, -1, :]
                next_token = torch.multinomial(torch.softmax(next_token_logits, dim=-1), 1)
                generated = torch.cat([generated, next_token], dim=1)
            
            generated_tokens = generated[:, 1:]  # ç§»é™¤èµ·å§‹token
            
            # 4. å…³é”®æŒ‡æ ‡
            gen_unique = len(torch.unique(generated_tokens))
            gen_diversity = gen_unique / (batch_size * 50)
            
            # ç”¨æˆ·å·®å¼‚æµ‹è¯•
            if batch_size > 1:
                user_diff = (generated_tokens[0] != generated_tokens[1]).float().mean().item()
            else:
                user_diff = 0.5  # å‡è®¾æœ‰å·®å¼‚
            
            print(f"   ç”Ÿæˆtokenå”¯ä¸€å€¼: {gen_unique}")
            print(f"   ç”Ÿæˆå¤šæ ·æ€§: {gen_diversity:.2%}")
            print(f"   ç”¨æˆ·é—´å·®å¼‚: {user_diff:.2%}")
            
            # 5. åˆ¤æ–­
            transformer_issues = []
            if gen_diversity < 0.1:
                transformer_issues.append("ç”Ÿæˆå¤šæ ·æ€§ä¸è¶³")
            if user_diff < 0.05:
                transformer_issues.append("ç”¨æˆ·æ¡ä»¶æ— æ•ˆ")
            
            # æ£€æŸ¥æ˜¯å¦æ€»æ˜¯ç”Ÿæˆç›¸åŒtoken
            if gen_unique < 5:
                transformer_issues.append("æ¨¡å¼å´©æºƒ")
            
            if transformer_issues:
                print(f"   âŒ Transformeré—®é¢˜: {', '.join(transformer_issues)}")
                return False
            else:
                print("   âœ… Transformerè´¨é‡è‰¯å¥½")
                return True
                
    except Exception as e:
        print(f"âŒ Transformeræ£€æŸ¥å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ éµå¾ªæŒ‡å—ï¼šå¿«é€Ÿç»„ä»¶è¯Šæ–­")
    print("="*50)
    
    import argparse
    parser = argparse.ArgumentParser(description="å¿«é€Ÿç»„ä»¶æ£€æŸ¥")
    parser.add_argument("--vqvae_path", type=str, default="models/vqvae_model", help="VQ-VAEè·¯å¾„")
    parser.add_argument("--transformer_path", type=str, help="Transformerè·¯å¾„")
    parser.add_argument("--data_dir", type=str, default="data/processed", help="æ•°æ®ç›®å½•")
    
    args = parser.parse_args()
    
    # 1. æ£€æŸ¥VQ-VAE
    vqvae_ok = quick_vqvae_check(args.vqvae_path, args.data_dir)
    
    # 2. æ£€æŸ¥Transformerï¼ˆå¦‚æœæä¾›ï¼‰
    transformer_ok = True
    if args.transformer_path and Path(args.transformer_path).exists():
        transformer_ok = quick_transformer_check(args.transformer_path, args.vqvae_path, args.data_dir)
    elif args.transformer_path:
        print(f"âš ï¸ Transformeræ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.transformer_path}")
        transformer_ok = False
    
    # 3. è¯Šæ–­ç»“è®º
    print("\n" + "="*50)
    print("ğŸ¯ å¿«é€Ÿè¯Šæ–­ç»“è®º")
    print("="*50)
    
    if not vqvae_ok:
        print("âŒ é—®é¢˜æºå¤´ï¼šVQ-VAE")
        print("ğŸ”§ å»ºè®®è§£å†³æ–¹æ¡ˆï¼š")
        print("   1. é‡æ–°è®­ç»ƒVQ-VAEï¼Œå¢åŠ è®­ç»ƒè½®æ•°")
        print("   2. è°ƒæ•´VQ-VAEçš„å­¦ä¹ ç‡å’ŒæŸå¤±æƒé‡")
        print("   3. æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£ç¡®")
        print("   4. è€ƒè™‘ä½¿ç”¨æ›´å¤§çš„ç æœ¬æˆ–è°ƒæ•´é‡åŒ–å‚æ•°")
        
    elif not transformer_ok:
        print("âŒ é—®é¢˜æºå¤´ï¼šTransformer")
        print("ğŸ”§ å»ºè®®è§£å†³æ–¹æ¡ˆï¼š")
        print("   1. ä½¿ç”¨ train_improved.py é‡æ–°è®­ç»ƒ")
        print("   2. é™ä½å­¦ä¹ ç‡ï¼Œå¢åŠ æ­£åˆ™åŒ–")
        print("   3. æ·»åŠ ç©ºé—´ä¸€è‡´æ€§æŸå¤±")
        print("   4. ä½¿ç”¨æ›´ä¿å®ˆçš„ç”Ÿæˆç­–ç•¥")
        
    else:
        print("âœ… ä¸¤ä¸ªç»„ä»¶éƒ½æ­£å¸¸")
        print("ğŸ”§ å¯èƒ½çš„é—®é¢˜ï¼š")
        print("   1. è®­ç»ƒå‚æ•°è®¾ç½®ä¸å½“")
        print("   2. æ•°æ®è´¨é‡é—®é¢˜")
        print("   3. è®­ç»ƒæ—¶é—´ä¸è¶³")
        print("   4. ç”Ÿæˆå‚æ•°éœ€è¦è°ƒæ•´")
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼š")
    if not vqvae_ok:
        print("   ä¼˜å…ˆä¿®å¤VQ-VAEï¼Œç„¶åå†è®­ç»ƒTransformer")
    elif not transformer_ok:
        print("   VQ-VAEæ­£å¸¸ï¼Œä¸“æ³¨äºæ”¹è¿›Transformerè®­ç»ƒ")
    else:
        print("   ä¸¤ä¸ªç»„ä»¶éƒ½æ­£å¸¸ï¼Œæ£€æŸ¥æ•´ä½“è®­ç»ƒæµç¨‹")

if __name__ == "__main__":
    main()
