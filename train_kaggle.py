#!/usr/bin/env python3
"""
Kaggleç¯å¢ƒä¸“ç”¨è®­ç»ƒè„šæœ¬
ä¸€é”®è¿è¡ŒVAEå’Œæ‰©æ•£æ¨¡å‹è®­ç»ƒ
"""

import os
import sys
import subprocess
import time
from pathlib import Path
import argparse
import torch

# å¯¼å…¥é…ç½®
from kaggle_config import (
    setup_kaggle_environment, 
    get_kaggle_train_command,
    get_kaggle_generate_command,
    verify_kaggle_dataset,
    KAGGLE_CONFIG,
    OUTPUT_DIR
)

def check_gpu():
    """æ£€æŸ¥GPUçŠ¶æ€"""
    print("ğŸ” Checking GPU status...")
    
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        
        print(f"âœ… GPU available: {gpu_name}")
        print(f"   GPU count: {gpu_count}")
        print(f"   GPU memory: {gpu_memory:.1f} GB")
        
        return True
    else:
        print("âŒ No GPU available")
        return False

def run_command(command, description):
    """è¿è¡Œå‘½ä»¤å¹¶å¤„ç†è¾“å‡º"""
    print(f"\nğŸ”„ {description}...")

    # æ”¯æŒå­—ç¬¦ä¸²å’Œåˆ—è¡¨ä¸¤ç§æ ¼å¼
    if isinstance(command, list):
        cmd_parts = command
        print(f"Command: {' '.join(command)}")
    else:
        # å°†å‘½ä»¤åˆ†å‰²ä¸ºåˆ—è¡¨
        cmd_parts = command.replace(" \\\n", " ").split()
        print(f"Command: {command}")

    try:
        # è¿è¡Œå‘½ä»¤
        process = subprocess.Popen(
            cmd_parts,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )
        
        # å®æ—¶è¾“å‡º
        for line in process.stdout:
            print(line.rstrip())
        
        # ç­‰å¾…å®Œæˆ
        return_code = process.wait()
        
        if return_code == 0:
            print(f"âœ… {description} completed successfully")
            return True
        else:
            print(f"âŒ {description} failed with return code {return_code}")
            return False
            
    except Exception as e:
        print(f"âŒ {description} failed with error: {e}")
        return False

def train_vae(interactive=False):
    """è®­ç»ƒVAE"""
    print("\n" + "="*50)
    print("ğŸ¯ Starting VAE Training")
    print("="*50)

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰VAEæ¨¡å‹
    vae_model_path = Path(OUTPUT_DIR) / "vae" / "final_model"
    if vae_model_path.exists():
        if interactive:
            try:
                response = input("VAE model already exists. Continue training? (y/n): ")
                if response.lower() != 'y':
                    print("Skipping VAE training")
                    return True
            except (EOFError, KeyboardInterrupt):
                print("âš ï¸  No input detected, using existing model...")
                return True
        else:
            print("âš ï¸  VAE model already exists. Using existing model...")
            print("   (Use --interactive flag to enable retraining option)")
            return True
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¤šGPUï¼Œä½¿ç”¨ä¸“ç”¨å¯åŠ¨å™¨
    if torch.cuda.device_count() > 1:
        print("ğŸš€ æ£€æµ‹åˆ°å¤šGPUï¼Œä½¿ç”¨ä¸“ç”¨å¯åŠ¨å™¨")
        command = ["python", "launch_multi_gpu.py", "vae"]
        success = run_command(command, "VAE Training (Multi-GPU)")
    else:
        # å•GPUä½¿ç”¨åŸæ¥çš„æ–¹å¼
        command = get_kaggle_train_command("vae")
        success = run_command(command, "VAE Training")
    
    if success:
        print("ğŸ‰ VAE training completed!")
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        if vae_model_path.exists():
            print(f"âœ… VAE model saved at: {vae_model_path}")
        else:
            print("âš ï¸  VAE model not found at expected location")
            return False
    
    return success

def train_diffusion(interactive=False):
    """è®­ç»ƒæ‰©æ•£æ¨¡å‹"""
    print("\n" + "="*50)
    print("ğŸ¯ Starting Diffusion Training")
    print("="*50)

    # æ£€æŸ¥VAEæ¨¡å‹æ˜¯å¦å­˜åœ¨
    vae_model_path = Path(OUTPUT_DIR) / "vae" / "final_model"
    if not vae_model_path.exists():
        print("âŒ VAE model not found. Please train VAE first.")
        return False

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ‰©æ•£æ¨¡å‹
    diffusion_model_path = Path(OUTPUT_DIR) / "diffusion" / "final_model"
    if diffusion_model_path.exists():
        if interactive:
            try:
                response = input("Diffusion model already exists. Continue training? (y/n): ")
                if response.lower() != 'y':
                    print("Skipping diffusion training")
                    return True
            except (EOFError, KeyboardInterrupt):
                print("âš ï¸  No input detected, using existing model...")
                return True
        else:
            print("âš ï¸  Diffusion model already exists. Using existing model...")
            print("   (Use --interactive flag to enable retraining option)")
            return True
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¤šGPUï¼Œä½¿ç”¨ä¸“ç”¨å¯åŠ¨å™¨
    if torch.cuda.device_count() > 1:
        print("ğŸš€ æ£€æµ‹åˆ°å¤šGPUï¼Œä½¿ç”¨ä¸“ç”¨å¯åŠ¨å™¨")
        command = ["python", "launch_multi_gpu.py", "diffusion"]
        success = run_command(command, "Diffusion Training (Multi-GPU)")
    else:
        # å•GPUä½¿ç”¨åŸæ¥çš„æ–¹å¼
        command = get_kaggle_train_command("diffusion")
        success = run_command(command, "Diffusion Training")
    
    if success:
        print("ğŸ‰ Diffusion training completed!")
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        unet_path = diffusion_model_path / "unet"
        encoder_path = diffusion_model_path / "condition_encoder.pt"
        
        if unet_path.exists() and encoder_path.exists():
            print(f"âœ… Diffusion model saved at: {diffusion_model_path}")
        else:
            print("âš ï¸  Diffusion model files not found at expected location")
            return False
    
    return success

def generate_samples():
    """ç”Ÿæˆæ ·æœ¬å›¾åƒ"""
    print("\n" + "="*50)
    print("ğŸ¯ Generating Sample Images")
    print("="*50)
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    vae_model_path = Path(OUTPUT_DIR) / "vae" / "final_model"
    diffusion_model_path = Path(OUTPUT_DIR) / "diffusion" / "final_model"
    
    if not vae_model_path.exists():
        print("âŒ VAE model not found")
        return False
    
    if not diffusion_model_path.exists():
        print("âŒ Diffusion model not found")
        return False
    
    # è·å–ç”Ÿæˆå‘½ä»¤
    command = get_kaggle_generate_command()
    
    # è¿è¡Œç”Ÿæˆ
    success = run_command(command, "Image Generation")
    
    if success:
        print("ğŸ‰ Image generation completed!")
        
        # æ£€æŸ¥ç”Ÿæˆçš„å›¾åƒ
        output_path = Path(OUTPUT_DIR) / "generated_images"
        if output_path.exists():
            image_count = len(list(output_path.rglob("*.png")))
            print(f"âœ… Generated {image_count} images at: {output_path}")
        else:
            print("âš ï¸  Generated images not found")
            return False
    
    return success

def estimate_training_time():
    """ä¼°ç®—è®­ç»ƒæ—¶é—´"""
    vae_config = KAGGLE_CONFIG["vae"]
    diffusion_config = KAGGLE_CONFIG["diffusion"]
    
    # ç²—ç•¥ä¼°ç®— (åŸºäºç»éªŒå€¼)
    vae_time = vae_config["num_epochs"] * 2  # æ¯ä¸ªepochçº¦2åˆ†é’Ÿ
    diffusion_time = diffusion_config["num_epochs"] * 3  # æ¯ä¸ªepochçº¦3åˆ†é’Ÿ
    
    total_time = vae_time + diffusion_time
    
    print(f"â±ï¸  Estimated training time:")
    print(f"   VAE: ~{vae_time//60}h {vae_time%60}m")
    print(f"   Diffusion: ~{diffusion_time//60}h {diffusion_time%60}m")
    print(f"   Total: ~{total_time//60}h {total_time%60}m")
    
    if total_time > 1800:  # 30å°æ—¶
        print("âš ï¸  Warning: Estimated time exceeds Kaggle GPU limit (30h/week)")
        print("   Consider reducing epochs or using checkpoints")

def main():
    parser = argparse.ArgumentParser(description="Kaggle Training Pipeline")
    parser.add_argument("--stage", type=str, choices=[
        "setup", "vae", "diffusion", "generate", "all"
    ], default="all", help="Training stage to run")
    parser.add_argument("--skip_setup", action="store_true", help="Skip environment setup")
    parser.add_argument("--interactive", action="store_true", help="Enable interactive mode (ask for confirmation)")
    
    args = parser.parse_args()
    
    print("ğŸš€ Kaggle Micro-Doppler Training Pipeline")
    print("=" * 50)
    
    # ç¯å¢ƒè®¾ç½®
    if not args.skip_setup:
        print("ğŸ”§ Setting up environment...")
        try:
            env_info = setup_kaggle_environment()
            print("âœ… Environment setup completed")
        except Exception as e:
            print(f"âŒ Environment setup failed: {e}")
            return
        
        # éªŒè¯æ•°æ®é›†
        if not verify_kaggle_dataset():
            print("âŒ Dataset verification failed")
            return
    
    # æ£€æŸ¥GPU
    if not check_gpu():
        print("âŒ GPU not available. Cannot proceed with training.")
        return
    
    # ä¼°ç®—è®­ç»ƒæ—¶é—´
    if args.stage in ["all", "vae", "diffusion"]:
        estimate_training_time()

        # æ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦éœ€è¦ç¡®è®¤
        if args.interactive:
            try:
                response = input("\nProceed with training? (y/n): ")
                if response.lower() != 'y':
                    print("Training cancelled")
                    return
            except (EOFError, KeyboardInterrupt):
                print("\nğŸš€ No input detected, starting training automatically...")
        else:
            print("\nğŸš€ Starting training automatically...")
            print("   (Use --interactive flag to enable confirmation prompts)")
            import time
            time.sleep(2)
    
    # æ‰§è¡ŒæŒ‡å®šé˜¶æ®µ
    success = True
    
    if args.stage == "setup":
        print("âœ… Setup completed")
        
    elif args.stage == "vae":
        success = train_vae(interactive=args.interactive)

    elif args.stage == "diffusion":
        success = train_diffusion(interactive=args.interactive)

    elif args.stage == "generate":
        success = generate_samples()

    elif args.stage == "all":
        # å®Œæ•´æµç¨‹
        print("\nğŸ¯ Running complete training pipeline...")

        # VAEè®­ç»ƒ
        if not train_vae(interactive=args.interactive):
            print("âŒ VAE training failed")
            return

        # æ‰©æ•£è®­ç»ƒ
        if not train_diffusion(interactive=args.interactive):
            print("âŒ Diffusion training failed")
            return

        # ç”Ÿæˆæ ·æœ¬
        if not generate_samples():
            print("âŒ Sample generation failed")
            return

        print("\nğŸ‰ Complete pipeline finished successfully!")
    
    if success:
        print(f"\nâœ… Stage '{args.stage}' completed successfully!")
    else:
        print(f"\nâŒ Stage '{args.stage}' failed!")

if __name__ == "__main__":
    main()
