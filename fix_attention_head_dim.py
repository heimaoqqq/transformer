#!/usr/bin/env python3
"""
ä¿®å¤attention_head_dimé—®é¢˜
æ£€æŸ¥å¹¶ä¿®å¤UNetçš„æ³¨æ„åŠ›å¤´ç»´åº¦é…ç½®
"""

import torch
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

def analyze_attention_problem():
    """åˆ†ææ³¨æ„åŠ›ç»´åº¦é—®é¢˜"""
    print("ğŸ” åˆ†ææ³¨æ„åŠ›ç»´åº¦é—®é¢˜...")
    
    unet_path = "/kaggle/input/diffusion-final-model"
    
    try:
        from diffusers import UNet2DConditionModel
        
        # åŠ è½½UNet
        unet = UNet2DConditionModel.from_pretrained(unet_path)
        config = unet.config
        
        print(f"ğŸ“‹ å½“å‰UNeté…ç½®:")
        print(f"  - cross_attention_dim: {config.cross_attention_dim}")
        print(f"  - attention_head_dim: {config.attention_head_dim}")
        print(f"  - block_out_channels: {config.block_out_channels}")
        
        # åˆ†æé—®é¢˜
        cross_dim = config.cross_attention_dim
        head_dim = config.attention_head_dim
        
        print(f"\nğŸ” ç»´åº¦åˆ†æ:")
        
        if isinstance(head_dim, (list, tuple)):
            print(f"  attention_head_dimæ˜¯åˆ—è¡¨: {head_dim}")
            for i, hd in enumerate(head_dim):
                if cross_dim % hd != 0:
                    print(f"  âŒ å±‚{i}: cross_attention_dim ({cross_dim}) ä¸èƒ½è¢« attention_head_dim ({hd}) æ•´é™¤")
                else:
                    num_heads = cross_dim // hd
                    print(f"  âœ… å±‚{i}: {num_heads} ä¸ªæ³¨æ„åŠ›å¤´")
        else:
            print(f"  attention_head_dimæ˜¯æ ‡é‡: {head_dim}")
            if cross_dim % head_dim != 0:
                print(f"  âŒ cross_attention_dim ({cross_dim}) ä¸èƒ½è¢« attention_head_dim ({head_dim}) æ•´é™¤")
                
                # å»ºè®®ä¿®å¤æ–¹æ¡ˆ
                print(f"\nğŸ’¡ å»ºè®®çš„attention_head_dimå€¼:")
                for candidate in [8, 16, 32, 64]:
                    if cross_dim % candidate == 0:
                        num_heads = cross_dim // candidate
                        print(f"    - {candidate} (å¾—åˆ° {num_heads} ä¸ªæ³¨æ„åŠ›å¤´)")
            else:
                num_heads = cross_dim // head_dim
                print(f"  âœ… {num_heads} ä¸ªæ³¨æ„åŠ›å¤´")
        
        # æ£€æŸ¥block_out_channelsçš„æœ€åä¸€ä¸ªå€¼
        if hasattr(config, 'block_out_channels'):
            last_channel = config.block_out_channels[-1]
            print(f"\nğŸ” æ£€æŸ¥block_out_channels:")
            print(f"  - æœ€åä¸€å±‚é€šé“æ•°: {last_channel}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰1024çš„é€šé“æ•°
            if 1024 in config.block_out_channels:
                print(f"  âš ï¸  å‘ç°1024é€šé“æ•°åœ¨block_out_channelsä¸­!")
                print(f"  è¿™å¯èƒ½æ˜¯é—®é¢˜çš„æ ¹æº")
        
        return config
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return None

def suggest_fix():
    """å»ºè®®ä¿®å¤æ–¹æ¡ˆ"""
    print(f"\nğŸ”§ ä¿®å¤å»ºè®®:")
    
    print(f"åŸºäºé”™è¯¯ä¿¡æ¯ 'tensor a (512) vs tensor b (1024)'ï¼Œå¯èƒ½çš„åŸå› :")
    print(f"1. UNetå†…éƒ¨æŸå±‚æœŸæœ›1024ç»´è¾“å…¥ï¼Œä½†æ”¶åˆ°512ç»´")
    print(f"2. attention_head_dimé…ç½®ä¸æ­£ç¡®")
    print(f"3. UNetçš„æŸä¸ªæŠ•å½±å±‚æœ‰ç¡¬ç¼–ç çš„1024ç»´åº¦")
    
    print(f"\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
    print(f"æ–¹æ¡ˆ1: ä¿®æ”¹æ¨ç†ä»£ç ï¼Œå¼ºåˆ¶ä½¿ç”¨1024ç»´æ¡ä»¶ç¼–ç å™¨")
    print(f"æ–¹æ¡ˆ2: æ£€æŸ¥UNetè®­ç»ƒæ—¶çš„å®é™…é…ç½®")
    print(f"æ–¹æ¡ˆ3: é‡æ–°åˆ›å»ºUNetä½¿ç”¨æ­£ç¡®çš„é…ç½®")
    
    print(f"\nğŸš€ å¿«é€Ÿä¿®å¤ä»£ç :")
    print(f"```python")
    print(f"# åœ¨inference/generate.pyä¸­ï¼Œå¼ºåˆ¶ä½¿ç”¨1024ç»´")
    print(f"self.condition_encoder = UserConditionEncoder(")
    print(f"    num_users=num_users,")
    print(f"    embed_dim=1024  # å¼ºåˆ¶ä½¿ç”¨1024ç»´")
    print(f")")
    print(f"```")

def create_test_with_1024():
    """æµ‹è¯•ä½¿ç”¨1024ç»´çš„æ¡ä»¶ç¼–ç å™¨"""
    print(f"\nğŸ§ª æµ‹è¯•1024ç»´æ¡ä»¶ç¼–ç å™¨...")
    
    try:
        from training.train_diffusion import UserConditionEncoder
        
        # åˆ›å»º1024ç»´çš„æ¡ä»¶ç¼–ç å™¨
        condition_encoder_1024 = UserConditionEncoder(
            num_users=31,
            embed_dim=1024
        )
        
        print(f"âœ… æˆåŠŸåˆ›å»º1024ç»´æ¡ä»¶ç¼–ç å™¨")
        
        # æµ‹è¯•ç¼–ç 
        with torch.no_grad():
            user_tensor = torch.tensor([0])
            encoder_hidden_states = condition_encoder_1024(user_tensor)
            print(f"  è¾“å‡ºå½¢çŠ¶: {encoder_hidden_states.shape}")
            
            if encoder_hidden_states.shape[-1] == 1024:
                print(f"  âœ… è¾“å‡ºç»´åº¦æ­£ç¡®: 1024")
                return True
            else:
                print(f"  âŒ è¾“å‡ºç»´åº¦é”™è¯¯: {encoder_hidden_states.shape[-1]}")
                return False
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ æ³¨æ„åŠ›å¤´ç»´åº¦ä¿®å¤å·¥å…·")
    print("=" * 50)
    
    # åˆ†æé—®é¢˜
    config = analyze_attention_problem()
    
    # å»ºè®®ä¿®å¤æ–¹æ¡ˆ
    suggest_fix()
    
    # æµ‹è¯•1024ç»´æ–¹æ¡ˆ
    test_1024_ok = create_test_with_1024()
    
    print("\n" + "=" * 50)
    print("ğŸ¯ æ€»ç»“:")
    
    if config:
        cross_dim = config.cross_attention_dim
        head_dim = config.attention_head_dim
        
        if isinstance(head_dim, int) and cross_dim % head_dim != 0:
            print("âŒ å‘ç°attention_head_dimé…ç½®é—®é¢˜")
            print(f"   cross_attention_dim ({cross_dim}) ä¸èƒ½è¢« attention_head_dim ({head_dim}) æ•´é™¤")
        else:
            print("âœ… attention_head_dimé…ç½®çœ‹èµ·æ¥æ­£å¸¸")
    
    if test_1024_ok:
        print("âœ… 1024ç»´æ¡ä»¶ç¼–ç å™¨æµ‹è¯•æˆåŠŸ")
        print("   å»ºè®®å°è¯•åœ¨æ¨ç†ä»£ç ä¸­ä½¿ç”¨1024ç»´")
    else:
        print("âŒ 1024ç»´æ¡ä»¶ç¼–ç å™¨æµ‹è¯•å¤±è´¥")
    
    print(f"\nğŸš€ ä¸‹ä¸€æ­¥:")
    print(f"1. å°è¯•ä¿®æ”¹æ¨ç†ä»£ç ä½¿ç”¨1024ç»´æ¡ä»¶ç¼–ç å™¨")
    print(f"2. æˆ–è€…æ£€æŸ¥UNetè®­ç»ƒæ—¶çš„å®é™…é…ç½®")
    print(f"3. è¿è¡Œ debug_unet_internal.py è·å–æ›´è¯¦ç»†ä¿¡æ¯")

if __name__ == "__main__":
    main()
