#!/usr/bin/env python3
"""
Kaggleç¯å¢ƒä¸“ç”¨é…ç½®æ–‡ä»¶
é’ˆå¯¹æ‚¨çš„æ•°æ®é›†ç»“æ„è¿›è¡Œä¼˜åŒ–
"""

import os
from pathlib import Path

# æ•°æ®é›†é…ç½®
KAGGLE_DATA_DIR = "/kaggle/input/dataset"
OUTPUT_DIR = "/kaggle/working/outputs"
TEMP_DIR = "/kaggle/working/temp"

# æ•°æ®é›†ä¿¡æ¯
NUM_USERS = 31
USER_IDS = list(range(1, 32))  # 1åˆ°31
IMAGE_SIZE = 256

# è®­ç»ƒé…ç½® (é’ˆå¯¹Kaggleç¯å¢ƒä¼˜åŒ–)
KAGGLE_CONFIG = {
    # VAEè®­ç»ƒé…ç½® (å†…å­˜ä¼˜åŒ–)
    "vae": {
        "batch_size": 4,  # å‡å°æ‰¹æ¬¡å¤§å°é¿å…OOM
        "num_epochs": 30,  # å‡å°‘epochæ•°ä»¥é€‚åº”æ—¶é—´é™åˆ¶
        "learning_rate": 1e-4,
        "mixed_precision": "fp16",
        "gradient_accumulation_steps": 4,  # å¢åŠ æ¢¯åº¦ç´¯ç§¯ä¿æŒæœ‰æ•ˆæ‰¹æ¬¡å¤§å°
        "kl_weight": 1e-6,
        "perceptual_weight": 0.0,  # ç¦ç”¨æ„ŸçŸ¥æŸå¤±èŠ‚çœå†…å­˜
        "freq_weight": 0.05,
        "resolution": 128,  # é™ä½åˆ†è¾¨ç‡èŠ‚çœå†…å­˜
        "num_workers": 1,  # å‡å°‘workeræ•°
        "save_interval": 10,
        "log_interval": 5,
        "sample_interval": 200,  # å‡å°‘é‡‡æ ·é¢‘ç‡
    },
    
    # æ‰©æ•£è®­ç»ƒé…ç½®
    "diffusion": {
        "batch_size": 4,  # æ›´å°çš„æ‰¹æ¬¡å¤§å°
        "num_epochs": 100,
        "learning_rate": 1e-4,
        "mixed_precision": "fp16",
        "gradient_accumulation_steps": 4,
        "cross_attention_dim": 768,
        "num_train_timesteps": 1000,
        "condition_dropout": 0.1,
        "save_interval": 20,
        "log_interval": 10,
        "sample_interval": 200,
        "val_interval": 10,
    },
    
    # æ•°æ®é…ç½®
    "data": {
        "resolution": 256,
        "val_split": 0.2,
        "test_split": 0.1,
        "num_workers": 2,  # Kaggleç¯å¢ƒé™åˆ¶
        "use_augmentation": False,  # å¾®å¤šæ™®å‹’å¯¹ä¼ ç»Ÿå¢å¼ºæ•æ„Ÿï¼Œé»˜è®¤å…³é—­
    },
    
    # ç”Ÿæˆé…ç½®
    "generation": {
        "num_inference_steps": 50,
        "guidance_scale": 7.5,
        "scheduler_type": "ddim",
        "num_images_per_user": 5,
    }
}

def setup_kaggle_environment():
    """è®¾ç½®Kaggleç¯å¢ƒ"""
    print("ğŸ”§ Setting up Kaggle environment...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(TEMP_DIR, exist_ok=True)
    
    # æ£€æŸ¥æ•°æ®é›†
    data_path = Path(KAGGLE_DATA_DIR)
    if not data_path.exists():
        raise FileNotFoundError(f"Dataset not found at {KAGGLE_DATA_DIR}")
    
    # éªŒè¯ç”¨æˆ·ç›®å½•
    missing_users = []
    for user_id in range(1, NUM_USERS + 1):
        user_dir = data_path / f"ID_{user_id}"
        if not user_dir.exists():
            missing_users.append(user_id)
    
    if missing_users:
        print(f"âš ï¸  Warning: Missing user directories: {missing_users}")
    else:
        print(f"âœ… All {NUM_USERS} user directories found")
    
    # ç»Ÿè®¡å›¾åƒæ•°é‡
    total_images = 0
    user_image_counts = {}
    
    for user_id in range(1, NUM_USERS + 1):
        user_dir = data_path / f"ID_{user_id}"
        if user_dir.exists():
            images = list(user_dir.glob("*.png")) + list(user_dir.glob("*.jpg")) + list(user_dir.glob("*.jpeg"))
            user_image_counts[user_id] = len(images)
            total_images += len(images)
    
    print(f"ğŸ“Š Dataset statistics:")
    print(f"   Total images: {total_images}")
    print(f"   Average per user: {total_images / NUM_USERS:.1f}")
    print(f"   Min per user: {min(user_image_counts.values())}")
    print(f"   Max per user: {max(user_image_counts.values())}")
    
    return {
        "data_dir": KAGGLE_DATA_DIR,
        "output_dir": OUTPUT_DIR,
        "temp_dir": TEMP_DIR,
        "total_images": total_images,
        "user_image_counts": user_image_counts
    }

def get_kaggle_train_command(stage="vae"):
    """ç”ŸæˆKaggleè®­ç»ƒå‘½ä»¤"""
    if stage == "vae":
        config = KAGGLE_CONFIG["vae"]
        data_config = KAGGLE_CONFIG["data"]
        
        cmd = f"""python training/train_vae.py \\
    --data_dir {KAGGLE_DATA_DIR} \\
    --output_dir {OUTPUT_DIR}/vae \\
    --batch_size {config['batch_size']} \\
    --num_epochs {config['num_epochs']} \\
    --learning_rate {config['learning_rate']} \\
    --mixed_precision {config['mixed_precision']} \\
    --gradient_accumulation_steps {config['gradient_accumulation_steps']} \\
    --kl_weight {config['kl_weight']} \\
    --perceptual_weight {config['perceptual_weight']} \\
    --freq_weight {config['freq_weight']} \\
    --resolution {config['resolution']} \\
    --num_workers {config['num_workers']} \\
    --save_interval {config['save_interval']} \\
    --log_interval {config['log_interval']} \\
    --sample_interval {config['sample_interval']} \\
    --experiment_name kaggle_vae"""
        
        if data_config['use_augmentation']:
            cmd += " \\\n    --use_augmentation"
            
    elif stage == "diffusion":
        config = KAGGLE_CONFIG["diffusion"]
        data_config = KAGGLE_CONFIG["data"]
        
        cmd = f"""python training/train_diffusion.py \\
    --data_dir {KAGGLE_DATA_DIR} \\
    --vae_path {OUTPUT_DIR}/vae/final_model \\
    --output_dir {OUTPUT_DIR}/diffusion \\
    --batch_size {config['batch_size']} \\
    --num_epochs {config['num_epochs']} \\
    --learning_rate {config['learning_rate']} \\
    --mixed_precision {config['mixed_precision']} \\
    --gradient_accumulation_steps {config['gradient_accumulation_steps']} \\
    --cross_attention_dim {config['cross_attention_dim']} \\
    --num_train_timesteps {config['num_train_timesteps']} \\
    --condition_dropout {config['condition_dropout']} \\
    --resolution {data_config['resolution']} \\
    --val_split {data_config['val_split']} \\
    --num_workers {data_config['num_workers']} \\
    --save_interval {config['save_interval']} \\
    --log_interval {config['log_interval']} \\
    --sample_interval {config['sample_interval']} \\
    --val_interval {config['val_interval']} \\
    --experiment_name kaggle_diffusion"""
    
    return cmd

def get_kaggle_generate_command():
    """ç”ŸæˆKaggleæ¨ç†å‘½ä»¤"""
    config = KAGGLE_CONFIG["generation"]
    
    cmd = f"""python inference/generate.py \\
    --vae_path {OUTPUT_DIR}/vae/final_model \\
    --unet_path {OUTPUT_DIR}/diffusion/final_model/unet \\
    --condition_encoder_path {OUTPUT_DIR}/diffusion/final_model/condition_encoder.pt \\
    --num_users {NUM_USERS} \\
    --user_ids 1 5 10 15 20 25 31 \\
    --num_images_per_user {config['num_images_per_user']} \\
    --num_inference_steps {config['num_inference_steps']} \\
    --guidance_scale {config['guidance_scale']} \\
    --scheduler_type {config['scheduler_type']} \\
    --output_dir {OUTPUT_DIR}/generated_images"""
    
    return cmd

def print_kaggle_instructions():
    """æ‰“å°Kaggleä½¿ç”¨è¯´æ˜"""
    print("ğŸš€ Kaggleç¯å¢ƒä½¿ç”¨è¯´æ˜")
    print("=" * 50)
    
    print("\n1. ç¯å¢ƒè®¾ç½®:")
    print("   python kaggle_config.py")
    
    print("\n2. VAEè®­ç»ƒ:")
    print(get_kaggle_train_command("vae"))
    
    print("\n3. æ‰©æ•£è®­ç»ƒ:")
    print(get_kaggle_train_command("diffusion"))
    
    print("\n4. ç”Ÿæˆå›¾åƒ:")
    print(get_kaggle_generate_command())
    
    print("\nğŸ“‹ æ³¨æ„äº‹é¡¹:")
    print("- Kaggle GPUæ—¶é—´é™åˆ¶: 30å°æ—¶/å‘¨")
    print("- å»ºè®®åˆ†é˜¶æ®µè®­ç»ƒï¼Œä¿å­˜æ£€æŸ¥ç‚¹")
    print("- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒèŠ‚çœå†…å­˜")
    print("- ç›‘æ§è®­ç»ƒè¿›åº¦ï¼ŒåŠæ—¶è°ƒæ•´å‚æ•°")

def verify_kaggle_dataset():
    """éªŒè¯Kaggleæ•°æ®é›†"""
    print("ğŸ” Verifying Kaggle dataset...")
    
    try:
        from utils.data_loader import MicroDopplerDataset
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = MicroDopplerDataset(
            data_dir=KAGGLE_DATA_DIR,
            resolution=256,
            augment=False
        )
        
        print(f"âœ… Dataset loaded successfully")
        print(f"   Total samples: {len(dataset)}")
        print(f"   Number of users: {dataset.num_users}")
        print(f"   User mapping: {dataset.user_to_idx}")
        
        # æµ‹è¯•åŠ è½½ä¸€ä¸ªæ ·æœ¬
        sample = dataset[0]
        print(f"   Sample image shape: {sample['image'].shape}")
        print(f"   Sample user ID: {sample['user_id']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Dataset verification failed: {e}")
        return False

if __name__ == "__main__":
    # è®¾ç½®ç¯å¢ƒ
    env_info = setup_kaggle_environment()
    
    # éªŒè¯æ•°æ®é›†
    if verify_kaggle_dataset():
        print("\nğŸ‰ Kaggle environment ready!")
        print_kaggle_instructions()
    else:
        print("\nâŒ Please check your dataset structure")
