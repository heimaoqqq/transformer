#!/usr/bin/env python3
"""
æ¨ç†è®¾ç½®éªŒè¯è„šæœ¬
æ£€æŸ¥æ¨ç†æ‰€éœ€çš„æ‰€æœ‰æ–‡ä»¶å’Œé…ç½®æ˜¯å¦æ­£ç¡®
"""

import os
import torch
from pathlib import Path
import json

def check_file_exists(path, description):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    if Path(path).exists():
        size = Path(path).stat().st_size / (1024**2) if Path(path).is_file() else 0
        print(f"  âœ… {description}: {path} ({size:.1f} MB)")
        return True
    else:
        print(f"  âŒ {description}: {path} - æ–‡ä»¶ä¸å­˜åœ¨!")
        return False

def check_directory_contents(path, description):
    """æ£€æŸ¥ç›®å½•å†…å®¹"""
    if Path(path).exists() and Path(path).is_dir():
        files = list(Path(path).iterdir())
        total_size = sum(f.stat().st_size for f in files if f.is_file()) / (1024**2)
        print(f"  âœ… {description}: {path} ({len(files)} æ–‡ä»¶, {total_size:.1f} MB)")
        for file in files:
            print(f"    - {file.name}")
        return True
    else:
        print(f"  âŒ {description}: {path} - ç›®å½•ä¸å­˜åœ¨!")
        return False

def validate_model_configs():
    """éªŒè¯æ¨¡å‹é…ç½®æ–‡ä»¶"""
    print("\nğŸ” éªŒè¯æ¨¡å‹é…ç½®...")
    
    # æ£€æŸ¥VAEé…ç½®
    vae_config_path = "/kaggle/input/final-model/config.json"
    if Path(vae_config_path).exists():
        try:
            with open(vae_config_path, 'r') as f:
                vae_config = json.load(f)
            print(f"  âœ… VAEé…ç½®: {vae_config.get('_class_name', 'Unknown')}")
            print(f"    - è¾“å…¥é€šé“: {vae_config.get('in_channels', 'Unknown')}")
            print(f"    - æ½œåœ¨é€šé“: {vae_config.get('latent_channels', 'Unknown')}")
        except Exception as e:
            print(f"  âš ï¸ VAEé…ç½®è¯»å–å¤±è´¥: {e}")
    
    # æ£€æŸ¥UNeté…ç½®
    unet_config_path = "/kaggle/working/outputs/diffusion/final_model/unet/config.json"
    if Path(unet_config_path).exists():
        try:
            with open(unet_config_path, 'r') as f:
                unet_config = json.load(f)
            print(f"  âœ… UNeté…ç½®: {unet_config.get('_class_name', 'Unknown')}")
            print(f"    - è¾“å…¥é€šé“: {unet_config.get('in_channels', 'Unknown')}")
            print(f"    - äº¤å‰æ³¨æ„åŠ›ç»´åº¦: {unet_config.get('cross_attention_dim', 'Unknown')}")
            print(f"    - Blockè¾“å‡ºé€šé“: {unet_config.get('block_out_channels', 'Unknown')}")
        except Exception as e:
            print(f"  âš ï¸ UNeté…ç½®è¯»å–å¤±è´¥: {e}")

def check_inference_requirements():
    """æ£€æŸ¥æ¨ç†æ‰€éœ€çš„æ‰€æœ‰æ–‡ä»¶"""
    print("ğŸ” æ£€æŸ¥æ¨ç†æ‰€éœ€æ–‡ä»¶...\n")
    
    all_good = True
    
    # 1. VAEæ¨¡å‹
    print("1ï¸âƒ£ VAEæ¨¡å‹æ–‡ä»¶:")
    vae_base = "/kaggle/input/final-model"
    vae_files = [
        ("config.json", "VAEé…ç½®æ–‡ä»¶"),
        ("diffusion_pytorch_model.safetensors", "VAEæƒé‡æ–‡ä»¶(ä¸»)"),
        ("diffusion_pytorch_model.bin", "VAEæƒé‡æ–‡ä»¶(å¤‡ç”¨)")
    ]
    
    for file, desc in vae_files:
        path = f"{vae_base}/{file}"
        if not check_file_exists(path, desc):
            if file != "diffusion_pytorch_model.bin":  # binæ–‡ä»¶æ˜¯å¯é€‰çš„
                all_good = False
    
    # 2. UNetæ¨¡å‹
    print("\n2ï¸âƒ£ UNetæ¨¡å‹æ–‡ä»¶:")
    unet_base = "/kaggle/working/outputs/diffusion/final_model/unet"
    unet_files = [
        ("config.json", "UNeté…ç½®æ–‡ä»¶"),
        ("diffusion_pytorch_model.safetensors", "UNetæƒé‡æ–‡ä»¶(ä¸»)"),
        ("diffusion_pytorch_model.bin", "UNetæƒé‡æ–‡ä»¶(å¤‡ç”¨)")
    ]
    
    for file, desc in unet_files:
        path = f"{unet_base}/{file}"
        if not check_file_exists(path, desc):
            if file != "diffusion_pytorch_model.bin":  # binæ–‡ä»¶æ˜¯å¯é€‰çš„
                all_good = False
    
    # 3. æ¡ä»¶ç¼–ç å™¨
    print("\n3ï¸âƒ£ æ¡ä»¶ç¼–ç å™¨:")
    condition_path = "/kaggle/working/outputs/diffusion/final_model/condition_encoder.pt"
    if not check_file_exists(condition_path, "æ¡ä»¶ç¼–ç å™¨æƒé‡"):
        all_good = False
    
    # 4. æ£€æŸ¥é‡‡æ ·å›¾åƒ (å¯é€‰ï¼Œç”¨äºéªŒè¯è®­ç»ƒæ•ˆæœ)
    print("\n4ï¸âƒ£ è®­ç»ƒé‡‡æ ·å›¾åƒ (å¯é€‰):")
    samples_dir = "/kaggle/working/outputs/diffusion/samples"
    check_directory_contents(samples_dir, "è®­ç»ƒé‡‡æ ·å›¾åƒ")
    
    return all_good

def generate_inference_command():
    """ç”Ÿæˆæ¨ç†å‘½ä»¤ç¤ºä¾‹"""
    print("\nğŸš€ æ¨ç†å‘½ä»¤ç¤ºä¾‹:")
    print("```bash")
    print("python inference/generate.py \\")
    print("    --vae_path \"/kaggle/input/final-model\" \\")
    print("    --unet_path \"/kaggle/working/outputs/diffusion/final_model/unet\" \\")
    print("    --condition_encoder_path \"/kaggle/working/outputs/diffusion/final_model/condition_encoder.pt\" \\")
    print("    --num_users 31 \\")
    print("    --user_ids 1 5 10 15 \\")
    print("    --num_images_per_user 3 \\")
    print("    --num_inference_steps 50 \\")
    print("    --guidance_scale 7.5 \\")
    print("    --output_dir \"/kaggle/working/generated_images\"")
    print("```")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª æ¨ç†è®¾ç½®éªŒè¯\n")
    print("=" * 50)
    
    # æ£€æŸ¥åŸºæœ¬ç¯å¢ƒ
    print(f"ğŸ–¥ï¸  è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
    if torch.cuda.is_available():
        print(f"    GPU: {torch.cuda.get_device_name()}")
        print(f"    å†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # æ£€æŸ¥æ–‡ä»¶
    all_files_ready = check_inference_requirements()
    
    # éªŒè¯é…ç½®
    validate_model_configs()
    
    # ç”Ÿæˆå‘½ä»¤
    generate_inference_command()
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    if all_files_ready:
        print("ğŸ‰ æ‰€æœ‰æ¨ç†æ–‡ä»¶å‡†å¤‡å°±ç»ª!")
        print("âœ… å¯ä»¥å¼€å§‹æ¨ç†ç”Ÿæˆå›¾åƒ")
    else:
        print("âš ï¸ éƒ¨åˆ†æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥è®­ç»ƒæ˜¯å¦å®Œæˆ")
        print("âŒ æ¨ç†å¯èƒ½æ— æ³•æ­£å¸¸è¿è¡Œ")
    
    print("\nğŸ“‹ æ¨ç†æ–‡ä»¶æ¸…å•:")
    print("  1. VAEæ¨¡å‹: /kaggle/input/final-model/")
    print("  2. UNetæ¨¡å‹: /kaggle/working/outputs/diffusion/final_model/unet/")
    print("  3. æ¡ä»¶ç¼–ç å™¨: /kaggle/working/outputs/diffusion/final_model/condition_encoder.pt")

if __name__ == "__main__":
    main()
