#!/usr/bin/env python3
"""
éªŒè¯å½“å‰å®‰è£…çš„ç‰ˆæœ¬ä¸è®­ç»ƒä»£ç çš„APIå…¼å®¹æ€§
ç¡®ä¿æ‰€æœ‰å‚æ•°ã€æ–¹æ³•å’Œè¿”å›å€¼éƒ½æ­£ç¡®
"""

import torch
import warnings
warnings.filterwarnings("ignore")

def check_versions():
    """æ£€æŸ¥å…³é”®åŒ…ç‰ˆæœ¬"""
    print("ğŸ“¦ æ£€æŸ¥å…³é”®åŒ…ç‰ˆæœ¬:")
    
    packages = [
        ('torch', 'PyTorch'),
        ('diffusers', 'Diffusers'),
        ('transformers', 'Transformers'),
        ('accelerate', 'Accelerate'),
        ('huggingface_hub', 'HuggingFace Hub')
    ]
    
    versions = {}
    for package, name in packages:
        try:
            module = __import__(package)
            version = getattr(module, '__version__', 'unknown')
            print(f"   âœ… {name}: {version}")
            versions[package] = version
        except ImportError:
            print(f"   âŒ {name}: æœªå®‰è£…")
            versions[package] = None
    
    return versions

def test_autoencoder_kl_api():
    """æµ‹è¯•AutoencoderKL APIå…¼å®¹æ€§"""
    print("\nğŸ”§ æµ‹è¯•AutoencoderKL APIå…¼å®¹æ€§:")
    
    try:
        from diffusers import AutoencoderKL
        
        # 1. æµ‹è¯•æ„é€ å‡½æ•°å‚æ•° (è®­ç»ƒä»£ç ä¸­ä½¿ç”¨çš„)
        print("   1ï¸âƒ£ æµ‹è¯•æ„é€ å‡½æ•°å‚æ•°...")
        vae = AutoencoderKL(
            in_channels=3,
            out_channels=3,
            down_block_types=[
                "DownEncoderBlock2D",
                "DownEncoderBlock2D", 
                "DownEncoderBlock2D",
                "DownEncoderBlock2D"
            ],
            up_block_types=[
                "UpDecoderBlock2D",
                "UpDecoderBlock2D",
                "UpDecoderBlock2D",
                "UpDecoderBlock2D"
            ],
            block_out_channels=[128, 256, 512, 512],
            latent_channels=4,
            sample_size=256,
            layers_per_block=2,
            act_fn="silu",
            norm_num_groups=32,
            scaling_factor=0.18215,
        )
        print("   âœ… æ„é€ å‡½æ•°å‚æ•°å…¼å®¹")
        
        # 2. æµ‹è¯•encodeæ–¹æ³•
        print("   2ï¸âƒ£ æµ‹è¯•encodeæ–¹æ³•...")
        test_input = torch.randn(1, 3, 256, 256)
        
        with torch.no_grad():
            # è®­ç»ƒä»£ç ä¸­çš„ç”¨æ³•: vae.encode(images).latent_dist
            encode_result = vae.encode(test_input)
            
            # æ£€æŸ¥è¿”å›å€¼ç»“æ„
            if hasattr(encode_result, 'latent_dist'):
                posterior = encode_result.latent_dist
                print("   âœ… encode().latent_dist å¯ç”¨")
                
                # æ£€æŸ¥posterioræ–¹æ³•
                if hasattr(posterior, 'sample'):
                    latents = posterior.sample()
                    print("   âœ… latent_dist.sample() å¯ç”¨")
                else:
                    print("   âŒ latent_dist.sample() ä¸å¯ç”¨")
                    return False
                
                if hasattr(posterior, 'kl'):
                    kl_loss = posterior.kl()
                    print("   âœ… latent_dist.kl() å¯ç”¨")
                else:
                    print("   âŒ latent_dist.kl() ä¸å¯ç”¨")
                    return False
                    
            else:
                print("   âŒ encode().latent_dist ä¸å¯ç”¨")
                return False
        
        # 3. æµ‹è¯•decodeæ–¹æ³•
        print("   3ï¸âƒ£ æµ‹è¯•decodeæ–¹æ³•...")
        with torch.no_grad():
            # è®­ç»ƒä»£ç ä¸­çš„ç”¨æ³•: vae.decode(latents).sample
            decode_result = vae.decode(latents)
            
            if hasattr(decode_result, 'sample'):
                reconstruction = decode_result.sample
                print("   âœ… decode().sample å¯ç”¨")
            else:
                print("   âŒ decode().sample ä¸å¯ç”¨")
                return False
        
        # 4. æµ‹è¯•configå±æ€§
        print("   4ï¸âƒ£ æµ‹è¯•configå±æ€§...")
        if hasattr(vae, 'config'):
            config = vae.config
            if hasattr(config, 'scaling_factor'):
                scaling_factor = config.scaling_factor
                print(f"   âœ… config.scaling_factor å¯ç”¨: {scaling_factor}")
            else:
                print("   âŒ config.scaling_factor ä¸å¯ç”¨")
                return False
        else:
            print("   âŒ config å±æ€§ä¸å¯ç”¨")
            return False
        
        print("   âœ… AutoencoderKL APIå®Œå…¨å…¼å®¹")
        return True
        
    except Exception as e:
        print(f"   âŒ AutoencoderKL APIæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_unet_api():
    """æµ‹è¯•UNet2DConditionModel APIå…¼å®¹æ€§"""
    print("\nğŸ¯ æµ‹è¯•UNet2DConditionModel APIå…¼å®¹æ€§:")
    
    try:
        from diffusers import UNet2DConditionModel
        
        # 1. æµ‹è¯•æ„é€ å‡½æ•°å‚æ•°
        print("   1ï¸âƒ£ æµ‹è¯•æ„é€ å‡½æ•°å‚æ•°...")
        unet = UNet2DConditionModel(
            sample_size=32,
            in_channels=4,
            out_channels=4,
            cross_attention_dim=768,
            layers_per_block=1,
            block_out_channels=(32, 64),
            down_block_types=("CrossAttnDownBlock2D", "DownBlock2D"),
            up_block_types=("UpBlock2D", "CrossAttnUpBlock2D"),
        )
        print("   âœ… æ„é€ å‡½æ•°å‚æ•°å…¼å®¹")
        
        # 2. æµ‹è¯•å‰å‘ä¼ æ’­
        print("   2ï¸âƒ£ æµ‹è¯•å‰å‘ä¼ æ’­...")
        with torch.no_grad():
            test_latents = torch.randn(1, 4, 32, 32)
            test_timesteps = torch.randint(0, 1000, (1,))
            test_conditions = torch.randn(1, 1, 768)
            
            # è®­ç»ƒä»£ç ä¸­çš„ç”¨æ³•1: return_dict=False
            result1 = unet(
                test_latents,
                test_timesteps,
                encoder_hidden_states=test_conditions,
                return_dict=False
            )
            
            if isinstance(result1, tuple) and len(result1) > 0:
                noise_pred1 = result1[0]
                print("   âœ… return_dict=False æ¨¡å¼å…¼å®¹")
            else:
                print("   âŒ return_dict=False æ¨¡å¼ä¸å…¼å®¹")
                return False
            
            # è®­ç»ƒä»£ç ä¸­çš„ç”¨æ³•2: .sampleå±æ€§
            result2 = unet(
                test_latents,
                test_timesteps,
                encoder_hidden_states=test_conditions
            )
            
            if hasattr(result2, 'sample'):
                noise_pred2 = result2.sample
                print("   âœ… .sample å±æ€§å…¼å®¹")
            else:
                print("   âŒ .sample å±æ€§ä¸å…¼å®¹")
                return False
        
        # 3. æµ‹è¯•configå±æ€§
        print("   3ï¸âƒ£ æµ‹è¯•configå±æ€§...")
        if hasattr(unet, 'config'):
            config = unet.config
            if hasattr(config, 'in_channels'):
                print(f"   âœ… config.in_channels å¯ç”¨: {config.in_channels}")
            else:
                print("   âŒ config.in_channels ä¸å¯ç”¨")
                return False
        else:
            print("   âŒ config å±æ€§ä¸å¯ç”¨")
            return False
        
        print("   âœ… UNet2DConditionModel APIå®Œå…¨å…¼å®¹")
        return True
        
    except Exception as e:
        print(f"   âŒ UNet2DConditionModel APIæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_scheduler_api():
    """æµ‹è¯•è°ƒåº¦å™¨APIå…¼å®¹æ€§"""
    print("\nâ° æµ‹è¯•è°ƒåº¦å™¨APIå…¼å®¹æ€§:")
    
    try:
        from diffusers import DDPMScheduler, DDIMScheduler
        
        # 1. æµ‹è¯•DDPMScheduler
        print("   1ï¸âƒ£ æµ‹è¯•DDPMScheduler...")
        scheduler = DDPMScheduler(
            num_train_timesteps=1000,
            beta_start=0.00085,
            beta_end=0.012,
            beta_schedule="scaled_linear"
        )
        
        # æµ‹è¯•å…³é”®æ–¹æ³•
        test_latents = torch.randn(1, 4, 32, 32)
        test_noise = torch.randn_like(test_latents)
        test_timesteps = torch.randint(0, 1000, (1,))
        
        with torch.no_grad():
            # add_noiseæ–¹æ³•
            noisy_latents = scheduler.add_noise(test_latents, test_noise, test_timesteps)
            print("   âœ… add_noise() æ–¹æ³•å¯ç”¨")
            
            # configå±æ€§
            if hasattr(scheduler, 'config'):
                config = scheduler.config
                if hasattr(config, 'num_train_timesteps'):
                    print(f"   âœ… config.num_train_timesteps å¯ç”¨: {config.num_train_timesteps}")
                if hasattr(config, 'prediction_type'):
                    print(f"   âœ… config.prediction_type å¯ç”¨: {config.prediction_type}")
                else:
                    print("   âš ï¸  config.prediction_type ä¸å¯ç”¨ (å¯èƒ½ä½¿ç”¨é»˜è®¤å€¼)")
            
            # init_noise_sigmaå±æ€§
            if hasattr(scheduler, 'init_noise_sigma'):
                print(f"   âœ… init_noise_sigma å¯ç”¨: {scheduler.init_noise_sigma}")
            else:
                print("   âŒ init_noise_sigma ä¸å¯ç”¨")
                return False
            
            # timestepså±æ€§
            if hasattr(scheduler, 'timesteps'):
                print(f"   âœ… timesteps å¯ç”¨: é•¿åº¦ {len(scheduler.timesteps)}")
            else:
                print("   âŒ timesteps ä¸å¯ç”¨")
                return False
            
            # scale_model_inputæ–¹æ³•
            scaled_input = scheduler.scale_model_input(test_latents, test_timesteps[0])
            print("   âœ… scale_model_input() æ–¹æ³•å¯ç”¨")
            
            # stepæ–¹æ³•
            step_result = scheduler.step(test_noise, test_timesteps[0], test_latents)
            if hasattr(step_result, 'prev_sample'):
                print("   âœ… step().prev_sample å¯ç”¨")
            else:
                print("   âŒ step().prev_sample ä¸å¯ç”¨")
                return False
        
        # 2. æµ‹è¯•DDIMScheduler
        print("   2ï¸âƒ£ æµ‹è¯•DDIMScheduler...")
        ddim_scheduler = DDIMScheduler.from_config(scheduler.config)
        ddim_scheduler.set_timesteps(50)
        print("   âœ… DDIMScheduler.from_config() å’Œ set_timesteps() å¯ç”¨")
        
        print("   âœ… è°ƒåº¦å™¨APIå®Œå…¨å…¼å®¹")
        return True
        
    except Exception as e:
        print(f"   âŒ è°ƒåº¦å™¨APIæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_training_workflow():
    """æµ‹è¯•å®Œæ•´è®­ç»ƒå·¥ä½œæµç¨‹"""
    print("\nğŸ”„ æµ‹è¯•å®Œæ•´è®­ç»ƒå·¥ä½œæµç¨‹:")
    
    try:
        from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler
        
        # åˆ›å»ºæ¨¡å‹ (å°å°ºå¯¸)
        vae = AutoencoderKL(
            in_channels=3,
            out_channels=3,
            latent_channels=4,
            sample_size=64,
        )
        
        unet = UNet2DConditionModel(
            sample_size=8,
            in_channels=4,
            out_channels=4,
            cross_attention_dim=768,
        )
        
        scheduler = DDPMScheduler(num_train_timesteps=1000)
        
        print("   1ï¸âƒ£ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
        with torch.no_grad():
            # è¾“å…¥æ•°æ®
            images = torch.randn(2, 3, 64, 64)
            user_indices = torch.tensor([0, 1])
            
            # VAEç¼–ç  (è®­ç»ƒä»£ç ä¸­çš„ç”¨æ³•)
            posterior = vae.encode(images).latent_dist
            latents = posterior.sample()
            latents = latents * vae.config.scaling_factor
            
            print("   2ï¸âƒ£ VAEç¼–ç æˆåŠŸ")
            
            # æ·»åŠ å™ªå£°
            noise = torch.randn_like(latents)
            timesteps = torch.randint(0, scheduler.config.num_train_timesteps, (latents.shape[0],))
            noisy_latents = scheduler.add_noise(latents, noise, timesteps)
            
            print("   3ï¸âƒ£ å™ªå£°æ·»åŠ æˆåŠŸ")
            
            # æ¡ä»¶ç¼–ç  (æ¨¡æ‹Ÿ)
            encoder_hidden_states = torch.randn(2, 1, 768)
            
            # UNeté¢„æµ‹
            model_pred = unet(
                noisy_latents,
                timesteps,
                encoder_hidden_states=encoder_hidden_states,
                return_dict=False
            )[0]
            
            print("   4ï¸âƒ£ UNeté¢„æµ‹æˆåŠŸ")
            
            # VAEè§£ç 
            latents_decoded = latents / vae.config.scaling_factor
            reconstruction = vae.decode(latents_decoded).sample
            
            print("   5ï¸âƒ£ VAEè§£ç æˆåŠŸ")
            
            # éªŒè¯å½¢çŠ¶
            print(f"   ğŸ“Š å½¢çŠ¶éªŒè¯:")
            print(f"      è¾“å…¥å›¾åƒ: {images.shape}")
            print(f"      æ½œåœ¨è¡¨ç¤º: {latents.shape}")
            print(f"      å™ªå£°é¢„æµ‹: {model_pred.shape}")
            print(f"      é‡å»ºå›¾åƒ: {reconstruction.shape}")
        
        print("   âœ… å®Œæ•´è®­ç»ƒå·¥ä½œæµç¨‹å…¼å®¹")
        return True
        
    except Exception as e:
        print(f"   âŒ è®­ç»ƒå·¥ä½œæµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    print("ğŸ” APIå…¼å®¹æ€§éªŒè¯å·¥å…·")
    print("éªŒè¯å½“å‰ç‰ˆæœ¬ä¸è®­ç»ƒä»£ç çš„å®Œå…¨å…¼å®¹æ€§")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ç‰ˆæœ¬
    versions = check_versions()
    
    # 2. APIå…¼å®¹æ€§æµ‹è¯•
    tests = [
        ("AutoencoderKL API", test_autoencoder_kl_api),
        ("UNet2DConditionModel API", test_unet_api),
        ("è°ƒåº¦å™¨ API", test_scheduler_api),
        ("å®Œæ•´è®­ç»ƒå·¥ä½œæµç¨‹", test_training_workflow)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # 3. æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š å…¼å®¹æ€§éªŒè¯æ€»ç»“:")
    
    passed = 0
    for test_name, result in results:
        status = "âœ…" if result else "âŒ"
        print(f"   {status} {test_name}")
        if result:
            passed += 1
    
    total = len(results)
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰APIå®Œå…¨å…¼å®¹ï¼")
        print("âœ… å½“å‰ç‰ˆæœ¬å¯ä»¥å®‰å…¨ç”¨äºè®­ç»ƒ")
        print("\nğŸ“‹ ç‰ˆæœ¬ä¿¡æ¯:")
        for package, version in versions.items():
            if version:
                print(f"   - {package}: {version}")
        return True
    else:
        print("\nâš ï¸  å­˜åœ¨APIå…¼å®¹æ€§é—®é¢˜")
        print("âŒ å»ºè®®ä½¿ç”¨æ¨èç‰ˆæœ¬ç»„åˆ")
        return False

if __name__ == "__main__":
    main()
