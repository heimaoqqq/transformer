#!/usr/bin/env python3
"""
å¼ºåˆ¶å¤šGPUå¯åŠ¨è„šæœ¬
ä¸“é—¨ç”¨äºKaggleç¯å¢ƒçš„å¤šGPUè®­ç»ƒ
"""

import os
import sys
import subprocess
import torch
from pathlib import Path

def setup_environment():
    """è®¾ç½®å¤šGPUç¯å¢ƒå˜é‡"""
    
    # æ£€æµ‹GPUæ•°é‡
    gpu_count = torch.cuda.device_count()
    print(f"ğŸ® æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    if gpu_count <= 1:
        print("âš ï¸  åªæœ‰å•GPUï¼Œæ— æ³•å¯åŠ¨å¤šGPUè®­ç»ƒ")
        return False
    
    # è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ä½¿ç”¨æ‰€æœ‰GPU
    os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(i) for i in range(gpu_count))
    os.environ['WORLD_SIZE'] = str(gpu_count)
    os.environ['MASTER_ADDR'] = 'localhost'
    os.environ['MASTER_PORT'] = '12355'
    
    print(f"âœ… ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆ:")
    print(f"   CUDA_VISIBLE_DEVICES: {os.environ['CUDA_VISIBLE_DEVICES']}")
    print(f"   WORLD_SIZE: {os.environ['WORLD_SIZE']}")
    
    return True

def launch_training(stage="vae"):
    """å¯åŠ¨å¤šGPUè®­ç»ƒ"""
    
    if not setup_environment():
        print("âŒ ç¯å¢ƒè®¾ç½®å¤±è´¥")
        return False
    
    gpu_count = torch.cuda.device_count()
    
    # æ„å»ºè®­ç»ƒå‘½ä»¤
    if stage == "vae":
        script_args = [
            "--data_dir", "/kaggle/input/dataset",
            "--output_dir", "/kaggle/working/outputs/vae",
            "--batch_size", "6",
            "--num_epochs", "40",
            "--learning_rate", "0.0001",
            "--mixed_precision", "fp16",
            "--gradient_accumulation_steps", "2",
            "--kl_weight", "1e-6",
            "--perceptual_weight", "0.05",
            "--freq_weight", "0.05",
            "--resolution", "256",
            "--num_workers", "2",
            "--save_interval", "10",
            "--log_interval", "5",
            "--sample_interval", "100",
            "--experiment_name", "kaggle_vae"
        ]
        script_path = "training/train_vae.py"
    
    elif stage == "diffusion":
        script_args = [
            "--data_dir", "/kaggle/input/dataset",
            "--vae_path", "/kaggle/working/outputs/vae/final_model",
            "--output_dir", "/kaggle/working/outputs/diffusion",
            "--batch_size", "4",
            "--num_epochs", "100",
            "--learning_rate", "0.0001",
            "--mixed_precision", "fp16",
            "--gradient_accumulation_steps", "4",
            "--cross_attention_dim", "768",
            "--num_train_timesteps", "1000",
            "--condition_dropout", "0.1",
            "--resolution", "256",
            "--val_split", "0.1",
            "--num_workers", "2",
            "--save_interval", "20",
            "--log_interval", "10",
            "--sample_interval", "100",
            "--val_interval", "50",
            "--experiment_name", "kaggle_diffusion"
        ]
        script_path = "training/train_diffusion.py"
    
    else:
        print(f"âŒ æœªçŸ¥çš„è®­ç»ƒé˜¶æ®µ: {stage}")
        return False
    
    # æ–¹æ³•1: ä½¿ç”¨accelerate launch
    cmd1 = [
        "accelerate", "launch",
        "--config_file", "accelerate_config.yaml",
        "--num_processes", str(gpu_count),
        script_path
    ] + script_args
    
    print(f"\nğŸš€ å¯åŠ¨å¤šGPUè®­ç»ƒ ({stage}):")
    print("Command:", " ".join(cmd1))
    
    try:
        # ä½¿ç”¨å®æ—¶è¾“å‡ºï¼Œä¸é‡å®šå‘
        result = subprocess.run(cmd1, check=True, text=True)
        print("âœ… è®­ç»ƒå®Œæˆ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ accelerate launch å¤±è´¥: {e}")

        # æ–¹æ³•2: ä½¿ç”¨torchrun (å¤‡ç”¨æ–¹æ¡ˆ)
        print("\nğŸ”„ å°è¯•ä½¿ç”¨torchrun...")
        cmd2 = [
            "torchrun",
            "--nproc_per_node", str(gpu_count),
            "--master_port", "12355",
            script_path
        ] + script_args

        print("Command:", " ".join(cmd2))

        try:
            # ä½¿ç”¨å®æ—¶è¾“å‡ºï¼Œä¸é‡å®šå‘
            result = subprocess.run(cmd2, check=True, text=True)
            print("âœ… è®­ç»ƒå®Œæˆ (torchrun)")
            return True
        except subprocess.CalledProcessError as e2:
            print(f"âŒ torchrun ä¹Ÿå¤±è´¥: {e2}")

            # æ–¹æ³•3: æ‰‹åŠ¨å¯åŠ¨å¤šè¿›ç¨‹ (æœ€åæ–¹æ¡ˆ)
            print("\nğŸ”„ å°è¯•æ‰‹åŠ¨å¤šè¿›ç¨‹å¯åŠ¨...")
            return launch_manual_multiprocess(script_path, script_args, gpu_count)
    
    return False

def launch_manual_multiprocess(script_path, script_args, gpu_count):
    """æ‰‹åŠ¨å¯åŠ¨å¤šè¿›ç¨‹è®­ç»ƒ"""
    
    processes = []
    
    for rank in range(gpu_count):
        env = os.environ.copy()
        env['LOCAL_RANK'] = str(rank)
        env['RANK'] = str(rank)
        env['CUDA_VISIBLE_DEVICES'] = str(rank)
        
        cmd = ["python", script_path] + script_args + [
            "--local_rank", str(rank)
        ]
        
        print(f"å¯åŠ¨è¿›ç¨‹ {rank}: {' '.join(cmd)}")
        
        # åªé‡å®šå‘stderrï¼Œä¿æŒstdoutå®æ—¶è¾“å‡º
        process = subprocess.Popen(
            cmd,
            env=env,
            stderr=subprocess.PIPE,
            text=True
        )
        processes.append(process)

    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    success = True
    for i, process in enumerate(processes):
        _, stderr = process.communicate()
        if process.returncode != 0:
            print(f"âŒ è¿›ç¨‹ {i} å¤±è´¥:")
            if stderr:
                print(stderr)
            success = False
        else:
            print(f"âœ… è¿›ç¨‹ {i} å®Œæˆ")
    
    return success

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python launch_multi_gpu.py <stage>")
        print("stage: vae æˆ– diffusion")
        sys.exit(1)
    
    stage = sys.argv[1]
    
    print("ğŸš€ Kaggleå¤šGPUè®­ç»ƒå¯åŠ¨å™¨")
    print("=" * 50)
    
    success = launch_training(stage)
    
    if success:
        print(f"\nğŸ‰ {stage} è®­ç»ƒå®Œæˆ!")
    else:
        print(f"\nâŒ {stage} è®­ç»ƒå¤±è´¥!")
        sys.exit(1)

if __name__ == "__main__":
    main()
