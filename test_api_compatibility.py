#!/usr/bin/env python3
"""
å®Œæ•´çš„APIå…¼å®¹æ€§æ£€æŸ¥è„šæœ¬
éªŒè¯diffusersã€transformerså’Œè‡ªå®šä¹‰æ¨¡å‹çš„APIå…¼å®¹æ€§

âš ï¸ é‡è¦ï¼šè¯·åœ¨ç¯å¢ƒé…ç½®å®Œæˆåè¿è¡Œæ­¤è„šæœ¬
ä½¿ç”¨æ–¹æ³•ï¼š
1. å…ˆè¿è¡Œ: python setup_unified_environment.py
2. å†è¿è¡Œ: python test_api_compatibility.py
"""

import torch
import sys
import importlib
import inspect
import warnings
from pathlib import Path
from typing import Dict, List, Tuple, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

class APICompatibilityChecker:
    """APIå…¼å®¹æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.results = {}
        self.warnings_captured = []
        
    def capture_warnings(self):
        """æ•è·è­¦å‘Šä¿¡æ¯"""
        def warning_handler(message, category, filename, lineno, file=None, line=None):
            self.warnings_captured.append({
                'message': str(message),
                'category': category.__name__,
                'filename': filename,
                'lineno': lineno
            })
        
        warnings.showwarning = warning_handler
        
    def check_module_versions(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ¨¡å—ç‰ˆæœ¬"""
        print("ğŸ” æ£€æŸ¥æ¨¡å—ç‰ˆæœ¬...")
        
        modules = {
            'torch': 'PyTorch',
            'diffusers': 'Diffusers',
            'transformers': 'Transformers',
            'huggingface_hub': 'HuggingFace Hub',
            'accelerate': 'Accelerate',
            'safetensors': 'SafeTensors',
            'tokenizers': 'Tokenizers',
        }
        
        versions = {}
        for module_name, display_name in modules.items():
            try:
                module = importlib.import_module(module_name)
                version = getattr(module, '__version__', 'unknown')
                versions[module_name] = version
                print(f"âœ… {display_name}: {version}")
            except ImportError as e:
                versions[module_name] = f"ERROR: {e}"
                print(f"âŒ {display_name}: å¯¼å…¥å¤±è´¥ - {e}")
        
        return versions
    
    def check_diffusers_api(self) -> Dict[str, Any]:
        """æ£€æŸ¥diffusers APIå…¼å®¹æ€§"""
        print("\nğŸ” æ£€æŸ¥diffusers APIå…¼å®¹æ€§...")
        
        results = {}
        
        # 1. æ£€æŸ¥VQModelå¯¼å…¥
        try:
            from diffusers.models.autoencoders.vq_model import VQModel
            results['vqmodel_import'] = "SUCCESS"
            print("âœ… VQModelå¯¼å…¥æˆåŠŸ")
            
            # æ£€æŸ¥VQModelæ„é€ å‡½æ•°å‚æ•°
            sig = inspect.signature(VQModel.__init__)
            params = list(sig.parameters.keys())
            results['vqmodel_params'] = params
            print(f"âœ… VQModelå‚æ•°: {len(params)} ä¸ª")
            
            # æµ‹è¯•VQModelå®ä¾‹åŒ–
            try:
                model = VQModel(
                    in_channels=3,
                    out_channels=3,
                    latent_channels=4,
                    num_vq_embeddings=1024,
                    vq_embed_dim=256,
                )
                results['vqmodel_instantiation'] = "SUCCESS"
                print("âœ… VQModelå®ä¾‹åŒ–æˆåŠŸ")
                
                # æ£€æŸ¥VQModelæ–¹æ³•
                methods = [method for method in dir(model) if not method.startswith('_')]
                results['vqmodel_methods'] = methods
                print(f"âœ… VQModelæ–¹æ³•: {len(methods)} ä¸ª")
                
            except Exception as e:
                results['vqmodel_instantiation'] = f"ERROR: {e}"
                print(f"âŒ VQModelå®ä¾‹åŒ–å¤±è´¥: {e}")
                
        except ImportError as e:
            results['vqmodel_import'] = f"ERROR: {e}"
            print(f"âŒ VQModelå¯¼å…¥å¤±è´¥: {e}")
        
        # 2. æ£€æŸ¥VectorQuantizer
        try:
            from diffusers.models.autoencoders.vq_model import VectorQuantizer
            results['vectorquantizer_import'] = "SUCCESS"
            print("âœ… VectorQuantizerå¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            results['vectorquantizer_import'] = f"ERROR: {e}"
            print(f"âŒ VectorQuantizerå¯¼å…¥å¤±è´¥: {e}")
        
        # 3. æ£€æŸ¥å…¶ä»–diffusersç»„ä»¶
        try:
            from diffusers import AutoencoderKL
            results['autoencoder_import'] = "SUCCESS"
            print("âœ… AutoencoderKLå¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            results['autoencoder_import'] = f"ERROR: {e}"
            print(f"âŒ AutoencoderKLå¯¼å…¥å¤±è´¥: {e}")
        
        return results
    
    def check_transformers_api(self) -> Dict[str, Any]:
        """æ£€æŸ¥transformers APIå…¼å®¹æ€§"""
        print("\nğŸ” æ£€æŸ¥transformers APIå…¼å®¹æ€§...")
        
        results = {}
        
        # 1. æ£€æŸ¥GPT2
        try:
            from transformers import GPT2Config, GPT2LMHeadModel
            results['gpt2_import'] = "SUCCESS"
            print("âœ… GPT2å¯¼å…¥æˆåŠŸ")
            
            # æ£€æŸ¥GPT2Configå‚æ•°
            sig = inspect.signature(GPT2Config.__init__)
            params = list(sig.parameters.keys())
            results['gpt2_config_params'] = params
            print(f"âœ… GPT2Configå‚æ•°: {len(params)} ä¸ª")
            
            # æµ‹è¯•GPT2å®ä¾‹åŒ–
            try:
                config = GPT2Config(
                    vocab_size=1024,
                    n_positions=256,
                    n_embd=512,
                    n_layer=4,
                    n_head=8
                )
                model = GPT2LMHeadModel(config)
                results['gpt2_instantiation'] = "SUCCESS"
                print("âœ… GPT2å®ä¾‹åŒ–æˆåŠŸ")
                
            except Exception as e:
                results['gpt2_instantiation'] = f"ERROR: {e}"
                print(f"âŒ GPT2å®ä¾‹åŒ–å¤±è´¥: {e}")
                
        except ImportError as e:
            results['gpt2_import'] = f"ERROR: {e}"
            print(f"âŒ GPT2å¯¼å…¥å¤±è´¥: {e}")
        
        # 2. æ£€æŸ¥Tokenizer
        try:
            from transformers import AutoTokenizer
            results['tokenizer_import'] = "SUCCESS"
            print("âœ… AutoTokenizerå¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            results['tokenizer_import'] = f"ERROR: {e}"
            print(f"âŒ AutoTokenizerå¯¼å…¥å¤±è´¥: {e}")
        
        return results
    
    def check_custom_models_api(self) -> Dict[str, Any]:
        """æ£€æŸ¥è‡ªå®šä¹‰æ¨¡å‹APIå…¼å®¹æ€§"""
        print("\nğŸ” æ£€æŸ¥è‡ªå®šä¹‰æ¨¡å‹APIå…¼å®¹æ€§...")
        
        results = {}
        
        try:
            from models.vqvae_model import MicroDopplerVQVAE
            results['custom_vqvae_import'] = "SUCCESS"
            print("âœ… MicroDopplerVQVAEå¯¼å…¥æˆåŠŸ")
            
            # æ£€æŸ¥æ„é€ å‡½æ•°å‚æ•°
            sig = inspect.signature(MicroDopplerVQVAE.__init__)
            params = list(sig.parameters.keys())
            results['custom_vqvae_params'] = params
            print(f"âœ… MicroDopplerVQVAEå‚æ•°: {len(params)} ä¸ª")
            
            # æµ‹è¯•å®ä¾‹åŒ–
            try:
                model = MicroDopplerVQVAE(
                    in_channels=3,
                    out_channels=3,
                    latent_channels=4,
                    codebook_size=1024,
                    codebook_dim=256
                )
                results['custom_vqvae_instantiation'] = "SUCCESS"
                print("âœ… MicroDopplerVQVAEå®ä¾‹åŒ–æˆåŠŸ")
                
                # æ£€æŸ¥æ–¹æ³•
                methods = [method for method in dir(model) if not method.startswith('_')]
                results['custom_vqvae_methods'] = methods
                print(f"âœ… MicroDopplerVQVAEæ–¹æ³•: {len(methods)} ä¸ª")
                
            except Exception as e:
                results['custom_vqvae_instantiation'] = f"ERROR: {e}"
                print(f"âŒ MicroDopplerVQVAEå®ä¾‹åŒ–å¤±è´¥: {e}")
                
        except ImportError as e:
            results['custom_vqvae_import'] = f"ERROR: {e}"
            print(f"âŒ MicroDopplerVQVAEå¯¼å…¥å¤±è´¥: {e}")
        
        return results
    
    def check_forward_compatibility(self) -> Dict[str, Any]:
        """æ£€æŸ¥å‰å‘ä¼ æ’­å…¼å®¹æ€§"""
        print("\nğŸ” æ£€æŸ¥å‰å‘ä¼ æ’­å…¼å®¹æ€§...")
        
        results = {}
        
        # 1. æµ‹è¯•VQModelå‰å‘ä¼ æ’­
        try:
            from diffusers.models.autoencoders.vq_model import VQModel
            model = VQModel(
                in_channels=3,
                out_channels=3,
                latent_channels=4,
                num_vq_embeddings=1024,
                vq_embed_dim=256,
            )
            
            x = torch.randn(1, 3, 64, 64)
            with torch.no_grad():
                output = model(x)
                
            results['vqmodel_forward'] = {
                'input_shape': list(x.shape),
                'output_shape': list(output.sample.shape),
                'output_type': type(output).__name__
            }
            print(f"âœ… VQModelå‰å‘ä¼ æ’­: {x.shape} -> {output.sample.shape}")
            
        except Exception as e:
            results['vqmodel_forward'] = f"ERROR: {e}"
            print(f"âŒ VQModelå‰å‘ä¼ æ’­å¤±è´¥: {e}")
        
        # 2. æµ‹è¯•GPT2å‰å‘ä¼ æ’­
        try:
            from transformers import GPT2Config, GPT2LMHeadModel
            config = GPT2Config(
                vocab_size=1024,
                n_positions=256,
                n_embd=512,
                n_layer=4,
                n_head=8
            )
            model = GPT2LMHeadModel(config)
            
            input_ids = torch.randint(0, 1024, (1, 10))
            with torch.no_grad():
                output = model(input_ids)
                
            results['gpt2_forward'] = {
                'input_shape': list(input_ids.shape),
                'output_shape': list(output.logits.shape),
                'output_type': type(output).__name__
            }
            print(f"âœ… GPT2å‰å‘ä¼ æ’­: {input_ids.shape} -> {output.logits.shape}")
            
        except Exception as e:
            results['gpt2_forward'] = f"ERROR: {e}"
            print(f"âŒ GPT2å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        
        # 3. æµ‹è¯•è‡ªå®šä¹‰æ¨¡å‹å‰å‘ä¼ æ’­
        try:
            from models.vqvae_model import MicroDopplerVQVAE
            model = MicroDopplerVQVAE()
            
            x = torch.randn(1, 3, 128, 128)
            with torch.no_grad():
                output = model(x)
                
            results['custom_vqvae_forward'] = {
                'input_shape': list(x.shape),
                'output_shape': list(output.sample.shape),
                'output_type': type(output).__name__
            }
            print(f"âœ… MicroDopplerVQVAEå‰å‘ä¼ æ’­: {x.shape} -> {output.sample.shape}")
            
        except Exception as e:
            results['custom_vqvae_forward'] = f"ERROR: {e}"
            print(f"âŒ MicroDopplerVQVAEå‰å‘ä¼ æ’­å¤±è´¥: {e}")
        
        return results
    
    def check_save_load_compatibility(self) -> Dict[str, Any]:
        """æ£€æŸ¥ä¿å­˜/åŠ è½½å…¼å®¹æ€§"""
        print("\nğŸ” æ£€æŸ¥ä¿å­˜/åŠ è½½å…¼å®¹æ€§...")
        
        results = {}
        
        try:
            from models.vqvae_model import MicroDopplerVQVAE
            model = MicroDopplerVQVAE()
            
            # æµ‹è¯•state_dict
            state_dict = model.state_dict()
            results['state_dict_keys'] = len(state_dict)
            print(f"âœ… state_dictè·å–æˆåŠŸ: {len(state_dict)} ä¸ªå‚æ•°")
            
            # æµ‹è¯•load_state_dict
            model.load_state_dict(state_dict)
            results['load_state_dict'] = "SUCCESS"
            print("âœ… load_state_dictæˆåŠŸ")
            
        except Exception as e:
            results['save_load'] = f"ERROR: {e}"
            print(f"âŒ ä¿å­˜/åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        
        return results
    
    def run_full_check(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„APIå…¼å®¹æ€§æ£€æŸ¥"""
        print("ğŸ¨ å®Œæ•´APIå…¼å®¹æ€§æ£€æŸ¥")
        print("=" * 60)
        
        self.capture_warnings()
        
        # è¿è¡Œæ‰€æœ‰æ£€æŸ¥
        self.results['versions'] = self.check_module_versions()
        self.results['diffusers_api'] = self.check_diffusers_api()
        self.results['transformers_api'] = self.check_transformers_api()
        self.results['custom_models_api'] = self.check_custom_models_api()
        self.results['forward_compatibility'] = self.check_forward_compatibility()
        self.results['save_load_compatibility'] = self.check_save_load_compatibility()
        self.results['warnings'] = self.warnings_captured
        
        return self.results
    
    def generate_report(self) -> str:
        """ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š"""
        report = []
        report.append("# APIå…¼å®¹æ€§æ£€æŸ¥æŠ¥å‘Š")
        report.append("=" * 60)
        
        # ç‰ˆæœ¬ä¿¡æ¯
        report.append("\n## ğŸ“¦ ç‰ˆæœ¬ä¿¡æ¯")
        for module, version in self.results.get('versions', {}).items():
            status = "âœ…" if not version.startswith("ERROR") else "âŒ"
            report.append(f"{status} {module}: {version}")
        
        # è­¦å‘Šä¿¡æ¯
        if self.warnings_captured:
            report.append(f"\n## âš ï¸ è­¦å‘Šä¿¡æ¯ ({len(self.warnings_captured)} ä¸ª)")
            for warning in self.warnings_captured:
                report.append(f"- {warning['category']}: {warning['message']}")
        
        # æ€»ç»“
        total_checks = 0
        passed_checks = 0
        
        for category, results in self.results.items():
            if category in ['versions', 'warnings']:
                continue
            if isinstance(results, dict):
                for key, value in results.items():
                    total_checks += 1
                    if not str(value).startswith("ERROR"):
                        passed_checks += 1
        
        report.append(f"\n## ğŸ“Š æ£€æŸ¥æ€»ç»“")
        report.append(f"- æ€»æ£€æŸ¥é¡¹: {total_checks}")
        report.append(f"- é€šè¿‡æ£€æŸ¥: {passed_checks}")
        report.append(f"- æˆåŠŸç‡: {passed_checks/total_checks*100:.1f}%")
        
        if passed_checks >= total_checks * 0.9:  # 90%é€šè¿‡ç‡
            report.append("\nğŸ‰ APIå…¼å®¹æ€§æ£€æŸ¥é€šè¿‡ï¼ç¯å¢ƒé…ç½®æ­£ç¡®ã€‚")
        else:
            report.append("\nâŒ APIå…¼å®¹æ€§æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®ã€‚")
        
        return "\n".join(report)

def main():
    """ä¸»å‡½æ•°"""
    print("âš ï¸ é‡è¦æé†’ï¼šè¯·ç¡®ä¿å·²å®Œæˆç¯å¢ƒé…ç½®")
    print("   å¦‚æœå°šæœªé…ç½®ç¯å¢ƒï¼Œè¯·å…ˆè¿è¡Œ:")
    print("   python setup_unified_environment.py")
    print("   æˆ–")
    print("   python setup_vqvae_environment.py")
    print("   python setup_transformer_environment.py")
    print()

    checker = APICompatibilityChecker()
    results = checker.run_full_check()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š...")
    
    report = checker.generate_report()
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = Path(__file__).parent / "api_compatibility_report.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    return results

if __name__ == "__main__":
    results = main()
