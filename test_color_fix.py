#!/usr/bin/env python3
"""
æµ‹è¯•é¢œè‰²ä¿®å¤ - éªŒè¯VAEè¾“å‡ºèŒƒå›´å’Œåå½’ä¸€åŒ–æ˜¯å¦æ­£ç¡®
"""

import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from pathlib import Path
from diffusers import AutoencoderKL

# æ·»åŠ é¡¹ç›®è·¯å¾„
import sys
sys.path.append('.')
from utils.data_loader import MicroDopplerDataset

def test_vae_output_range():
    """æµ‹è¯•VAEçš„å®žé™…è¾“å‡ºèŒƒå›´"""
    print("ðŸ” æµ‹è¯•VAEè¾“å‡ºèŒƒå›´...")
    
    # åŠ è½½VAE
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    vae_path = "/kaggle/input/final-model"  # æ ¹æ®å®žé™…è·¯å¾„è°ƒæ•´
    
    try:
        vae = AutoencoderKL.from_pretrained(vae_path)
        vae = vae.to(device)
        vae.eval()
        print("âœ… VAEåŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ VAEåŠ è½½å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_input = torch.randn(1, 3, 128, 128).to(device)
    test_input = torch.clamp(test_input, 0, 1)  # ç¡®ä¿è¾“å…¥åœ¨[0,1]èŒƒå›´
    
    with torch.no_grad():
        # VAEç¼–ç -è§£ç 
        posterior = vae.encode(test_input).latent_dist
        latents = posterior.sample()
        reconstructed = vae.decode(latents).sample
        
        # æ£€æŸ¥è¾“å‡ºèŒƒå›´
        min_val = reconstructed.min().item()
        max_val = reconstructed.max().item()
        mean_val = reconstructed.mean().item()
        
        print(f"ðŸ“Š VAEè¾“å‡ºç»Ÿè®¡:")
        print(f"   æœ€å°å€¼: {min_val:.4f}")
        print(f"   æœ€å¤§å€¼: {max_val:.4f}")
        print(f"   å¹³å‡å€¼: {mean_val:.4f}")
        
        # åˆ¤æ–­è¾“å‡ºèŒƒå›´
        if min_val >= -0.1 and max_val <= 1.1:
            print("âœ… VAEè¾“å‡ºèŒƒå›´ä¼¼ä¹Žåœ¨[0,1]é™„è¿‘")
            return "0_1"
        elif min_val >= -1.1 and max_val <= 1.1:
            print("âœ… VAEè¾“å‡ºèŒƒå›´ä¼¼ä¹Žåœ¨[-1,1]é™„è¿‘")
            return "-1_1"
        else:
            print(f"âš ï¸ VAEè¾“å‡ºèŒƒå›´å¼‚å¸¸: [{min_val:.4f}, {max_val:.4f}]")
            return "unknown"

def test_color_conversion():
    """æµ‹è¯•é¢œè‰²è½¬æ¢çš„æ­£ç¡®æ€§"""
    print("\nðŸŽ¨ æµ‹è¯•é¢œè‰²è½¬æ¢...")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ - æ·±è“è‰²èƒŒæ™¯ï¼Œç±»ä¼¼çœŸå®žå›¾åƒ
    test_image = np.zeros((128, 128, 3), dtype=np.uint8)
    test_image[:, :, 0] = 0    # R = 0
    test_image[:, :, 1] = 0    # G = 0  
    test_image[:, :, 2] = 255  # B = 255 (æ·±è“è‰²)
    
    # æ·»åŠ ä¸€äº›é»„è‰²åŒºåŸŸ (ç±»ä¼¼çœŸå®žå›¾åƒçš„æ¨¡å¼)
    test_image[60:68, :, 0] = 255  # R = 255
    test_image[60:68, :, 1] = 255  # G = 255
    test_image[60:68, :, 2] = 0    # B = 0 (é»„è‰²)
    
    print("ðŸ“Š åŽŸå§‹æµ‹è¯•å›¾åƒ:")
    print(f"   è“è‰²åŒºåŸŸ RGB: ({test_image[0,0,0]}, {test_image[0,0,1]}, {test_image[0,0,2]})")
    print(f"   é»„è‰²åŒºåŸŸ RGB: ({test_image[64,64,0]}, {test_image[64,64,1]}, {test_image[64,64,2]})")
    
    # è½¬æ¢ä¸ºtensor (æ¨¡æ‹Ÿæ•°æ®åŠ è½½å™¨çš„å¤„ç†)
    tensor_image = torch.from_numpy(test_image).float() / 255.0  # [0,1]
    tensor_image = tensor_image.permute(2, 0, 1).unsqueeze(0)  # [1,3,H,W]
    
    print(f"   TensorèŒƒå›´: [{tensor_image.min():.4f}, {tensor_image.max():.4f}]")
    
    # æµ‹è¯•ä¸¤ç§åå½’ä¸€åŒ–æ–¹æ³•
    print("\nðŸ”„ æµ‹è¯•åå½’ä¸€åŒ–æ–¹æ³•:")
    
    # æ–¹æ³•1: é”™è¯¯çš„æ–¹æ³• (å‡è®¾è¾“å…¥æ˜¯[-1,1])
    wrong_denorm = (tensor_image / 2 + 0.5).clamp(0, 1)
    wrong_result = (wrong_denorm * 255).numpy().astype(np.uint8)[0].transpose(1, 2, 0)
    
    # æ–¹æ³•2: æ­£ç¡®çš„æ–¹æ³• (è¾“å…¥å·²ç»æ˜¯[0,1])
    correct_denorm = tensor_image.clamp(0, 1)
    correct_result = (correct_denorm * 255).numpy().astype(np.uint8)[0].transpose(1, 2, 0)
    
    print("âŒ é”™è¯¯æ–¹æ³•ç»“æžœ:")
    print(f"   è“è‰²åŒºåŸŸ RGB: ({wrong_result[0,0,0]}, {wrong_result[0,0,1]}, {wrong_result[0,0,2]})")
    print(f"   é»„è‰²åŒºåŸŸ RGB: ({wrong_result[64,64,0]}, {wrong_result[64,64,1]}, {wrong_result[64,64,2]})")
    
    print("âœ… æ­£ç¡®æ–¹æ³•ç»“æžœ:")
    print(f"   è“è‰²åŒºåŸŸ RGB: ({correct_result[0,0,0]}, {correct_result[0,0,1]}, {correct_result[0,0,2]})")
    print(f"   é»„è‰²åŒºåŸŸ RGB: ({correct_result[64,64,0]}, {correct_result[64,64,1]}, {correct_result[64,64,2]})")
    
    # ä¿å­˜å¯¹æ¯”å›¾åƒ
    output_dir = Path("color_test_results")
    output_dir.mkdir(exist_ok=True)
    
    Image.fromarray(test_image).save(output_dir / "original.png")
    Image.fromarray(wrong_result).save(output_dir / "wrong_denorm.png")
    Image.fromarray(correct_result).save(output_dir / "correct_denorm.png")
    
    print(f"\nðŸ’¾ æµ‹è¯•å›¾åƒå·²ä¿å­˜åˆ° {output_dir}/")
    
    return np.array_equal(test_image, correct_result)

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ðŸ§ª å¼€å§‹é¢œè‰²ä¿®å¤æµ‹è¯•\n")
    
    # æµ‹è¯•1: VAEè¾“å‡ºèŒƒå›´
    vae_range = test_vae_output_range()
    
    # æµ‹è¯•2: é¢œè‰²è½¬æ¢
    color_correct = test_color_conversion()
    
    print("\nðŸ“‹ æµ‹è¯•æ€»ç»“:")
    print(f"   VAEè¾“å‡ºèŒƒå›´: {vae_range}")
    print(f"   é¢œè‰²è½¬æ¢æ­£ç¡®: {'âœ…' if color_correct else 'âŒ'}")
    
    if vae_range == "0_1" and color_correct:
        print("\nðŸŽ‰ ä¿®å¤éªŒè¯æˆåŠŸï¼")
        print("   - VAEè¾“å‡ºç¡®å®žåœ¨[0,1]èŒƒå›´")
        print("   - ç§»é™¤äº†é”™è¯¯çš„ (image / 2 + 0.5) è½¬æ¢")
        print("   - ç”Ÿæˆå›¾åƒçš„é¢œè‰²åº”è¯¥æ¢å¤æ­£å¸¸")
    else:
        print("\nâš ï¸ éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
        if vae_range == "-1_1":
            print("   - VAEè¾“å‡ºåœ¨[-1,1]èŒƒå›´ï¼Œå¯èƒ½éœ€è¦ä¿ç•™åŽŸæ¥çš„è½¬æ¢")
        if not color_correct:
            print("   - é¢œè‰²è½¬æ¢æµ‹è¯•å¤±è´¥")

if __name__ == "__main__":
    main()
