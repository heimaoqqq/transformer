#!/usr/bin/env python3
"""
å®‰å…¨ç‰ˆVAEè®­ç»ƒå¯åŠ¨å™¨
- 3å±‚ä¸‹é‡‡æ · (50%å‚æ•°å‡å°‘)
- ä¿å®ˆæ‰¹æ¬¡å¤§å° (é¿å…OOM)
- FP16æ··åˆç²¾åº¦
"""

import os
import sys
import subprocess
import torch
from pathlib import Path

def setup_safe_environment():
    """è®¾ç½®å®‰å…¨è®­ç»ƒç¯å¢ƒ"""
    # ä¿å®ˆå†…å­˜åˆ†é…
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
    
    # å¯ç”¨ä¼˜åŒ–
    os.environ['PYTHONUNBUFFERED'] = '1'
    os.environ['CUDA_LAUNCH_BLOCKING'] = '0'
    
    # å¯ç”¨cuDNNä¼˜åŒ–
    torch.backends.cudnn.benchmark = True

def launch_safe_training():
    """å¯åŠ¨å®‰å…¨è®­ç»ƒ"""
    
    setup_safe_environment()
    
    gpu_count = torch.cuda.device_count()
    print(f"ğŸ® æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    # æ˜¾ç¤ºGPUå†…å­˜ä¿¡æ¯
    if torch.cuda.is_available():
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            print(f"   GPU {i}: {props.name} - {props.total_memory / 1024**3:.1f} GB")
            
            # æ¸…ç†GPUç¼“å­˜
            torch.cuda.set_device(i)
            torch.cuda.empty_cache()
    
    if gpu_count > 1:
        print("ğŸš€ å¯åŠ¨å®‰å…¨åŒGPUè®­ç»ƒ...")
        
        # è®¾ç½®å¤šGPUç¯å¢ƒå˜é‡
        os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'
        os.environ['WORLD_SIZE'] = str(gpu_count)
        os.environ['MASTER_ADDR'] = 'localhost'
        os.environ['MASTER_PORT'] = '12355'
        
        cmd = [
            "accelerate", "launch",
            "--config_file", "accelerate_config.yaml",
            "--num_processes", str(gpu_count),
            "training/train_vae.py",
            "--data_dir", "/kaggle/input/dataset",
            "--output_dir", "/kaggle/working/outputs/vae",
            "--batch_size", "4",        # å®‰å…¨æ‰¹æ¬¡å¤§å°
            "--num_epochs", "30",       
            "--learning_rate", "0.00015", # é€‚ä¸­å­¦ä¹ ç‡
            "--mixed_precision", "fp16", 
            "--gradient_accumulation_steps", "2", # é€‚ä¸­æ¢¯åº¦ç´¯ç§¯
            "--kl_weight", "1e-6",
            "--perceptual_weight", "0.0",
            "--freq_weight", "0.05",
            "--resolution", "256",
            "--num_workers", "1",       # å•çº¿ç¨‹é¿å…ç«äº‰
            "--save_interval", "5",     
            "--log_interval", "2",      
            "--sample_interval", "100", 
            "--experiment_name", "kaggle_vae_safe"
        ]
        
        print(f"ğŸ“Š å®‰å…¨é…ç½®:")
        print(f"   ğŸ—ï¸  æ¶æ„: 3å±‚ä¸‹é‡‡æ · (256â†’128â†’64â†’32)")
        print(f"   ğŸ“¦ æ‰¹æ¬¡å¤§å°: 4 (æ¯GPU 2ä¸ª)")
        print(f"   ğŸ”¢ æ··åˆç²¾åº¦: FP16")
        print(f"   ğŸ§µ æ•°æ®çº¿ç¨‹: 1 (å®‰å…¨)")
        print(f"   âš¡ æ¢¯åº¦ç´¯ç§¯: 2")
        print(f"   ğŸ“ˆ å­¦ä¹ ç‡: 1.5e-4")
        print(f"   ğŸ’¾ é¢„æœŸå†…å­˜: ~8GB/GPU")
        
    else:
        print("ğŸš€ å¯åŠ¨å®‰å…¨å•GPUè®­ç»ƒ...")
        
        cmd = [
            "python", "-u",
            "training/train_vae.py",
            "--data_dir", "/kaggle/input/dataset",
            "--output_dir", "/kaggle/working/outputs/vae",
            "--batch_size", "2",        # å•GPUå°æ‰¹æ¬¡
            "--num_epochs", "30",
            "--learning_rate", "0.00015",
            "--mixed_precision", "fp16",
            "--gradient_accumulation_steps", "4",
            "--kl_weight", "1e-6",
            "--perceptual_weight", "0.0",
            "--freq_weight", "0.05",
            "--resolution", "256",
            "--num_workers", "1",
            "--save_interval", "5",
            "--log_interval", "2",
            "--sample_interval", "100",
            "--experiment_name", "kaggle_vae_safe"
        ]
        
        print(f"ğŸ“Š å®‰å…¨é…ç½®:")
        print(f"   ğŸ—ï¸  æ¶æ„: 3å±‚ä¸‹é‡‡æ ·")
        print(f"   ğŸ“¦ æ‰¹æ¬¡å¤§å°: 2")
        print(f"   ğŸ”¢ æ··åˆç²¾åº¦: FP16")
        print(f"   ğŸ§µ æ•°æ®çº¿ç¨‹: 1")
        print(f"   ğŸ’¾ é¢„æœŸå†…å­˜: ~6GB")
    
    print(f"\nCommand: {' '.join(cmd)}")
    print("=" * 80)
    
    try:
        # å¯åŠ¨è®­ç»ƒ
        process = subprocess.Popen(
            cmd,
            stdout=None,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=0
        )
        
        return_code = process.wait()
        
        if return_code == 0:
            print("\nâœ… å®‰å…¨è®­ç»ƒå®Œæˆ!")
            return True
        else:
            print(f"\nâŒ è®­ç»ƒå¤±è´¥ (é€€å‡ºç : {return_code})")
            return False
            
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        process.terminate()
        return False
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¯åŠ¨å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ›¡ï¸  å®‰å…¨ç‰ˆVAEè®­ç»ƒ (3å±‚ä¸‹é‡‡æ ·)")
    print("=" * 50)
    
    print("ğŸ¯ å®‰å…¨ä¼˜åŒ–:")
    print("   âœ… 3å±‚ä¸‹é‡‡æ · â†’ 50%å‚æ•°å‡å°‘")
    print("   âœ… FP16æ··åˆç²¾åº¦ â†’ å†…å­˜èŠ‚çœ")
    print("   âœ… ä¿å®ˆæ‰¹æ¬¡å¤§å° â†’ é¿å…OOM")
    print("   âœ… å•çº¿ç¨‹æ•°æ®åŠ è½½ â†’ ç¨³å®šæ€§")
    print("   âœ… é€‚ä¸­æ¢¯åº¦ç´¯ç§¯ â†’ å¹³è¡¡æ•ˆç‡")
    
    print("\nğŸ“Š é¢„æœŸæ•ˆæœ:")
    print("   ğŸš€ è®­ç»ƒé€Ÿåº¦: +50-100% (vs 4å±‚)")
    print("   â±ï¸  æ¯è½®æ—¶é—´: 30åˆ†é’Ÿâ†’15-20åˆ†é’Ÿ")
    print("   ğŸ’¾ å†…å­˜ä½¿ç”¨: ~8GB (vs 14GB)")
    print("   ğŸ›¡ï¸  ç¨³å®šæ€§: é«˜ (ä¸ä¼šOOM)")
    print("   ğŸ¯ è´¨é‡: ä¿æŒ (256Ã—256)")
    
    print("\nğŸ—ï¸  æ¶æ„ä¼˜åŠ¿:")
    print("   ğŸ“‰ å‚æ•°é‡: 83M â†’ 40M (å‡åŠ)")
    print("   âš¡ è®¡ç®—é‡: å‡å°‘50%")
    print("   ğŸ¯ å‹ç¼©æ¯”: ä¿æŒ64:1")
    print("   ğŸ“ æ½œåœ¨ç©ºé—´: 32Ã—32Ã—4")
    
    success = launch_safe_training()
    
    if success:
        print("\nğŸ‰ å®‰å…¨è®­ç»ƒå®Œæˆ!")
        print("ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: /kaggle/working/outputs/vae/final_model")
    else:
        print("\nâŒ è®­ç»ƒå¤±è´¥!")
        print("ğŸ’¡ å¦‚æœè¿˜æœ‰é—®é¢˜ï¼Œå¯ä»¥:")
        print("   - è¿›ä¸€æ­¥å‡å°‘batch_sizeåˆ°2")
        print("   - é™ä½åˆ†è¾¨ç‡åˆ°128")
        sys.exit(1)

if __name__ == "__main__":
    main()
