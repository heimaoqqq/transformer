#!/usr/bin/env python3
"""
æµ‹è¯•128Ã—128 â†’ 32Ã—32é…ç½®
éªŒè¯æ¶æ„ã€æ˜¾å­˜ä½¿ç”¨å’Œæ•°æ®åŠ è½½
"""

import torch
import numpy as np
from pathlib import Path
from diffusers import AutoencoderKL
from utils.data_loader import MicroDopplerDataset
from torch.utils.data import DataLoader
import time

def test_new_architecture():
    """æµ‹è¯•æ–°æ¶æ„é…ç½®"""
    print("ğŸ§ª æµ‹è¯•128Ã—128 â†’ 32Ã—32ç°ä»£åŒ–é…ç½®")
    print("=" * 60)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    if not torch.cuda.is_available():
        print("âŒ éœ€è¦CUDAæ”¯æŒè¿›è¡Œæµ‹è¯•")
        return False
    
    gpu_props = torch.cuda.get_device_properties(0)
    gpu_memory = gpu_props.total_memory / 1024**3
    print(f"ğŸ® GPU: {gpu_props.name} ({gpu_memory:.1f}GB)")
    
    # æµ‹è¯•æ•°æ®åŠ è½½å™¨
    print(f"\nğŸ“Š æµ‹è¯•æ•°æ®åŠ è½½å™¨ (128Ã—128 + Lanczos):")
    try:
        dataset = MicroDopplerDataset(
            data_dir="/kaggle/input/dataset",
            resolution=128,  # æ–°çš„åˆ†è¾¨ç‡
            augment=False,
            split="test"
        )
        
        # æµ‹è¯•å•ä¸ªæ ·æœ¬
        sample = dataset[0]
        print(f"   âœ… æ ·æœ¬å½¢çŠ¶: {sample['image'].shape}")
        print(f"   âœ… æ•°æ®ç±»å‹: {sample['image'].dtype}")
        print(f"   âœ… æ•°å€¼èŒƒå›´: [{sample['image'].min():.3f}, {sample['image'].max():.3f}]")
        
    except Exception as e:
        print(f"   âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•VAEæ¶æ„
    print(f"\nğŸ—ï¸  æµ‹è¯•VAEæ¶æ„ (128Ã—128 â†’ 32Ã—32):")
    try:
        # æ–°æ¶æ„é…ç½® (2å±‚ä¸‹é‡‡æ ·: 128â†’64â†’32)
        vae = AutoencoderKL(
            in_channels=3,
            out_channels=3,
            down_block_types=["DownEncoderBlock2D", "DownEncoderBlock2D"],  # 2å±‚
            up_block_types=["UpDecoderBlock2D", "UpDecoderBlock2D"],        # 2å±‚
            block_out_channels=[128, 256],                                   # 2å±‚é€šé“æ•°
            latent_channels=4,
            sample_size=128,                                                 # ä¿®å¤: è®¾ç½®ä¸º128åŒ¹é…è¾“å…¥å°ºå¯¸
            layers_per_block=1,                                              # æ ‡å‡†é…ç½®
            act_fn="silu",
            norm_num_groups=32,
            scaling_factor=0.18215,
        ).to(device)
        
        # è®¡ç®—å‚æ•°é‡
        total_params = sum(p.numel() for p in vae.parameters())
        trainable_params = sum(p.numel() for p in vae.parameters() if p.requires_grad)
        
        print(f"   âœ… æ€»å‚æ•°: {total_params:,}")
        print(f"   âœ… å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_input = torch.randn(1, 3, 128, 128).to(device)
        
        with torch.no_grad():
            # ç¼–ç 
            latent_dist = vae.encode(test_input).latent_dist
            latent = latent_dist.sample()
            print(f"   âœ… æ½œåœ¨ç©ºé—´å½¢çŠ¶: {latent.shape}")
            
            # è§£ç 
            reconstructed = vae.decode(latent).sample
            print(f"   âœ… é‡å»ºå½¢çŠ¶: {reconstructed.shape}")
            
            # éªŒè¯å½¢çŠ¶
            expected_latent_shape = (1, 4, 32, 32)
            expected_output_shape = (1, 3, 128, 128)
            
            if latent.shape == expected_latent_shape:
                print(f"   âœ… æ½œåœ¨ç©ºé—´å½¢çŠ¶æ­£ç¡®: {latent.shape}")
            else:
                print(f"   âŒ æ½œåœ¨ç©ºé—´å½¢çŠ¶é”™è¯¯: {latent.shape}, æœŸæœ›: {expected_latent_shape}")
                return False
                
            if reconstructed.shape == expected_output_shape:
                print(f"   âœ… é‡å»ºå½¢çŠ¶æ­£ç¡®: {reconstructed.shape}")
            else:
                print(f"   âŒ é‡å»ºå½¢çŠ¶é”™è¯¯: {reconstructed.shape}, æœŸæœ›: {expected_output_shape}")
                return False
        
    except Exception as e:
        print(f"   âŒ VAEæ¶æ„æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•æ˜¾å­˜ä½¿ç”¨
    print(f"\nğŸ’¾ æµ‹è¯•æ˜¾å­˜ä½¿ç”¨:")
    try:
        torch.cuda.empty_cache()
        initial_memory = torch.cuda.memory_allocated() / 1024**2
        
        # æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°
        batch_sizes = [2, 4, 6, 8]
        max_batch = 0
        
        for batch_size in batch_sizes:
            try:
                torch.cuda.empty_cache()
                test_batch = torch.randn(batch_size, 3, 128, 128).to(device)
                
                with torch.no_grad():
                    latent = vae.encode(test_batch).latent_dist.sample()
                    reconstructed = vae.decode(latent).sample
                
                current_memory = torch.cuda.memory_allocated() / 1024**2
                memory_used = current_memory - initial_memory
                
                print(f"   âœ… æ‰¹æ¬¡{batch_size}: {memory_used:.0f}MB")
                max_batch = batch_size
                
                del test_batch, latent, reconstructed
                torch.cuda.empty_cache()
                
            except RuntimeError as e:
                if "out of memory" in str(e):
                    print(f"   âš ï¸  æ‰¹æ¬¡{batch_size}: æ˜¾å­˜ä¸è¶³")
                    break
                else:
                    raise e
        
        print(f"   ğŸ“Š æ¨èæœ€å¤§æ‰¹æ¬¡: {max_batch}")
        
    except Exception as e:
        print(f"   âŒ æ˜¾å­˜æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•æ•°æ®åŠ è½½å™¨æ€§èƒ½
    print(f"\nâ±ï¸  æµ‹è¯•æ•°æ®åŠ è½½æ€§èƒ½:")
    try:
        dataloader = DataLoader(
            dataset,
            batch_size=4,
            shuffle=False,
            num_workers=2,
            pin_memory=True
        )
        
        start_time = time.time()
        for i, batch in enumerate(dataloader):
            if i >= 5:  # åªæµ‹è¯•5ä¸ªæ‰¹æ¬¡
                break
        
        elapsed = time.time() - start_time
        print(f"   âœ… 5ä¸ªæ‰¹æ¬¡åŠ è½½æ—¶é—´: {elapsed:.2f}ç§’")
        print(f"   âœ… å¹³å‡æ¯æ‰¹æ¬¡: {elapsed/5:.2f}ç§’")
        
    except Exception as e:
        print(f"   âŒ æ•°æ®åŠ è½½æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # è®¡ç®—æ”¹è¿›æŒ‡æ ‡
    print(f"\nğŸ“ˆ é…ç½®å¯¹æ¯”:")
    print(f"   æ—§é…ç½® (64Ã—64 â†’ 8Ã—8):")
    print(f"     - è¾“å…¥: 64Ã—64Ã—3 = 12,288 åƒç´ ")
    print(f"     - æ½œåœ¨: 8Ã—8Ã—4 = 256 ç»´åº¦")
    print(f"     - å‹ç¼©æ¯”: 48:1")
    print(f"     - é€šé“: [64, 128, 256]")
    
    print(f"   æ–°é…ç½® (128Ã—128 â†’ 32Ã—32):")
    print(f"     - è¾“å…¥: 128Ã—128Ã—3 = 49,152 åƒç´ ")
    print(f"     - æ½œåœ¨: 32Ã—32Ã—4 = 4,096 ç»´åº¦")
    print(f"     - å‹ç¼©æ¯”: 12:1")
    print(f"     - é€šé“: [128, 256]")
    
    print(f"   æ”¹è¿›:")
    print(f"     - è¾“å…¥åˆ†è¾¨ç‡: 4å€æå‡")
    print(f"     - ä¿¡æ¯å®¹é‡: 16å€æå‡")
    print(f"     - å‹ç¼©æ¯”: 4å€é™ä½ (æ›´å¥½)")
    print(f"     - ç¼©æ”¾è´¨é‡: Lanczos (æœ€ä½³)")
    print(f"     - å…³é”®ä¿®å¤: sample_size=128 (åŒ¹é…è¾“å…¥å°ºå¯¸ï¼Œç¡®ä¿æ­£ç¡®ä¸‹é‡‡æ ·)")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ 128Ã—128 â†’ 32Ã—32 ç°ä»£åŒ–é…ç½®æµ‹è¯•")
    
    success = test_new_architecture()
    
    if success:
        print(f"\nğŸ‰ é…ç½®æµ‹è¯•é€šè¿‡!")
        print(f"âœ… å¯ä»¥å¼€å§‹è®­ç»ƒ: python train_improved_quality.py")
        print(f"ğŸ“Š é¢„æœŸPSNR: 28+ dB (vs ä¹‹å‰21.78 dB)")
    else:
        print(f"\nâŒ é…ç½®æµ‹è¯•å¤±è´¥!")
        print(f"ğŸ”§ è¯·æ£€æŸ¥GPUå†…å­˜å’Œæ•°æ®è·¯å¾„")

if __name__ == "__main__":
    main()
