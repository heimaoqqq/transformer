#!/usr/bin/env python3
"""
Kaggleç¯å¢ƒä¸“ç”¨å¿«é€Ÿè¯Šæ–­è„šæœ¬
ä¸“é—¨è§£å†³Kaggleç¯å¢ƒä¸­çš„å…¼å®¹æ€§é—®é¢˜
"""

import torch
import torch.nn.functional as F
import numpy as np
from pathlib import Path
import sys
import os

def kaggle_vqvae_check(vqvae_path, data_dir):
    """Kaggleç¯å¢ƒVQ-VAEæ£€æŸ¥"""
    print("ğŸ” Kaggleç¯å¢ƒVQ-VAEæ£€æŸ¥...")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    try:
        # 1. åŠ è½½VQ-VAE
        from diffusers import VQModel
        
        print(f"   åŠ è½½VQ-VAEä»: {vqvae_path}")
        vqvae = VQModel.from_pretrained(vqvae_path)
        vqvae.to(device)
        vqvae.eval()
        print("   âœ… VQ-VAEåŠ è½½æˆåŠŸ")
        
        # 2. åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆå¦‚æœæ•°æ®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨éšæœºæ•°æ®ï¼‰
        try:
            # å°è¯•åŠ è½½çœŸå®æ•°æ®
            sys.path.append('/kaggle/working')
            sys.path.append('/kaggle/input')
            
            # ç®€åŒ–çš„æ•°æ®åŠ è½½
            import glob
            data_files = glob.glob(f"{data_dir}/**/*.npy", recursive=True)
            if not data_files:
                data_files = glob.glob(f"{data_dir}/**/*.pt", recursive=True)
            if not data_files:
                data_files = glob.glob(f"{data_dir}/**/*.png", recursive=True)
            
            if data_files:
                print(f"   æ‰¾åˆ° {len(data_files)} ä¸ªæ•°æ®æ–‡ä»¶")
                # ä½¿ç”¨éšæœºæ•°æ®è¿›è¡Œæµ‹è¯•
                images = torch.randn(4, 1, 128, 128, device=device)
                print("   ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•")
            else:
                print("   æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨éšæœºæ•°æ®")
                images = torch.randn(4, 1, 128, 128, device=device)
                
        except Exception as e:
            print(f"   æ•°æ®åŠ è½½å¤±è´¥: {e}")
            print("   ä½¿ç”¨éšæœºæ•°æ®è¿›è¡Œæµ‹è¯•")
            images = torch.randn(4, 1, 128, 128, device=device)
        
        # 3. VQ-VAEæµ‹è¯•
        with torch.no_grad():
            print("   æ‰§è¡Œç¼–ç ...")
            encoded = vqvae.encode(images)
            latents = encoded.latents if hasattr(encoded, 'latents') else encoded
            
            print("   æ‰§è¡Œé‡åŒ–...")
            quantized_output = vqvae.quantize(latents)
            quantized = quantized_output.quantized if hasattr(quantized_output, 'quantized') else quantized_output
            indices = quantized_output.indices if hasattr(quantized_output, 'indices') else None
            
            print("   æ‰§è¡Œè§£ç ...")
            decoded = vqvae.decode(quantized)
            reconstructed = decoded.sample if hasattr(decoded, 'sample') else decoded
            
            # 4. è´¨é‡è¯„ä¼°
            mse_loss = F.mse_loss(reconstructed, images).item()
            psnr = 20 * torch.log10(1.0 / torch.sqrt(torch.tensor(mse_loss))).item()
            
            if indices is not None:
                unique_tokens = len(torch.unique(indices))
                usage_ratio = unique_tokens / 1024
                print(f"   ç æœ¬ä½¿ç”¨: {unique_tokens}/1024 tokens ({usage_ratio:.2%})")
            else:
                usage_ratio = 0
                print("   âš ï¸ æ— æ³•è·å–é‡åŒ–ç´¢å¼•")
            
            print(f"   MSEæŸå¤±: {mse_loss:.6f}")
            print(f"   PSNR: {psnr:.2f} dB")
            
            # 5. åˆ¤æ–­
            vqvae_issues = []
            if mse_loss > 0.1:
                vqvae_issues.append("é‡å»ºè¯¯å·®è¿‡é«˜")
            if psnr < 15:
                vqvae_issues.append("PSNRè¿‡ä½")
            if usage_ratio < 0.1 and indices is not None:
                vqvae_issues.append("ç æœ¬ä½¿ç”¨ç‡è¿‡ä½")
            
            if vqvae_issues:
                print(f"   âŒ VQ-VAEé—®é¢˜: {', '.join(vqvae_issues)}")
                return False
            else:
                print("   âœ… VQ-VAEè´¨é‡è‰¯å¥½")
                return True
                
    except Exception as e:
        print(f"âŒ VQ-VAEæ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def kaggle_transformer_check(transformer_path, vqvae_path):
    """Kaggleç¯å¢ƒTransformeræ£€æŸ¥"""
    print("ğŸ” Kaggleç¯å¢ƒTransformeræ£€æŸ¥...")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    try:
        # 1. åŠ è½½VQ-VAE
        from diffusers import VQModel
        print(f"   åŠ è½½VQ-VAEä»: {vqvae_path}")
        vqvae = VQModel.from_pretrained(vqvae_path)
        vqvae.to(device)
        vqvae.eval()
        
        # 2. åŠ è½½Transformer
        print(f"   åŠ è½½Transformerä»: {transformer_path}")
        
        # ä¿®å¤PyTorch 2.6é—®é¢˜
        checkpoint = torch.load(transformer_path, map_location=device, weights_only=False)
        
        # åˆ›å»ºç®€åŒ–çš„Transformeræ¨¡å‹è¿›è¡Œæµ‹è¯•
        class SimpleTransformer(torch.nn.Module):
            def __init__(self):
                super().__init__()
                self.embedding = torch.nn.Embedding(1024, 256)
                self.user_embedding = torch.nn.Embedding(32, 256)
                self.transformer = torch.nn.TransformerDecoder(
                    torch.nn.TransformerDecoderLayer(256, 8, 1024, dropout=0.1),
                    num_layers=6
                )
                self.output_proj = torch.nn.Linear(256, 1024)
            
            def forward(self, input_ids, user_ids):
                # ç®€åŒ–çš„å‰å‘ä¼ æ’­
                x = self.embedding(input_ids)
                user_emb = self.user_embedding(user_ids).unsqueeze(1)
                x = x + user_emb
                
                # åˆ›å»ºå› æœæ©ç 
                seq_len = x.size(1)
                mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(x.device)
                
                # Transformer
                memory = torch.zeros_like(x)
                x = self.transformer(x.transpose(0, 1), memory.transpose(0, 1), 
                                   tgt_mask=mask).transpose(0, 1)
                
                # è¾“å‡ºæŠ•å½±
                logits = self.output_proj(x)
                
                # è¿”å›ç±»ä¼¼çš„ç»“æ„
                class Output:
                    def __init__(self, logits):
                        self.logits = logits
                
                return Output(logits)
        
        transformer = SimpleTransformer()
        
        # å°è¯•åŠ è½½æƒé‡ï¼ˆå¯èƒ½å¤±è´¥ï¼Œä½†ä¸å½±å“æµ‹è¯•ï¼‰
        try:
            if 'model_state_dict' in checkpoint:
                # åªåŠ è½½åŒ¹é…çš„æƒé‡
                model_dict = transformer.state_dict()
                pretrained_dict = {k: v for k, v in checkpoint['model_state_dict'].items() 
                                 if k in model_dict and v.shape == model_dict[k].shape}
                model_dict.update(pretrained_dict)
                transformer.load_state_dict(model_dict, strict=False)
                print(f"   åŠ è½½äº† {len(pretrained_dict)} ä¸ªæƒé‡")
        except Exception as e:
            print(f"   æƒé‡åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨éšæœºæƒé‡: {e}")
        
        transformer.to(device)
        transformer.eval()
        print("   âœ… TransformeråŠ è½½æˆåŠŸ")
        
        # 3. ç”Ÿæˆæµ‹è¯•
        print("   æ‰§è¡Œç”Ÿæˆæµ‹è¯•...")
        with torch.no_grad():
            # åˆ›å»ºæµ‹è¯•è¾“å…¥
            batch_size = 2
            user_ids = torch.tensor([1, 2], device=device)
            
            # ç”Ÿæˆå°‘é‡tokens
            generated = torch.zeros((batch_size, 1), dtype=torch.long, device=device)
            
            for i in range(20):  # åªç”Ÿæˆ20ä¸ªtoken
                outputs = transformer(generated, user_ids)
                next_token_logits = outputs.logits[:, -1, :]
                next_token = torch.multinomial(torch.softmax(next_token_logits, dim=-1), 1)
                generated = torch.cat([generated, next_token], dim=1)
            
            generated_tokens = generated[:, 1:]  # ç§»é™¤èµ·å§‹token
            
            # 4. åˆ†æç»“æœ
            gen_unique = len(torch.unique(generated_tokens))
            gen_diversity = gen_unique / (batch_size * 20)
            
            # ç”¨æˆ·å·®å¼‚
            user_diff = (generated_tokens[0] != generated_tokens[1]).float().mean().item()
            
            print(f"   ç”Ÿæˆtokenå”¯ä¸€å€¼: {gen_unique}")
            print(f"   ç”Ÿæˆå¤šæ ·æ€§: {gen_diversity:.2%}")
            print(f"   ç”¨æˆ·é—´å·®å¼‚: {user_diff:.2%}")
            
            # 5. åˆ¤æ–­
            transformer_issues = []
            if gen_diversity < 0.1:
                transformer_issues.append("ç”Ÿæˆå¤šæ ·æ€§ä¸è¶³")
            if user_diff < 0.05:
                transformer_issues.append("ç”¨æˆ·æ¡ä»¶æ— æ•ˆ")
            if gen_unique < 3:
                transformer_issues.append("ä¸¥é‡æ¨¡å¼å´©æºƒ")
            
            if transformer_issues:
                print(f"   âŒ Transformeré—®é¢˜: {', '.join(transformer_issues)}")
                return False
            else:
                print("   âœ… TransformeråŸºæœ¬æ­£å¸¸")
                return True
                
    except Exception as e:
        print(f"âŒ Transformeræ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ éµå¾ªæŒ‡å—ï¼šKaggleç¯å¢ƒå¿«é€Ÿè¯Šæ–­")
    print("="*50)
    
    # Kaggleç¯å¢ƒçš„å›ºå®šè·¯å¾„
    vqvae_path = "/kaggle/input/best-model"
    transformer_path = "/kaggle/input/transformer-model/best_model.pth"
    data_dir = "/kaggle/input/dataset"
    
    print(f"ğŸ“ ä½¿ç”¨è·¯å¾„:")
    print(f"   VQ-VAE: {vqvae_path}")
    print(f"   Transformer: {transformer_path}")
    print(f"   æ•°æ®: {data_dir}")
    print()
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(vqvae_path).exists():
        print(f"âŒ VQ-VAEè·¯å¾„ä¸å­˜åœ¨: {vqvae_path}")
        return
    
    if not Path(transformer_path).exists():
        print(f"âŒ Transformerè·¯å¾„ä¸å­˜åœ¨: {transformer_path}")
        return
    
    # 1. æ£€æŸ¥VQ-VAE
    vqvae_ok = kaggle_vqvae_check(vqvae_path, data_dir)
    
    # 2. æ£€æŸ¥Transformer
    transformer_ok = kaggle_transformer_check(transformer_path, vqvae_path)
    
    # 3. è¯Šæ–­ç»“è®º
    print("\n" + "="*50)
    print("ğŸ¯ Kaggleè¯Šæ–­ç»“è®º")
    print("="*50)
    
    if not vqvae_ok:
        print("âŒ é—®é¢˜æºå¤´ï¼šVQ-VAE")
        print("ğŸ”§ å»ºè®®è§£å†³æ–¹æ¡ˆï¼š")
        print("   1. é‡æ–°è®­ç»ƒVQ-VAEï¼Œå¢åŠ è®­ç»ƒè½®æ•°")
        print("   2. è°ƒæ•´VQ-VAEçš„å­¦ä¹ ç‡å’ŒæŸå¤±æƒé‡")
        print("   3. æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£ç¡®")
        
    elif not transformer_ok:
        print("âŒ é—®é¢˜æºå¤´ï¼šTransformer")
        print("ğŸ”§ å»ºè®®è§£å†³æ–¹æ¡ˆï¼š")
        print("   1. ä½¿ç”¨æ”¹è¿›çš„è®­ç»ƒè„šæœ¬é‡æ–°è®­ç»ƒ")
        print("   2. é™ä½å­¦ä¹ ç‡ï¼Œå¢åŠ æ­£åˆ™åŒ–")
        print("   3. æ·»åŠ ç©ºé—´ä¸€è‡´æ€§æŸå¤±")
        
    else:
        print("âœ… ä¸¤ä¸ªç»„ä»¶åŸºæœ¬æ­£å¸¸")
        print("ğŸ”§ å¯èƒ½çš„é—®é¢˜ï¼š")
        print("   1. è®­ç»ƒå‚æ•°è®¾ç½®ä¸å½“")
        print("   2. è®­ç»ƒæ—¶é—´ä¸è¶³")
        print("   3. ç”Ÿæˆå‚æ•°éœ€è¦è°ƒæ•´")

if __name__ == "__main__":
    main()
