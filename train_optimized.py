#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆVAEè®­ç»ƒå¯åŠ¨å™¨
é’ˆå¯¹é€Ÿåº¦å’Œæ•ˆç‡ä¼˜åŒ–
"""

import os
import sys
import subprocess
import torch
from pathlib import Path

def setup_optimized_environment():
    """è®¾ç½®ä¼˜åŒ–ç¯å¢ƒ"""
    # ä¼˜åŒ–å†…å­˜åˆ†é…
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'
    
    # å¯ç”¨ä¼˜åŒ–
    os.environ['PYTHONUNBUFFERED'] = '1'
    os.environ['CUDA_LAUNCH_BLOCKING'] = '0'
    
    # å¯ç”¨cuDNNä¼˜åŒ–
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False

def launch_optimized_training():
    """å¯åŠ¨ä¼˜åŒ–è®­ç»ƒ"""
    
    setup_optimized_environment()
    
    gpu_count = torch.cuda.device_count()
    print(f"ğŸ® æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    # æ˜¾ç¤ºGPUå†…å­˜ä¿¡æ¯
    if torch.cuda.is_available():
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            print(f"   GPU {i}: {props.name} - {props.total_memory / 1024**3:.1f} GB")
            
            # æ¸…ç†GPUç¼“å­˜
            torch.cuda.set_device(i)
            torch.cuda.empty_cache()
    
    if gpu_count > 1:
        print("ğŸš€ å¯åŠ¨ä¼˜åŒ–åŒGPUè®­ç»ƒ...")
        
        # è®¾ç½®å¤šGPUç¯å¢ƒå˜é‡
        os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'
        os.environ['WORLD_SIZE'] = str(gpu_count)
        os.environ['MASTER_ADDR'] = 'localhost'
        os.environ['MASTER_PORT'] = '12355'
        
        cmd = [
            "accelerate", "launch",
            "--config_file", "accelerate_config.yaml",
            "--num_processes", str(gpu_count),
            "training/train_vae.py",
            "--data_dir", "/kaggle/input/dataset",
            "--output_dir", "/kaggle/working/outputs/vae",
            "--batch_size", "8",        # å¢åŠ æ‰¹æ¬¡å¤§å°
            "--num_epochs", "30",       # å‡å°‘epochæ•°
            "--learning_rate", "0.0002", # ç¨å¾®æé«˜å­¦ä¹ ç‡
            "--mixed_precision", "fp16",
            "--gradient_accumulation_steps", "2", # å‡å°‘æ¢¯åº¦ç´¯ç§¯
            "--kl_weight", "1e-6",
            "--perceptual_weight", "0.0",
            "--freq_weight", "0.05",
            "--resolution", "256",
            "--num_workers", "2",       # å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹
            "--save_interval", "5",     # æ›´é¢‘ç¹ä¿å­˜
            "--log_interval", "2",      # æ›´é¢‘ç¹æ—¥å¿—
            "--sample_interval", "50",  # æ›´é¢‘ç¹é‡‡æ ·
            "--experiment_name", "kaggle_vae_optimized"
        ]
        
        print(f"ğŸ“Š ä¼˜åŒ–é…ç½®:")
        print(f"   æ‰¹æ¬¡å¤§å°: 8 (æ¯GPU 4ä¸ª)")
        print(f"   åˆ†è¾¨ç‡: 256Ã—256")
        print(f"   å‹ç¼©: 256â†’32 (8å€ä¸‹é‡‡æ ·)")
        print(f"   æ•°æ®çº¿ç¨‹: 2")
        print(f"   æ··åˆç²¾åº¦: FP16")
        
    else:
        print("ğŸš€ å¯åŠ¨ä¼˜åŒ–å•GPUè®­ç»ƒ...")
        
        cmd = [
            "python", "-u",
            "training/train_vae.py",
            "--data_dir", "/kaggle/input/dataset",
            "--output_dir", "/kaggle/working/outputs/vae",
            "--batch_size", "6",        # å•GPUæ›´å¤§æ‰¹æ¬¡
            "--num_epochs", "30",
            "--learning_rate", "0.0002",
            "--mixed_precision", "fp16",
            "--gradient_accumulation_steps", "3",
            "--kl_weight", "1e-6",
            "--perceptual_weight", "0.0",
            "--freq_weight", "0.05",
            "--resolution", "256",
            "--num_workers", "2",
            "--save_interval", "5",
            "--log_interval", "2",
            "--sample_interval", "50",
            "--experiment_name", "kaggle_vae_optimized"
        ]
        
        print(f"ğŸ“Š ä¼˜åŒ–é…ç½®:")
        print(f"   æ‰¹æ¬¡å¤§å°: 6")
        print(f"   åˆ†è¾¨ç‡: 256Ã—256")
        print(f"   æ•°æ®çº¿ç¨‹: 2")
    
    print(f"\nCommand: {' '.join(cmd)}")
    print("=" * 80)
    
    try:
        # å¯åŠ¨è®­ç»ƒ
        process = subprocess.Popen(
            cmd,
            stdout=None,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=0
        )
        
        return_code = process.wait()
        
        if return_code == 0:
            print("\nâœ… ä¼˜åŒ–è®­ç»ƒå®Œæˆ!")
            return True
        else:
            print(f"\nâŒ è®­ç»ƒå¤±è´¥ (é€€å‡ºç : {return_code})")
            return False
            
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        process.terminate()
        return False
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¯åŠ¨å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¼˜åŒ–ç‰ˆVAEè®­ç»ƒ")
    print("=" * 50)
    
    print("ğŸ¯ ä¼˜åŒ–é‡ç‚¹:")
    print("   âœ… å¢åŠ æ‰¹æ¬¡å¤§å° (4â†’8)")
    print("   âœ… å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹ (1â†’2)")
    print("   âœ… å¯ç”¨cuDNNä¼˜åŒ–")
    print("   âœ… ä¼˜åŒ–å†…å­˜åˆ†é…")
    print("   âœ… å‡å°‘epochæ•° (40â†’30)")
    print("   âœ… æé«˜å­¦ä¹ ç‡ (1e-4â†’2e-4)")
    
    print("\nğŸ“Š é¢„æœŸæ”¹è¿›:")
    print("   ğŸš€ è®­ç»ƒé€Ÿåº¦: +50-80%")
    print("   â±ï¸  æ¯è½®æ—¶é—´: 30åˆ†é’Ÿâ†’15-20åˆ†é’Ÿ")
    print("   ğŸ’¾ å†…å­˜ä½¿ç”¨: ~12-14GB")
    
    success = launch_optimized_training()
    
    if success:
        print("\nğŸ‰ ä¼˜åŒ–è®­ç»ƒå®Œæˆ!")
        print("ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: /kaggle/working/outputs/vae/final_model")
    else:
        print("\nâŒ è®­ç»ƒå¤±è´¥!")
        print("ğŸ’¡ å¦‚æœå†…å­˜ä¸è¶³ï¼Œå¯ä»¥:")
        print("   - å‡å°‘batch_sizeåˆ°6")
        print("   - å‡å°‘num_workersåˆ°1")
        print("   - ä½¿ç”¨train_high_res.py")
        sys.exit(1)

if __name__ == "__main__":
    main()
