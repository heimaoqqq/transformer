#!/usr/bin/env python3
"""
CelebAæ ‡å‡†å¾®å¤šæ™®å‹’VAEè®­ç»ƒå™¨
é‡‡ç”¨64Ã—64åˆ†è¾¨ç‡ï¼Œéµå¾ªæˆç†Ÿé¡¹ç›®çš„æ ‡å‡†åšæ³•
"""

import os
import sys
import subprocess
import torch
from pathlib import Path

def setup_celeba_environment():
    """è®¾ç½®CelebAæ ‡å‡†ç¯å¢ƒ"""
    # å¼ºåˆ¶å•GPU (CelebAæ ‡å‡†é€šå¸¸å•GPUè®­ç»ƒ)
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    
    # ä¼˜åŒ–å†…å­˜åˆ†é…
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'
    os.environ['PYTHONUNBUFFERED'] = '1'
    
    # åŸºç¡€ä¼˜åŒ–
    torch.backends.cudnn.benchmark = True

def get_celeba_standard_config():
    """è·å–é…ç½® - é’ˆå¯¹å°æ•°æ®é›†ä¼˜åŒ–"""

    if not torch.cuda.is_available():
        print("âŒ éœ€è¦CUDAæ”¯æŒ")
        return None

    gpu_name = torch.cuda.get_device_properties(0).name
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3

    print(f"ğŸ® GPU: {gpu_name} ({gpu_memory:.1f}GB)")

    # å°æ•°æ®é›†ä¼˜åŒ–é…ç½® (5000å¼ å›¾åƒ)
    if "P100" in gpu_name or gpu_memory > 14:
        return {
            "batch_size": 16,           # é€‚åˆå°æ•°æ®é›†
            "mixed_precision": "no",
            "learning_rate": "0.0001",
            "gradient_accumulation": 1,
            "num_workers": 2,
        }
    elif "T4" in gpu_name or gpu_memory > 10:
        return {
            "batch_size": 12,           # T4é€‚ä¸­æ‰¹æ¬¡
            "mixed_precision": "fp16",
            "learning_rate": "0.0001",
            "gradient_accumulation": 2,
            "num_workers": 2,
        }
    else:
        return {
            "batch_size": 8,            # ä¿å®ˆæ‰¹æ¬¡
            "mixed_precision": "fp16",
            "learning_rate": "0.0001",
            "gradient_accumulation": 2,
            "num_workers": 1,
        }

def launch_celeba_training():
    """å¯åŠ¨CelebAæ ‡å‡†è®­ç»ƒ"""
    
    setup_celeba_environment()
    
    # è·å–é…ç½®
    config = get_celeba_standard_config()
    if config is None:
        return False
    
    # æ¸…ç†GPUç¼“å­˜
    torch.cuda.empty_cache()

    print(f"\nğŸš€ å¯åŠ¨VAEè®­ç»ƒ (æ‰¹æ¬¡:{config['batch_size']}, ç²¾åº¦:{config['mixed_precision']})")
    
    cmd = [
        "python", "-u",
        "training/train_vae.py",
        "--data_dir", "/kaggle/input/dataset",
        "--output_dir", "/kaggle/working/outputs/vae_celeba_standard",
        "--batch_size", str(config["batch_size"]),
        "--num_epochs", "80",  # å¢åŠ è®­ç»ƒè½®æ•°ï¼Œé…åˆä½å­¦ä¹ ç‡
        "--learning_rate", config["learning_rate"],
        "--mixed_precision", config["mixed_precision"],
        "--gradient_accumulation_steps", str(config["gradient_accumulation"]),
        "--kl_weight", "1e-6",  # é™ä½KLæƒé‡ï¼Œé¿å…è¿‡åº¦æ­£åˆ™åŒ–
        "--perceptual_weight", "0.1",  # é™ä½æ„ŸçŸ¥æŸå¤±æƒé‡ï¼Œé¿å…è®¾å¤‡é—®é¢˜
        "--freq_weight", "0.05",  # å¾®å¤šæ™®å‹’ç‰¹æœ‰
        "--resolution", "64",  # CelebAæ ‡å‡†åˆ†è¾¨ç‡
        "--num_workers", str(config["num_workers"]),
        "--save_interval", "5",
        "--log_interval", "2",
        "--sample_interval", "50",
        "--experiment_name", "micro_doppler_celeba_standard"
    ]
    
    print(f"ğŸ“Š CelebAæ ‡å‡†é…ç½®:")
    # æœ‰æ•ˆæ‰¹æ¬¡å¤§å°
    effective_batch = config["batch_size"] * config["gradient_accumulation"]
    print(f"ğŸ“Š é…ç½®: æ‰¹æ¬¡{config['batch_size']} Ã— ç´¯ç§¯{config['gradient_accumulation']} = æœ‰æ•ˆæ‰¹æ¬¡{effective_batch}")
    print(f"âš™ï¸  å‚æ•°: å­¦ä¹ ç‡{config['learning_rate']}, ç²¾åº¦{config['mixed_precision']}, çº¿ç¨‹{config['num_workers']}")
    print(f"ğŸ¯ ç›®æ ‡: 64Ã—64â†’8Ã—8Ã—4, å‹ç¼©æ¯”48:1, PSNR>25dB")
    
    try:
        # å¯åŠ¨è®­ç»ƒ
        process = subprocess.Popen(
            cmd,
            stdout=None,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=0
        )
        
        return_code = process.wait()
        
        if return_code == 0:
            print(f"\nâœ… VAEè®­ç»ƒå®Œæˆ!")
            return True
        else:
            print(f"\nâŒ è®­ç»ƒå¤±è´¥ (é€€å‡ºç : {return_code})")
            return False

    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        process.terminate()
        return False
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¯åŠ¨å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ å¾®å¤šæ™®å‹’VAEè®­ç»ƒ (å°æ•°æ®é›†ä¼˜åŒ–)")

    print("ğŸ“Š æ•°æ®é›†: ~5000å¼ å›¾åƒ, 31ç”¨æˆ·")
    print("ğŸ¯ ç›®æ ‡: 64Ã—64â†’8Ã—8Ã—4, PSNR>25dB")

    success = launch_celeba_training()

    if success:
        print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print("ğŸ“ æ¨¡å‹: /kaggle/working/outputs/vae_celeba_standard/final_model")
        print("ï¿½ æ£€æŸ¥è´¨é‡: python check_vae.py")
    else:
        print("\nâŒ è®­ç»ƒå¤±è´¥! è¯·æ£€æŸ¥GPUå†…å­˜å’Œæ•°æ®è·¯å¾„")
        sys.exit(1)

if __name__ == "__main__":
    main()
