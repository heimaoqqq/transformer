#!/usr/bin/env python3
"""
ç»Ÿä¸€ç¯å¢ƒæµ‹è¯•è„šæœ¬
éªŒè¯VQ-VAE + Transformerç»Ÿä¸€ç¯å¢ƒçš„å®Œæ•´æ€§
"""

import torch
import sys
import importlib
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

def test_basic_imports():
    """æµ‹è¯•åŸºç¡€å¯¼å…¥"""
    print("ğŸ§ª æµ‹è¯•åŸºç¡€å¯¼å…¥...")
    
    tests = [
        ("PyTorch", "torch"),
        ("Diffusers", "diffusers"),
        ("Transformers", "transformers"),
        ("HuggingFace Hub", "huggingface_hub"),
        ("Accelerate", "accelerate"),
        ("SafeTensors", "safetensors"),
    ]
    
    success_count = 0
    for name, module in tests:
        try:
            imported_module = importlib.import_module(module)
            version = getattr(imported_module, '__version__', 'unknown')
            print(f"âœ… {name}: {version}")
            success_count += 1
        except ImportError as e:
            print(f"âŒ {name}: å¯¼å…¥å¤±è´¥ - {e}")
    
    print(f"\nğŸ“Š åŸºç¡€å¯¼å…¥ç»“æœ: {success_count}/{len(tests)} æˆåŠŸ")
    return success_count >= len(tests) - 1

def test_vqmodel():
    """æµ‹è¯•VQModel"""
    print("\nğŸ§ª æµ‹è¯•VQModel...")
    
    try:
        from diffusers.models.autoencoders.vq_model import VQModel
        print("âœ… VQModelå¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•åˆ›å»ºVQModelå®ä¾‹
        config = {
            "in_channels": 3,
            "out_channels": 3,
            "latent_channels": 4,
            "num_vq_embeddings": 1024,
            "vq_embed_dim": 256,
        }
        
        model = VQModel(**config)
        print("âœ… VQModelå®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        x = torch.randn(1, 3, 64, 64)
        with torch.no_grad():
            output = model(x)
            print(f"âœ… VQModelå‰å‘ä¼ æ’­æˆåŠŸ: {output.sample.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ VQModelæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_transformers():
    """æµ‹è¯•Transformers"""
    print("\nğŸ§ª æµ‹è¯•Transformers...")
    
    try:
        from transformers import GPT2Config, GPT2LMHeadModel
        print("âœ… GPT2å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•åˆ›å»ºGPT2æ¨¡å‹
        config = GPT2Config(
            vocab_size=1024,
            n_positions=256,
            n_embd=512,
            n_layer=4,
            n_head=8
        )
        
        model = GPT2LMHeadModel(config)
        print("âœ… GPT2å®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        input_ids = torch.randint(0, 1024, (1, 10))
        with torch.no_grad():
            output = model(input_ids)
            print(f"âœ… GPT2å‰å‘ä¼ æ’­æˆåŠŸ: {output.logits.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Transformersæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_custom_models():
    """æµ‹è¯•è‡ªå®šä¹‰æ¨¡å‹"""
    print("\nğŸ§ª æµ‹è¯•è‡ªå®šä¹‰æ¨¡å‹...")
    
    try:
        from models.vqvae_model import MicroDopplerVQVAE
        print("âœ… MicroDopplerVQVAEå¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•åˆ›å»ºè‡ªå®šä¹‰VQ-VAEæ¨¡å‹
        model = MicroDopplerVQVAE(
            in_channels=3,
            out_channels=3,
            latent_channels=4,
            codebook_size=1024,
            codebook_dim=256
        )
        print("âœ… MicroDopplerVQVAEå®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        x = torch.randn(1, 3, 128, 128)
        with torch.no_grad():
            output = model(x)
            print(f"âœ… MicroDopplerVQVAEå‰å‘ä¼ æ’­æˆåŠŸ: {output.sample.shape}")
        
        # æµ‹è¯•æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
        state_dict = model.state_dict()
        print(f"âœ… æ¨¡å‹æƒé‡è·å–æˆåŠŸ: {len(state_dict)} ä¸ªå‚æ•°")
        
        return True
        
    except Exception as e:
        print(f"âŒ è‡ªå®šä¹‰æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_gpu_support():
    """æµ‹è¯•GPUæ”¯æŒ"""
    print("\nğŸ§ª æµ‹è¯•GPUæ”¯æŒ...")
    
    try:
        if torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨: {torch.version.cuda}")
            print(f"âœ… GPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"âœ… å½“å‰GPU: {torch.cuda.get_device_name(0)}")
            
            # æµ‹è¯•GPUå†…å­˜
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"âœ… GPUå†…å­˜: {gpu_memory:.1f}GB")
            
            # æµ‹è¯•GPUæ“ä½œ
            x = torch.randn(100, 100).cuda()
            y = torch.mm(x, x.t())
            print("âœ… GPUè®¡ç®—æµ‹è¯•æˆåŠŸ")
            
            return True
        else:
            print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
            return True
            
    except Exception as e:
        print(f"âŒ GPUæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_training_compatibility():
    """æµ‹è¯•è®­ç»ƒå…¼å®¹æ€§"""
    print("\nğŸ§ª æµ‹è¯•è®­ç»ƒå…¼å®¹æ€§...")
    
    try:
        # æµ‹è¯•æ•°æ®åŠ è½½å™¨
        from torch.utils.data import DataLoader, TensorDataset
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        images = torch.randn(10, 3, 64, 64)
        labels = torch.randint(0, 5, (10,))
        dataset = TensorDataset(images, labels)
        dataloader = DataLoader(dataset, batch_size=2, shuffle=True)
        
        print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ä¼˜åŒ–å™¨
        from models.vqvae_model import MicroDopplerVQVAE
        model = MicroDopplerVQVAE()
        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
        
        print("âœ… ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ä¸€ä¸ªè®­ç»ƒæ­¥éª¤
        model.train()
        for batch_images, batch_labels in dataloader:
            optimizer.zero_grad()
            output = model(batch_images)
            loss = torch.nn.functional.mse_loss(output.sample, batch_images)
            loss.backward()
            optimizer.step()
            break
        
        print("âœ… è®­ç»ƒæ­¥éª¤æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ VQ-VAE + Transformer ç»Ÿä¸€ç¯å¢ƒæµ‹è¯•")
    print("=" * 60)
    print("ğŸ¯ éªŒè¯ç»Ÿä¸€ç¯å¢ƒçš„å®Œæ•´æ€§")
    
    tests = [
        ("åŸºç¡€å¯¼å…¥", test_basic_imports),
        ("VQModelåŠŸèƒ½", test_vqmodel),
        ("TransformersåŠŸèƒ½", test_transformers),
        ("è‡ªå®šä¹‰æ¨¡å‹", test_custom_models),
        ("GPUæ”¯æŒ", test_gpu_support),
        ("è®­ç»ƒå…¼å®¹æ€§", test_training_compatibility),
    ]
    
    success_count = 0
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        if test_func():
            success_count += 1
            print(f"âœ… {test_name} é€šè¿‡")
        else:
            print(f"âŒ {test_name} å¤±è´¥")
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {success_count}/{len(tests)} é€šè¿‡")
    
    if success_count >= len(tests) - 1:  # å…è®¸1ä¸ªå¤±è´¥
        print("\nğŸ‰ ç»Ÿä¸€ç¯å¢ƒæµ‹è¯•æˆåŠŸï¼")
        print("âœ… ç¯å¢ƒé…ç½®æ­£ç¡®ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ")
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        print("   python train_main.py --data_dir /kaggle/input/dataset")
        print("\nğŸ’¡ æç¤º:")
        print("   - ç»Ÿä¸€ç¯å¢ƒæ”¯æŒVQ-VAEå’ŒTransformerè®­ç»ƒ")
        print("   - å¯ä»¥ä½¿ç”¨ --skip_vqvae æˆ– --skip_transformer è¿›è¡Œéƒ¨åˆ†è®­ç»ƒ")
        print("   - æ‰€æœ‰ä¾èµ–éƒ½å·²æ­£ç¡®é…ç½®")
        return True
    else:
        print("\nâŒ ç»Ÿä¸€ç¯å¢ƒæµ‹è¯•å¤±è´¥")
        print("ğŸ”§ å»ºè®®:")
        print("   1. é‡æ–°è¿è¡Œ: python setup_unified_environment.py")
        print("   2. æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        print("   3. å¦‚æœé—®é¢˜æŒç»­ï¼Œä½¿ç”¨åˆ†é˜¶æ®µè®­ç»ƒä½œä¸ºå¤‡é€‰")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
