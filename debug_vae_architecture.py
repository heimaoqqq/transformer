#!/usr/bin/env python3
"""
è°ƒè¯•VAEæ¶æ„ - æ‰¾å‡ºæ­£ç¡®çš„é…ç½®
"""

import torch
from diffusers import AutoencoderKL

def test_vae_configurations():
    """æµ‹è¯•ä¸åŒçš„VAEé…ç½®"""
    print("ğŸ” è°ƒè¯•VAEæ¶æ„é…ç½®")
    print("=" * 50)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # æµ‹è¯•ä¸åŒçš„é…ç½®
    configs = [
        {
            "name": "2å±‚é…ç½®",
            "down_blocks": ["DownEncoderBlock2D", "DownEncoderBlock2D"],
            "up_blocks": ["UpDecoderBlock2D", "UpDecoderBlock2D"],
            "channels": [128, 256],
            "expected": "128â†’64â†’32"
        },
        {
            "name": "3å±‚é…ç½®", 
            "down_blocks": ["DownEncoderBlock2D", "DownEncoderBlock2D", "DownEncoderBlock2D"],
            "up_blocks": ["UpDecoderBlock2D", "UpDecoderBlock2D", "UpDecoderBlock2D"],
            "channels": [128, 256, 256],
            "expected": "128â†’64â†’32â†’16"
        },
        {
            "name": "Stable Diffusionæ ‡å‡†",
            "down_blocks": ["DownEncoderBlock2D", "DownEncoderBlock2D", "DownEncoderBlock2D", "DownEncoderBlock2D"],
            "up_blocks": ["UpDecoderBlock2D", "UpDecoderBlock2D", "UpDecoderBlock2D", "UpDecoderBlock2D"],
            "channels": [128, 256, 512, 512],
            "expected": "128â†’64â†’32â†’16â†’8"
        }
    ]
    
    test_input = torch.randn(1, 3, 128, 128).to(device)
    
    for config in configs:
        print(f"\nğŸ§ª æµ‹è¯• {config['name']}:")
        print(f"   æœŸæœ›: {config['expected']}")
        
        try:
            vae = AutoencoderKL(
                in_channels=3,
                out_channels=3,
                down_block_types=config["down_blocks"],
                up_block_types=config["up_blocks"],
                block_out_channels=config["channels"],
                latent_channels=4,
                sample_size=128,
                layers_per_block=2,
                act_fn="silu",
                norm_num_groups=32,
                scaling_factor=0.18215,
            ).to(device)
            
            with torch.no_grad():
                latent = vae.encode(test_input).latent_dist.sample()
                reconstructed = vae.decode(latent).sample
                
            print(f"   âœ… æ½œåœ¨ç©ºé—´: {latent.shape}")
            print(f"   âœ… é‡å»ºå½¢çŠ¶: {reconstructed.shape}")
            
            # è®¡ç®—å®é™…çš„ä¸‹é‡‡æ ·å€æ•°
            h_ratio = 128 / latent.shape[2]
            w_ratio = 128 / latent.shape[3]
            print(f"   ğŸ“Š ä¸‹é‡‡æ ·å€æ•°: {h_ratio}x{w_ratio}")
            
            # è®¡ç®—å‹ç¼©æ¯”
            input_size = 128 * 128 * 3
            latent_size = latent.shape[1] * latent.shape[2] * latent.shape[3]
            compression_ratio = input_size / latent_size
            print(f"   ğŸ“Š å‹ç¼©æ¯”: {compression_ratio:.1f}:1")
            
            # æ£€æŸ¥æ˜¯å¦ç¬¦åˆæˆ‘ä»¬çš„ç›®æ ‡ (32Ã—32)
            if latent.shape[2] == 32 and latent.shape[3] == 32:
                print(f"   ğŸ¯ âœ… ç¬¦åˆç›®æ ‡ 32Ã—32!")
                return config
            else:
                print(f"   âš ï¸  ä¸ç¬¦åˆç›®æ ‡ 32Ã—32")
                
        except Exception as e:
            print(f"   âŒ é…ç½®å¤±è´¥: {e}")
    
    return None

def find_correct_config_for_32x32():
    """æ‰¾åˆ°æ­£ç¡®çš„32Ã—32é…ç½®"""
    print(f"\nğŸ¯ å¯»æ‰¾32Ã—32çš„æ­£ç¡®é…ç½®...")
    
    # åˆ†æ: 128 â†’ 32 éœ€è¦4å€ä¸‹é‡‡æ ·
    # æ¯å±‚DownEncoderBlock2Dé€šå¸¸ä¸‹é‡‡æ ·2å€
    # æ‰€ä»¥éœ€è¦: 128 â†’ 64 â†’ 32 (2å±‚)
    
    # ä½†å¦‚æœå®é™…æµ‹è¯•æ˜¾ç¤º2å±‚å¾—åˆ°64Ã—64ï¼Œè¯´æ˜æ¯å±‚åªä¸‹é‡‡æ ·âˆš2å€
    # æˆ–è€…æœ‰å…¶ä»–æœºåˆ¶
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    test_input = torch.randn(1, 3, 128, 128).to(device)
    
    # å°è¯•ä¸åŒçš„layers_per_block
    for layers_per_block in [1, 2]:
        print(f"\nğŸ”§ æµ‹è¯• layers_per_block={layers_per_block}:")
        
        try:
            vae = AutoencoderKL(
                in_channels=3,
                out_channels=3,
                down_block_types=["DownEncoderBlock2D", "DownEncoderBlock2D"],
                up_block_types=["UpDecoderBlock2D", "UpDecoderBlock2D"],
                block_out_channels=[128, 256],
                latent_channels=4,
                sample_size=128,
                layers_per_block=layers_per_block,
                act_fn="silu",
                norm_num_groups=32,
                scaling_factor=0.18215,
            ).to(device)
            
            with torch.no_grad():
                latent = vae.encode(test_input).latent_dist.sample()
                
            print(f"   æ½œåœ¨ç©ºé—´: {latent.shape}")
            
            if latent.shape[2] == 32:
                print(f"   ğŸ¯ æ‰¾åˆ°äº†! layers_per_block={layers_per_block}")
                return {"layers_per_block": layers_per_block}
                
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {e}")
    
    # å¦‚æœè¿˜æ˜¯ä¸è¡Œï¼Œå°è¯•è°ƒæ•´sample_size
    print(f"\nğŸ”§ æµ‹è¯•è°ƒæ•´sample_size:")
    for sample_size in [64, 128, 256]:
        try:
            vae = AutoencoderKL(
                in_channels=3,
                out_channels=3,
                down_block_types=["DownEncoderBlock2D", "DownEncoderBlock2D"],
                up_block_types=["UpDecoderBlock2D", "UpDecoderBlock2D"],
                block_out_channels=[128, 256],
                latent_channels=4,
                sample_size=sample_size,
                layers_per_block=2,
                act_fn="silu",
                norm_num_groups=32,
                scaling_factor=0.18215,
            ).to(device)
            
            with torch.no_grad():
                latent = vae.encode(test_input).latent_dist.sample()
                
            print(f"   sample_size={sample_size}: æ½œåœ¨ç©ºé—´ {latent.shape}")
            
            if latent.shape[2] == 32:
                print(f"   ğŸ¯ æ‰¾åˆ°äº†! sample_size={sample_size}")
                return {"sample_size": sample_size}
                
        except Exception as e:
            print(f"   âŒ sample_size={sample_size} å¤±è´¥: {e}")
    
    return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” VAEæ¶æ„è°ƒè¯•å·¥å…·")
    
    # æµ‹è¯•ä¸åŒé…ç½®
    best_config = test_vae_configurations()
    
    if not best_config:
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        correction = find_correct_config_for_32x32()
        if correction:
            print(f"\nğŸ’¡ å»ºè®®ä¿®æ­£: {correction}")
    
    print(f"\nğŸ“ æ€»ç»“:")
    print(f"   ç›®æ ‡: 128Ã—128 â†’ 32Ã—32Ã—4")
    print(f"   é—®é¢˜: å½“å‰é…ç½®äº§ç”Ÿ64Ã—64è€Œä¸æ˜¯32Ã—32")
    print(f"   è§£å†³: éœ€è¦è°ƒæ•´æ¶æ„å‚æ•°")

if __name__ == "__main__":
    main()
